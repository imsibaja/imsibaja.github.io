[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "A lack of Pisaster may lead to … disaster\n\n\n\nQuarto\n\n\nMEDS\n\n\n\n\n\n\n\nIMS\n\n\nMar 17, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nBloom Shift\n\n\n\n\n\n\nIan Morris-Sibaja\n\n\nJan 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nThe Environmental Effects of the 2017 Thomas Fire\n\n\n\n\n\n\nIan Morris-Sibaja\n\n\nDec 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello World!\n\n\n\nQuarto\n\n\nMEDS\n\n\n\nMy first blog\n\n\n\nIMS\n\n\nOct 18, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ian Morris-Sibaja",
    "section": "",
    "text": "Ian Morris-Sibaja\n          \n            Environmental Data Scientist\n            Analyzing Ecosystem Responses on Land and Sea\n          \n        \n\n        \n          \n        \n      \n      \n      \n         LinkedIn\n         GitHub\n         Email\n         Resume\n      \n      \n      \n        Ian Morris-Sibaja is an environmental data scientist who applies modeling and data analysis to tackle pressing environmental challenges. He recently completed his Master of Environmental Data Science at UC Santa Barbara, where his capstone project with The Nature Conservancy used advanced statistical models to analyze range shifts of coastal species around Point Conception. Ian’s goal is to leverage his analytical toolkit to deliver data-driven solutions that measure and mitigate human impacts on Southern California’s natural environments.\n      \n    \n  \n\n  \n  \n    \n\n      \n        \n        \n          Coastal Species Range Shift Analysis\n          Capstone project using GAM models and geospatial datasets to quantify shifts in coastal species distributions for The Nature Conservancy, bundled into a tidy shiny app.\n          View Project\n        \n      \n\n      \n        Python\n        R\n        GIS\n        Statistical Modeling\n        Machine Learning\n        Data Pipelines\n        Reproducible Workflows"
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html",
    "href": "posts/2024-12-13-thomas-fire/index.html",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "Author: Ian Morris-Sibaja\n\n\n Image credits: spookysnoopy via Imgur\n\n\nThis notebook explores the 2017 Thomas Fire, one of California’s largest wildfires, which burned over 280,000 acres across Ventura and Santa Barbara counties, causing extensive environmental damage, including vegetation loss, soil erosion, and increased flood risks. This notebook examines the fire’s impact on air quality using AQI data from the US Environmental Protection Agency and visualizes burn severity and fire scars using false-colored Landsat multispectral geospatial data.\n\n\n\n\nAnalyzed Thomas Fires using AQI and Landsat data, creating time-series maps to explore wildfire impacts\nDeveloped true and false color imagery to highlight fire extent and visualize fire scars alongside perimeter data\nCombined and wrangled date and string data, merging data frames for streamlined analysis\nVisualized time series and polished workflows while manipulating raster and vector data with Rasterio and GeoPandas\nEnsured collaboration and reproducibility through structured workflows and Git version control best practices\n\n\n\n\n\n\nThe U.S. Air Quality Index (AQI), developed by the EPA, communicates outdoor air quality and associated health risks through six color-coded categories, ranging from “Good” (AQI ≤ 50) to “Hazardous” (AQI &gt; 300). AQI values up to 100 indicate satisfactory air quality, aligned with national health standards, while values above 100 signal unhealthy conditions—initially for sensitive groups and eventually for all as pollution levels rise. The color-coded system enables quick identification of air quality concerns in communities.\n\n\n\nThis dataset consists of simplified bands (red, green, blue, near-infrared, and shortwave infrared) from Landsat Collection 2 Level-2 surface reflectance data, which was atmospherically corrected and captured by NASA’s Landsat 8 satellite. It was sourced from the Microsoft Planetary Computer data catalog and preprocessed to exclude non-land areas and reduce spatial resolution for ease of computation.\n\n\n\nThis database contains spatial distribution information of both wild and prescribed fires in California. The data comes with a warning of its incompleteness. Some records were lost or damaged, so fire perimeters may be missing. There may also be duplicate or an over estimation of fire perimeters. The database is maintained by the California Department of Forestry and Fire Protection’s Fire and Resource Assessment Program.\n\n\n\n\nThe full repository can be found here.\n\n\n\n\n\n\nImport Modules\n# Import modules\nimport rioxarray as rioxr\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport os\n\n\n\n\nImport AQI data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\",\n                     compression=\"zip\")\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\",\n                     compression=\"zip\")\n\n\n\n\nImport landsat data\nlandsat_fp = os.path.join(\"data\", \"landsat8-2018-01-26-sb-simplified.nc\")\nlandsat = rioxr.open_rasterio(landsat_fp)\n\n\n\n\nImport Thomas Fire data\nthomas_fp = os.path.join(\"data\", \"thomas_2017.geojson\")\nthomas_2017 = gpd.read_file(thomas_fp)\n\n\n\n\n\n\n\nWe begin this section by excecuting preliminary explorations of our data.\n\n\nView first five rows of 2017 AQI\naqi_17_head\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n\nView first five rows of 2018 AQI\naqi_18_head\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n42\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n45\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2018-01-08\n20\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2018-01-11\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2018-01-14\n33\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n# Compare the differing shapes\nprint(aqi_17.shape, aqi_18.shape)\n# Compare dataframe columns and dtypes\nprint(aqi_17.dtypes == aqi_18.dtypes)\n\n(326801, 10) (327543, 10)\nState Name                   True\ncounty Name                  True\nState Code                   True\nCounty Code                  True\nDate                         True\nAQI                          True\nCategory                     True\nDefining Parameter           True\nDefining Site                True\nNumber of Sites Reporting    True\ndtype: bool\n\n\nWe started by examining the shape and data types of each dataframe to assess their compatibility for comparison. This step is crucial for ensuring the legitimacy of directly analyzing these two datasets together. Lucky for us, the dataframes share identical columns with matching data types. This consistency allows for seamless comparison and concatenation, aiding in our analysis.\n\n\n\nTo aid in our comparisons, we begin by cleaning up our data.\n\n\nConcatenate the two dataframes together\naqi = pd.concat([aqi_17, aqi_18])\naqi\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n327538\nWyoming\nWeston\n56\n45\n2018-12-27\n36\nGood\nOzone\n56-045-0003\n1\n\n\n327539\nWyoming\nWeston\n56\n45\n2018-12-28\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327540\nWyoming\nWeston\n56\n45\n2018-12-29\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327541\nWyoming\nWeston\n56\n45\n2018-12-30\n31\nGood\nOzone\n56-045-0003\n1\n\n\n327542\nWyoming\nWeston\n56\n45\n2018-12-31\n35\nGood\nOzone\n56-045-0003\n1\n\n\n\n\n654344 rows × 10 columns\n\n\n\n\n\nClean column names\n# Initial column names: notice caps and spaces (difficult to work with!)\nprint(aqi.columns, '\\n')\n\n# Simplify column names\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_')\n                )\nprint(aqi.columns, '\\n')\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object') \n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object') \n\n\n\nConcatenating and cleaning our column names help us create a clean dataframe that will aid in filtering. We want to filter for Santa Barbara only and our necessary column names.\n\n\nFilter and clean data\n# Filter AQI to only Santa Barbara\naqi_sb = aqi[aqi[\"county_name\"] == \"Santa Barbara\"]\n# Drop unnecessary columns\naqi_sb = aqi_sb.drop(columns=['state_name', 'county_name', 'state_code', 'county_code'])\n\n# Find data type of date column\ndate_type = aqi_sb[\"date\"].dtype\n# Update the date column to be pd.datetime object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n# Update index to the date column\naqi_sb = aqi_sb.set_index(\"date\")\naqi_sb.sort_index(inplace=True)\n\n\nNow with our data cleaned, we can begin with our analysis. We want to calculate the AQI average over a 5 day rolling window.\n\n# Calculate AQI rolling average over 5 days\nrolling_average = aqi_sb[\"aqi\"].rolling(\"5D\").mean()\n# Add rolling mean to SB dataframe\naqi_sb[\"five_day_average\"] = rolling_average.values\n\nHooray! We have completed our data cleaning and now we have a easy to plot data frame full of rolling average values. All we have left is to…\n\n\n\n\n\nPlot AQI Rolling Average\n# Visualize the AQI data\naqi_sb.plot(kind=\"line\",\n            y=[\"aqi\", \"five_day_average\"],\n            xlabel=\"Date\",\n            ylabel=\"PM 2.5\",\n            label=[\"Daily AQI Level\", \"5-Day Average AQI\"],\n            title=\"Daily and Rolling Average AQI\\nof Santa Barbara County from 2017-18\")\n\n\n\n\n\n\n\n\n\nAs you can see, there is a large spike in PM 2.5 during the same time frame of the Thomas Fire in late 2017. Next, we will visualize the fire scars left by the fire using landsat data and false color imagery.\n\n\n\n\n\n\nWe will examine the dataset to understand its structure. After exploring the data, we will summarize in paragraph form.\n\n# Show preliminary xarrary.Dataset\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\n\n# Show dimensions of dataset \nprint(landsat.dims)\n\nFrozenMappingWarningOnValuesAccess({'band': 1, 'x': 870, 'y': 731})\n\n\n\n# Show CRS of dataset \nprint(landsat.rio.crs)\n\nEPSG:32611\n\n\n\n# Show datatypes of dataset \nprint(landsat.dtypes)\n\nFrozen({'red': dtype('float64'), 'green': dtype('float64'), 'blue': dtype('float64'), 'nir08': dtype('float64'), 'swir22': dtype('float64')})\n\n\n\n\nThis dataset is a 2D dataset with a single band. There are five wavelength ranges captures, red, green, blue, near infrared and short wave infrared. The dataset is of CRS EPSG:32611.\n\n\n\n\nTo ease visualizations, we will simplify the dataset by removing unnecessary dimensions.\n\n\nDrop band dimension of data\nlandsat = landsat.drop_vars(\"band\").squeeze()\n\n\n\n# View updated dataset\nlandsat.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1kB\nDimensions:      (x: 5, y: 5)\nCoordinates:\n  * x            (x) float64 40B 1.213e+05 1.216e+05 ... 1.221e+05 1.224e+05\n  * y            (y) float64 40B 3.952e+06 3.952e+06 ... 3.952e+06 3.951e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (y, x) float64 200B ...\n    green        (y, x) float64 200B ...\n    blue         (y, x) float64 200B ...\n    nir08        (y, x) float64 200B ...\n    swir22       (y, x) float64 200B ...xarray.DatasetDimensions:x: 5y: 5Coordinates: (3)x(x)float641.213e+05 1.216e+05 ... 1.224e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., 122115., 122385.])y(y)float643.952e+06 3.952e+06 ... 3.951e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., 3951585., 3951315.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]green(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]blue(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]nir08(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]swir22(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]Indexes: (2)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0], dtype='float64', name='x'))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0], dtype='float64', name='y'))Attributes: (0)\n\n\n\n\n\nBy extracting the red, green, and blue bands we can begin to create an RGB image.\n\n\nFilter and clean data\n# Filter AQI to only Santa Barbara\naqi_sb = aqi[aqi[\"county_name\"] == \"Santa Barbara\"]\n# Drop unnecessary columns\naqi_sb = aqi_sb.drop(columns=['state_name', 'county_name', 'state_code', 'county_code'])\n\n\nConverting the dataframe to an array will easily allow us to plot using the plot.imshow() method.\n\n# Convert to array\nlandsat[[\"red\", \"green\", \"blue\"]].to_array()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (variable: 3, y: 731, x: 870)&gt; Size: 15MB\narray([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])\nCoordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\n  * variable     (variable) object 24B 'red' 'green' 'blue'xarray.DataArrayvariable: 3y: 731x: 8700.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])Coordinates: (4)x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)variable(variable)object'red' 'green' 'blue'array(['red', 'green', 'blue'], dtype=object)Indexes: (3)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))variablePandasIndexPandasIndex(Index(['red', 'green', 'blue'], dtype='object', name='variable'))Attributes: (0)\n\n\n\n\n\nNow we will plot the RGB data to visualize it as a true color image.\n\n# Visualize with simple plot\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\nWell we did not alter the robust parameter. Let’s set it to True and see what happens!\n\n# Visualize with true color plot\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\nThe output of a) shows a black and white outline of the area we are working with, while b) shows us a more true to color rendering. The robust=True parameter that we added will eliminate any outliers that may alter the data. It uses 2nd and 98th percentiles of the data to compute the color limits.\n\n\n\nTo visualize specific features like vegetation health or fire impacts, we can create false color imagery using the red, near infrared, and short wave infrared bands.\n\n# Visualize with false color plot\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, we can overlay the false color imagery with critical geographical features like the fire perimeters we imported before.\n\n# Compare CRS\nprint(landsat.rio.crs)\nprint(thomas_2017.crs)\n\nEPSG:32611\nEPSG:4326\n\n\n\n\nReproject data\nthomas_2017 = thomas_2017.to_crs(landsat.rio.crs)\nprint('Matched CRS?:',  landsat.rio.crs == thomas_2017.crs)\n\n\nMatched CRS?: True\n\n\n\n\nVisualize Thomas Fire scar\n# Plot of false color raster with buffer overlay\nfig, ax = plt.subplots(figsize=(6, 7))  # Directly set size and aspect\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(\n                robust=True,\n                ax=ax)\nthomas_2017.boundary.plot(ax=ax, color=\"maroon\")\nax.axis(\"off\")\nax.legend([\"Thomas Fire Boundary\"])\nfig.suptitle(\"2017 Thomas Fire Scar\", color = 'black', fontsize = 14, fontweight='light', y=0.855)\nax.set_title(\"False colors with Short Wave Infrared, Near-Infrared, & Red Wavelengths\", fontsize=9)\nfig.text(x=.5,y=.2,\n        s='Data Source: CAL FIRE via Data.gov &  Microsof Planetary Computer data catalogue',\n        ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nfig.text(x=.5,y=.18,\n        s='Date Accessed: 11/19/24',\n        ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThis map uses false-color imagery to highlight vegetation and fire-affected areas within the Thomas Fire boundary from 2017. In this visualization, near-infrared (NIR) is represented as green, shortwave infrared (SWIR) as red, and red light as blue. Healthy vegetation strongly reflects NIR, making those areas appear green, while it absorbs red and SWIR wavelengths. Burned areas, often rich in iron oxides, reflect SWIR more strongly, appearing red in the image. This method helps distinguish fire scars and vegetation loss more effectively compared to true-color images, which use visible red, green, and blue wavelengths and may not clearly show such contrasts.\n\n\n\n\nLandsat Data from Microsoft’s Planetary Computer Data Catalogue, AQI Data from the EPA’s daily AQI summaries\n\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 4-5 Thematic Mapper Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9IAXOVV\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 7 Enhanced Thematic Mapper Plus Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9C7I13B\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 8-9 Operational Land Imager / Thermal Infrared Sensor Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9OGBGM6\n\nGalaz García, Carmen. Assignment4 – EDS 220 - Working with Environmental Datasets. (n.d.). https://meds-eds-220.github.io/MEDS-eds-220-course/assignments/assignment4.html"
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html#about",
    "href": "posts/2024-12-13-thomas-fire/index.html#about",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "Image credits: spookysnoopy via Imgur\n\n\nThis notebook explores the 2017 Thomas Fire, one of California’s largest wildfires, which burned over 280,000 acres across Ventura and Santa Barbara counties, causing extensive environmental damage, including vegetation loss, soil erosion, and increased flood risks. This notebook examines the fire’s impact on air quality using AQI data from the US Environmental Protection Agency and visualizes burn severity and fire scars using false-colored Landsat multispectral geospatial data.\n\n\n\n\nAnalyzed Thomas Fires using AQI and Landsat data, creating time-series maps to explore wildfire impacts\nDeveloped true and false color imagery to highlight fire extent and visualize fire scars alongside perimeter data\nCombined and wrangled date and string data, merging data frames for streamlined analysis\nVisualized time series and polished workflows while manipulating raster and vector data with Rasterio and GeoPandas\nEnsured collaboration and reproducibility through structured workflows and Git version control best practices\n\n\n\n\n\n\nThe U.S. Air Quality Index (AQI), developed by the EPA, communicates outdoor air quality and associated health risks through six color-coded categories, ranging from “Good” (AQI ≤ 50) to “Hazardous” (AQI &gt; 300). AQI values up to 100 indicate satisfactory air quality, aligned with national health standards, while values above 100 signal unhealthy conditions—initially for sensitive groups and eventually for all as pollution levels rise. The color-coded system enables quick identification of air quality concerns in communities.\n\n\n\nThis dataset consists of simplified bands (red, green, blue, near-infrared, and shortwave infrared) from Landsat Collection 2 Level-2 surface reflectance data, which was atmospherically corrected and captured by NASA’s Landsat 8 satellite. It was sourced from the Microsoft Planetary Computer data catalog and preprocessed to exclude non-land areas and reduce spatial resolution for ease of computation.\n\n\n\nThis database contains spatial distribution information of both wild and prescribed fires in California. The data comes with a warning of its incompleteness. Some records were lost or damaged, so fire perimeters may be missing. There may also be duplicate or an over estimation of fire perimeters. The database is maintained by the California Department of Forestry and Fire Protection’s Fire and Resource Assessment Program.\n\n\n\n\nThe full repository can be found here."
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html#import-data-and-modules",
    "href": "posts/2024-12-13-thomas-fire/index.html#import-data-and-modules",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "Import Modules\n# Import modules\nimport rioxarray as rioxr\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport os\n\n\n\n\nImport AQI data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\",\n                     compression=\"zip\")\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\",\n                     compression=\"zip\")\n\n\n\n\nImport landsat data\nlandsat_fp = os.path.join(\"data\", \"landsat8-2018-01-26-sb-simplified.nc\")\nlandsat = rioxr.open_rasterio(landsat_fp)\n\n\n\n\nImport Thomas Fire data\nthomas_fp = os.path.join(\"data\", \"thomas_2017.geojson\")\nthomas_2017 = gpd.read_file(thomas_fp)"
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html#visualizing-aqi-during-the-2017-thomas-fire-in-santa-barbara-county",
    "href": "posts/2024-12-13-thomas-fire/index.html#visualizing-aqi-during-the-2017-thomas-fire-in-santa-barbara-county",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "We begin this section by excecuting preliminary explorations of our data.\n\n\nView first five rows of 2017 AQI\naqi_17_head\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n\nView first five rows of 2018 AQI\naqi_18_head\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n42\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n45\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2018-01-08\n20\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2018-01-11\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2018-01-14\n33\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n# Compare the differing shapes\nprint(aqi_17.shape, aqi_18.shape)\n# Compare dataframe columns and dtypes\nprint(aqi_17.dtypes == aqi_18.dtypes)\n\n(326801, 10) (327543, 10)\nState Name                   True\ncounty Name                  True\nState Code                   True\nCounty Code                  True\nDate                         True\nAQI                          True\nCategory                     True\nDefining Parameter           True\nDefining Site                True\nNumber of Sites Reporting    True\ndtype: bool\n\n\nWe started by examining the shape and data types of each dataframe to assess their compatibility for comparison. This step is crucial for ensuring the legitimacy of directly analyzing these two datasets together. Lucky for us, the dataframes share identical columns with matching data types. This consistency allows for seamless comparison and concatenation, aiding in our analysis.\n\n\n\nTo aid in our comparisons, we begin by cleaning up our data.\n\n\nConcatenate the two dataframes together\naqi = pd.concat([aqi_17, aqi_18])\naqi\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n327538\nWyoming\nWeston\n56\n45\n2018-12-27\n36\nGood\nOzone\n56-045-0003\n1\n\n\n327539\nWyoming\nWeston\n56\n45\n2018-12-28\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327540\nWyoming\nWeston\n56\n45\n2018-12-29\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327541\nWyoming\nWeston\n56\n45\n2018-12-30\n31\nGood\nOzone\n56-045-0003\n1\n\n\n327542\nWyoming\nWeston\n56\n45\n2018-12-31\n35\nGood\nOzone\n56-045-0003\n1\n\n\n\n\n654344 rows × 10 columns\n\n\n\n\n\nClean column names\n# Initial column names: notice caps and spaces (difficult to work with!)\nprint(aqi.columns, '\\n')\n\n# Simplify column names\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_')\n                )\nprint(aqi.columns, '\\n')\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object') \n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object') \n\n\n\nConcatenating and cleaning our column names help us create a clean dataframe that will aid in filtering. We want to filter for Santa Barbara only and our necessary column names.\n\n\nFilter and clean data\n# Filter AQI to only Santa Barbara\naqi_sb = aqi[aqi[\"county_name\"] == \"Santa Barbara\"]\n# Drop unnecessary columns\naqi_sb = aqi_sb.drop(columns=['state_name', 'county_name', 'state_code', 'county_code'])\n\n# Find data type of date column\ndate_type = aqi_sb[\"date\"].dtype\n# Update the date column to be pd.datetime object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n# Update index to the date column\naqi_sb = aqi_sb.set_index(\"date\")\naqi_sb.sort_index(inplace=True)\n\n\nNow with our data cleaned, we can begin with our analysis. We want to calculate the AQI average over a 5 day rolling window.\n\n# Calculate AQI rolling average over 5 days\nrolling_average = aqi_sb[\"aqi\"].rolling(\"5D\").mean()\n# Add rolling mean to SB dataframe\naqi_sb[\"five_day_average\"] = rolling_average.values\n\nHooray! We have completed our data cleaning and now we have a easy to plot data frame full of rolling average values. All we have left is to…\n\n\n\n\n\nPlot AQI Rolling Average\n# Visualize the AQI data\naqi_sb.plot(kind=\"line\",\n            y=[\"aqi\", \"five_day_average\"],\n            xlabel=\"Date\",\n            ylabel=\"PM 2.5\",\n            label=[\"Daily AQI Level\", \"5-Day Average AQI\"],\n            title=\"Daily and Rolling Average AQI\\nof Santa Barbara County from 2017-18\")\n\n\n\n\n\n\n\n\n\nAs you can see, there is a large spike in PM 2.5 during the same time frame of the Thomas Fire in late 2017. Next, we will visualize the fire scars left by the fire using landsat data and false color imagery."
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html#thomas-fire-false-color",
    "href": "posts/2024-12-13-thomas-fire/index.html#thomas-fire-false-color",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "We will examine the dataset to understand its structure. After exploring the data, we will summarize in paragraph form.\n\n# Show preliminary xarrary.Dataset\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\n\n# Show dimensions of dataset \nprint(landsat.dims)\n\nFrozenMappingWarningOnValuesAccess({'band': 1, 'x': 870, 'y': 731})\n\n\n\n# Show CRS of dataset \nprint(landsat.rio.crs)\n\nEPSG:32611\n\n\n\n# Show datatypes of dataset \nprint(landsat.dtypes)\n\nFrozen({'red': dtype('float64'), 'green': dtype('float64'), 'blue': dtype('float64'), 'nir08': dtype('float64'), 'swir22': dtype('float64')})\n\n\n\n\nThis dataset is a 2D dataset with a single band. There are five wavelength ranges captures, red, green, blue, near infrared and short wave infrared. The dataset is of CRS EPSG:32611.\n\n\n\n\nTo ease visualizations, we will simplify the dataset by removing unnecessary dimensions.\n\n\nDrop band dimension of data\nlandsat = landsat.drop_vars(\"band\").squeeze()\n\n\n\n# View updated dataset\nlandsat.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1kB\nDimensions:      (x: 5, y: 5)\nCoordinates:\n  * x            (x) float64 40B 1.213e+05 1.216e+05 ... 1.221e+05 1.224e+05\n  * y            (y) float64 40B 3.952e+06 3.952e+06 ... 3.952e+06 3.951e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (y, x) float64 200B ...\n    green        (y, x) float64 200B ...\n    blue         (y, x) float64 200B ...\n    nir08        (y, x) float64 200B ...\n    swir22       (y, x) float64 200B ...xarray.DatasetDimensions:x: 5y: 5Coordinates: (3)x(x)float641.213e+05 1.216e+05 ... 1.224e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., 122115., 122385.])y(y)float643.952e+06 3.952e+06 ... 3.951e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., 3951585., 3951315.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]green(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]blue(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]nir08(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]swir22(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]Indexes: (2)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0], dtype='float64', name='x'))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0], dtype='float64', name='y'))Attributes: (0)\n\n\n\n\n\nBy extracting the red, green, and blue bands we can begin to create an RGB image.\n\n\nFilter and clean data\n# Filter AQI to only Santa Barbara\naqi_sb = aqi[aqi[\"county_name\"] == \"Santa Barbara\"]\n# Drop unnecessary columns\naqi_sb = aqi_sb.drop(columns=['state_name', 'county_name', 'state_code', 'county_code'])\n\n\nConverting the dataframe to an array will easily allow us to plot using the plot.imshow() method.\n\n# Convert to array\nlandsat[[\"red\", \"green\", \"blue\"]].to_array()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (variable: 3, y: 731, x: 870)&gt; Size: 15MB\narray([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])\nCoordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\n  * variable     (variable) object 24B 'red' 'green' 'blue'xarray.DataArrayvariable: 3y: 731x: 8700.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])Coordinates: (4)x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)variable(variable)object'red' 'green' 'blue'array(['red', 'green', 'blue'], dtype=object)Indexes: (3)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))variablePandasIndexPandasIndex(Index(['red', 'green', 'blue'], dtype='object', name='variable'))Attributes: (0)\n\n\n\n\n\nNow we will plot the RGB data to visualize it as a true color image.\n\n# Visualize with simple plot\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\nWell we did not alter the robust parameter. Let’s set it to True and see what happens!\n\n# Visualize with true color plot\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\nThe output of a) shows a black and white outline of the area we are working with, while b) shows us a more true to color rendering. The robust=True parameter that we added will eliminate any outliers that may alter the data. It uses 2nd and 98th percentiles of the data to compute the color limits.\n\n\n\nTo visualize specific features like vegetation health or fire impacts, we can create false color imagery using the red, near infrared, and short wave infrared bands.\n\n# Visualize with false color plot\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, we can overlay the false color imagery with critical geographical features like the fire perimeters we imported before.\n\n# Compare CRS\nprint(landsat.rio.crs)\nprint(thomas_2017.crs)\n\nEPSG:32611\nEPSG:4326\n\n\n\n\nReproject data\nthomas_2017 = thomas_2017.to_crs(landsat.rio.crs)\nprint('Matched CRS?:',  landsat.rio.crs == thomas_2017.crs)\n\n\nMatched CRS?: True\n\n\n\n\nVisualize Thomas Fire scar\n# Plot of false color raster with buffer overlay\nfig, ax = plt.subplots(figsize=(6, 7))  # Directly set size and aspect\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(\n                robust=True,\n                ax=ax)\nthomas_2017.boundary.plot(ax=ax, color=\"maroon\")\nax.axis(\"off\")\nax.legend([\"Thomas Fire Boundary\"])\nfig.suptitle(\"2017 Thomas Fire Scar\", color = 'black', fontsize = 14, fontweight='light', y=0.855)\nax.set_title(\"False colors with Short Wave Infrared, Near-Infrared, & Red Wavelengths\", fontsize=9)\nfig.text(x=.5,y=.2,\n        s='Data Source: CAL FIRE via Data.gov &  Microsof Planetary Computer data catalogue',\n        ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nfig.text(x=.5,y=.18,\n        s='Date Accessed: 11/19/24',\n        ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThis map uses false-color imagery to highlight vegetation and fire-affected areas within the Thomas Fire boundary from 2017. In this visualization, near-infrared (NIR) is represented as green, shortwave infrared (SWIR) as red, and red light as blue. Healthy vegetation strongly reflects NIR, making those areas appear green, while it absorbs red and SWIR wavelengths. Burned areas, often rich in iron oxides, reflect SWIR more strongly, appearing red in the image. This method helps distinguish fire scars and vegetation loss more effectively compared to true-color images, which use visible red, green, and blue wavelengths and may not clearly show such contrasts.\n\n\n\n\nLandsat Data from Microsoft’s Planetary Computer Data Catalogue, AQI Data from the EPA’s daily AQI summaries\n\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 4-5 Thematic Mapper Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9IAXOVV\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 7 Enhanced Thematic Mapper Plus Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9C7I13B\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 8-9 Operational Land Imager / Thermal Infrared Sensor Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9OGBGM6\n\nGalaz García, Carmen. Assignment4 – EDS 220 - Working with Environmental Datasets. (n.d.). https://meds-eds-220.github.io/MEDS-eds-220-course/assignments/assignment4.html"
  },
  {
    "objectID": "posts/2024-10-18-hello-world/index.html",
    "href": "posts/2024-10-18-hello-world/index.html",
    "title": "Hello World!",
    "section": "",
    "text": "In my first language, C++\n#include &lt;iostream&gt;\n\nint main(){\n  std::cout&lt;&lt;\"Hello, World!\"&lt;&lt;std::endl;\n  return 0;\n}\nIn my favorite language, Python:\nprint(\"Hello, World!\")\nIn a language I am forced to use, R:\nprint(\"Hello, World!\")\nErm… How original…\nNo programmer is complete without the proverbial “Hello World!”. Now that that is done, I’ll the rest of the blog will be dedicated to Environmental Data Science. What’s that you say? Why don’t you check out my other posts and find out!"
  },
  {
    "objectID": "posts/2024-10-18-hello-world/index.html#hello-world",
    "href": "posts/2024-10-18-hello-world/index.html#hello-world",
    "title": "Hello World!",
    "section": "",
    "text": "In my first language, C++\n#include &lt;iostream&gt;\n\nint main(){\n  std::cout&lt;&lt;\"Hello, World!\"&lt;&lt;std::endl;\n  return 0;\n}\nIn my favorite language, Python:\nprint(\"Hello, World!\")\nIn a language I am forced to use, R:\nprint(\"Hello, World!\")\nErm… How original…\nNo programmer is complete without the proverbial “Hello World!”. Now that that is done, I’ll the rest of the blog will be dedicated to Environmental Data Science. What’s that you say? Why don’t you check out my other posts and find out!"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html",
    "href": "posts/2025-01-26-bloom-shift/index.html",
    "title": "Bloom Shift",
    "section": "",
    "text": "Author: Ian Morris-Sibaja\n\n\n\n\n\nSedgewick Reserve\n\n\nImage credits: UCNRS\n\n\nThis study investigates how climate change influences the flowering phenology of native and invasive Californian annual forbs. Given California’s status as a biodiversity hotspot and the region’s susceptibility to hotter and drier conditions, this research aims to understand how shifts in temperature and precipitation affect plant communities. Specifically, we address two primary questions:\n\nDoes the average flowering observation date correlate with changes in annual temperature or precipitation?\nAre particular climate zones, such as coastal Southern California, experiencing more pronounced phenological shifts compared to the state as a whole?\n\nBy analyzing 50 years of data on nine plant species and correlating it with climate trends, this research seeks to highlight the potential impacts of climate change on native and invasive species, with implications for ecosystem stability and conservation planning.\n\n\n\n\nPhenological Shifts: Investigate if flowering times correlate with changes in temperature and precipitation over time.\nSpatial Analysis: Determine if shifts are more pronounced in certain climate zones, e.g., coastal Southern California.\nConservation Implications: Understand how these changes impact the ecosystem dynamics and inform conservation strategies for native biodiversity.\nFocused on California, a biodiversity hotspot particularly sensitive to climate changes.\nIdentified trends for each species using statistical models (OLS regression) to link phenology with climate trends.\nHighlights differences between native and invasive species in their response to environmental changes.\n\n\n\n\nThe study relies on 50 years of data (1966–2016) on flowering observations for nine Californian annual forb species, including both native and invasive types. This dataset integrates:\n\nFlowering data: Derived from occurrence records supplied, focusing on observations from California.\nClimate data: Compiled from the National Weather Service Cooperative Observer Program (NWS COOP), including annual temperature and precipitation records.\nSpatial data: Uses shapefiles from NOAA to map flowering data to specific climate divisions in California.\nData preprocessing ensured temporal consistency and excluded irrelevant records.\n\n\n\n\n\n\n\nImport Modules\n# Import modules\nimport pandas as pd\nimport os\nfrom plotly import express as px\nimport plotly.graph_objects as go\nimport numpy as np\nimport geopandas as gpd\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sb\nimport statsmodels.formula.api as smf\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\n\n\n\n\n\n\n\nLoad Climate Data\n# set the directory to the climate data\ndirectory = './data/climate/'\n\n# create a dictionary to store all files in this directory\nd = {}\n# iterate over files in this directory, add each name of file and its contents into a dictionary\nfor filename in os.listdir(directory):\n        d[filename] = pd.read_csv(f'./data/climate/{filename}', encoding= 'unicode_escape')\ndel d['.DS_Store']\n\n\n\n# iterate over the dictionary and add the COOP_ID and type of data to each dataframe\nmaxMinT = []\nmaxMinP = []\n\nfor key, value in d.items():\n    if key[7:8] == 'p':\n        maxMinP.append(d[key]['YEAR(S)'].min())\n    else:\n        maxMinT.append(d[key]['YEAR(S)'].min())\n    value['COOP_ID'] = key[1:6]\n    value['type'] = key[7:8]\n    d[key] = d[key].loc[:, ~d[key].columns.str.contains('^Unnamed')]\n\nThe National Weather Service (NWS) Cooperative Observer Program (COOP) is a network of daily weather observations taken by more than 8,500 volunteers. Here we import and clean the data to be manipulated in out dataset.\n\n# Create a dataframe with COOP information \ncoopNames = pd.read_csv('./data/Coopnames.csv')\ncoopNames = coopNames.drop([0,1,2]).reset_index(drop=True)\ncoopNames = coopNames[['COOP_ID', 'COOP_NAME', 'DIV', 'LATITUDE', 'LONGITUDE']]\n\n# convert COOP_ID to int\ncoopNames.COOP_ID = coopNames.COOP_ID.astype(int)\n\n\n# merge the COOP information with the climate data\ncoop = pd.concat(d.values(), ignore_index=True)\n\n# filter the data to only include years 1966-2016\ncoop = coop[coop['YEAR(S)']&gt;=1966]\ncoop = coop[coop['YEAR(S)']&lt;=2016]\n\n# drop rows with irrelevant data\ncoop = coop.replace(['-----'], np.nan).reset_index(drop=True)\ncoop = coop.loc[:, ~coop.columns.str.contains('^Unnamed')]\ncoop = coop.drop(['January'], axis =1)\n\n\n\nCOOP Data\ncoop\n\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nt\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nt\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nt\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nt\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nt\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5929\n2012\n0.62\n0.45\n1.73\n1.39\n0.03\n0.00\n0.00\n0.00\n0.00\n0.28\n0.49\n1.90\n4.09\n43747\np\n\n\n5930\n2013\n0.22\n0.48\n0.79\n0.08\n0.17\n0.00\n0.00\n0.00\n0.01\n0.00\n0.33\n0.16\n2.24\n43747\np\n\n\n5931\n2014\n0.30\n1.38\n0.27\n0.35\n0.00\n0.00\n0.00\n0.00\n0.03\n0.00\n0.94\n2.52\n5.79\n43747\np\n\n\n5932\n2015\n0.08\n0.72\n0.02\n0.77\n0.10\n0.00\n0.45\n0.00\n0.00\n0.38\n0.91\n1.40\n4.83\n43747\np\n\n\n5933\n2016\n2.56\n0.58\n1.99\n0.57\n0.02\n0.09\n0.00\n0.00\n0.00\n0.76\n0.40\n1.60\n8.57\n43747\np\n\n\n\n\n5934 rows × 16 columns\n\n\n\n\n# assign the correct data types to the columns\ncoop = coop.astype({col: float for col in coop.columns[1:-2]})\ncoop = coop.astype({col: int for col in coop.columns[:1]})\ncoop = coop.astype({col: int for col in coop.columns[-2:-1]})\n\n\n# merge the COOP names with COOP data\ncoop = coop.merge(coopNames, left_on='COOP_ID', right_on='COOP_ID')\n\n\n# assign percipitation and temperature data to separate dataframes\ncoopT = coop[coop['type'] == 't']\ncoopP = coop[coop['type'] == 'p']\n\n\ncoopT.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n\n\n\n\n\n\ncoopP.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n102\n1966\n1.35\n1.40\n1.16\n0.05\n0.07\n0.22\n0.39\n0.19\n0.20\n0.46\n0.83\nNaN\n6.32\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n103\n1967\n1.42\n0.00\n1.03\n3.54\n0.48\n0.06\n0.34\n0.49\n0.82\n0.00\n3.65\n4.23\n16.06\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n104\n1968\n0.58\n0.73\n2.19\n0.85\n0.28\n0.03\n1.88\n0.06\n0.00\n0.05\n0.72\n1.66\n9.03\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n105\n1969\n8.30\n5.67\n1.96\n0.10\n0.43\n0.12\n0.01\n0.00\n0.20\n0.02\n1.85\n0.26\n18.92\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n106\n1970\n0.85\n0.96\n3.95\n1.18\n0.00\n0.03\n0.03\n2.66\n0.08\n0.12\n1.28\n2.66\n13.80\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n\n\n\n\n\n\n# drop the type column from the dataframes\ncoopP = coopP.drop(['type'], axis =1).reset_index(drop = True)\ncoopT = coopT.drop(['type'], axis =1).reset_index(drop = True)\n\n\ncoopT.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n\n\n\n\n\n\ncoopP.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n1.35\n1.40\n1.16\n0.05\n0.07\n0.22\n0.39\n0.19\n0.20\n0.46\n0.83\nNaN\n6.32\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n1\n1967\n1.42\n0.00\n1.03\n3.54\n0.48\n0.06\n0.34\n0.49\n0.82\n0.00\n3.65\n4.23\n16.06\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n2\n1968\n0.58\n0.73\n2.19\n0.85\n0.28\n0.03\n1.88\n0.06\n0.00\n0.05\n0.72\n1.66\n9.03\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n3\n1969\n8.30\n5.67\n1.96\n0.10\n0.43\n0.12\n0.01\n0.00\n0.20\n0.02\n1.85\n0.26\n18.92\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n4\n1970\n0.85\n0.96\n3.95\n1.18\n0.00\n0.03\n0.03\n2.66\n0.08\n0.12\n1.28\n2.66\n13.80\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n\n\n\n\n\n\n# group the data by year and calculate the average temperature and precipitation\ncoopTavg = coopT.groupby(['YEAR(S)'])[['ANN']].mean()\ncoopPavg = coopP.groupby(['YEAR(S)'])[['ANN']].mean()\n\n\ncoopPavg.head()\n\n\n\n\n\n\n\n\nANN\n\n\nYEAR(S)\n\n\n\n\n\n1966\n13.723684\n\n\n1967\n18.576316\n\n\n1968\n13.371930\n\n\n1969\n24.774386\n\n\n1970\n19.625789\n\n\n\n\n\n\n\n\n\ncoopTavg.head()\n\n\n\n\n\n\n\n\nANN\n\n\nYEAR(S)\n\n\n\n\n\n1966\n59.034815\n\n\n1967\n58.699091\n\n\n1968\n58.755893\n\n\n1969\n58.758750\n\n\n1970\n59.136316\n\n\n\n\n\n\n\n\n\n\nThe flowerDataFrame function processes and filters occurrence data for a specified plant species in California, returning a clean, structured DataFrame with relevant details such as geographic coordinates, flowering dates, and native status.\n\n\nFlowering Data Function\ndef flowerDataFrame(name, isNative):\n    '''\n    Returns a dataframe of the species data for a specific species in California\n\n    @param name: a string of the name of the species that you want to obtain data for\n    @param isNative: a string stating whether the species is native to california or not\n    '''\n    # Load csv of the species data into a pandas dataframe\n    df = pd.read_csv(f\"./data/{name}/occurrence.txt\", sep='\\t', low_memory=False)\n    #take only specific columns from the bigger dataframe\n    df = df[['scientificName', 'decimalLongitude', 'decimalLatitude', 'day', 'month', 'year', 'stateProvince', 'countryCode']]\n\n    #add a column stating if it is native or not\n    df['native'] = isNative\n\n    #make new column that will drop any unnecessary abbreviations at the end of each name of observation\n    df['species'] = df['scientificName'].str[:len(name)]\n    #make sure dataframe only includes desired species\n    df = df[df['species'] == name]\n    #drop now unused column\n    df = df.drop(['scientificName'], axis=1)\n\n    #make sure dataframe only includes observations from Califronia\n    df = df[(df['countryCode'] == \"US\")]\n    df = df[(df['stateProvince'] == \"California\") | (df['stateProvince'] == \"Ca\")]\n    df = df[df['decimalLongitude'] &gt; -125]\n    df = df[df['decimalLongitude'] &lt; -113]\n    #drop because we know all measurements in entire dataset are in california\n    df = df.drop(['stateProvince'], axis=1)\n    df = df.drop(['countryCode'], axis=1)\n    df = df.dropna()\n    df = df.reset_index(drop=True)\n    \n    #add column called day of year\n    df[list([\"day\", \"month\", \"year\"])] = df[list([\"day\", \"month\", \"year\"])].astype(int)\n    df[list([\"day\", \"month\", \"year\"])] = df[list([\"day\", \"month\", \"year\"])].astype(str)\n    \n    df['month'] = df['month'].apply(lambda x: '{0:0&gt;2}'.format(x))\n    df['day'] = df['day'].apply(lambda x: '{0:0&gt;2}'.format(x))\n    \n    df[\"DOY\"] = df[\"year\"].copy()\n    month = df[\"month\"].copy()\n    day = df[\"day\"].copy()\n    \n    df[\"DOY\"] = df[\"DOY\"].str.cat((month, day), sep =\"-\")\n    df['DOY'] = pd.to_datetime(df['DOY'], format='%Y-%m-%d')\n    df['DOY'] = df['DOY'].dt.dayofyear\n\n    #convert months and years into ints instead of floats \n    df[list([\"year\"])] = df[list([\"year\"])].astype(int)\n    \n    #make sure occurances are of from 1920-2020\n    df = df[df['year'] &gt; 1919]\n    df = df[df['year'] &lt; 2021]\n    df = df.reset_index(drop = True)\n    \n    #give columns more readable names\n    df = df.rename(columns={'decimalLongitude': 'longitude',\n                            'decimalLatitude':  'latitude'})\n    #keep latitude rounding same as eventual climate data\n    df.longitude = df.longitude.round(3)\n    df.latitude = df.latitude.round(3)\n\n    \n    return df\n\n\n\n#native plants\nlasCal = flowerDataFrame('Lasthenia californica', 'yes')\nplntgo = flowerDataFrame(\"Plantago erecta Morris\", 'yes')\nclrkiP = flowerDataFrame(\"Clarkia purpurea\", 'yes')\nclrkiB = flowerDataFrame(\"Clarkia bottae\", 'yes')\nchaenc = flowerDataFrame(\"Chaenactis glabriuscula\", 'yes')\namsink = flowerDataFrame(\"Amsinckia menziesii\", 'yes')\n\n#non-native\nmdcgoP = flowerDataFrame(\"Medicago polymorpha\", 'no')\ncntrea = flowerDataFrame(\"Centaurea solstitialis\", 'no')\nbrssTG = flowerDataFrame(\"Brassica tournefortii Gouan\", 'no')\n\n\n#concat all species dataframes into one big one\nflowersCA = pd.concat([lasCal, plntgo, clrkiP, clrkiB, chaenc, amsink,\n                       mdcgoP, cntrea, brssTG])\n#convert into geodataframe to be easily compared wihtin shape files in the future\nflowersCA = gpd.GeoDataFrame(flowersCA, geometry=gpd.points_from_xy(flowersCA.longitude, flowersCA.latitude))\n\n\n\n\nBelow I take a shape file from from NOAAs database, and determine which climate divisions each observation falls under.\n\n# from NOAAs shapefile, find useful columns and determine which are within CA\nclimateDivs = gpd.read_file(\"./data/climateDiv/GIS.OFFICIAL_CLIM_DIVISIONS.shp\")\nclimateDivs = climateDivs[climateDivs[\"ST_ABBRV\"] == 'CA']\nclimateDivs = climateDivs[[\"CD_NEW\", 'geometry']]\n\n\n# set both coordinate reference systems to be the same so the dataframes are accurately compared\nclimateDivs = climateDivs.set_crs(\"EPSG:4326\", allow_override=True)\nflowersCA = flowersCA.set_crs(\"EPSG:4326\")\n\n\n# this will join the two datasets based on if flowering observation\n# geometry points are within the climate division shapefiles, \n# and add a column within each observation of said Climate Divsion\nflowersCA = gpd.sjoin(flowersCA, climateDivs, how='inner', predicate='within')\nflowersCA = flowersCA.drop(['index_right'], axis = 1)\nflowersCA = flowersCA.reset_index(drop = True)\nflowersCA = flowersCA.rename(columns={'CD_NEW' : 'ClimateDivision'})\nflowersCA = flowersCA[flowersCA['year']&gt;=1966]\nflowersCA = flowersCA[flowersCA['year']&lt;=2016]\n# write only necessary info to csv for quick web parsing\nflowersCA.to_csv('./data/flowersCA.csv')\n\n\n# group the data by species, year, native status, and climate division, and calculate the average day of year that the species flowers\navgPhenologyDiv = flowersCA.groupby(['species', 'year', 'native', 'ClimateDivision'])[[\"DOY\"]].mean().reset_index().round(0)\navgPhenologyDiv\n\n\n\n\n\n\n\n\nspecies\nyear\nnative\nClimateDivision\nDOY\n\n\n\n\n0\nAmsinckia menziesii\n1966\nyes\n4\n119.0\n\n\n1\nAmsinckia menziesii\n1966\nyes\n5\n90.0\n\n\n2\nAmsinckia menziesii\n1966\nyes\n6\n114.0\n\n\n3\nAmsinckia menziesii\n1967\nyes\n4\n125.0\n\n\n4\nAmsinckia menziesii\n1967\nyes\n5\n93.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n1497\nPlantago erecta Morris\n2016\nyes\n1\n115.0\n\n\n1498\nPlantago erecta Morris\n2016\nyes\n2\n99.0\n\n\n1499\nPlantago erecta Morris\n2016\nyes\n4\n87.0\n\n\n1500\nPlantago erecta Morris\n2016\nyes\n5\n80.0\n\n\n1501\nPlantago erecta Morris\n2016\nyes\n6\n93.0\n\n\n\n\n1502 rows × 5 columns\n\n\n\n\n\n\nNow I will employ linear regression models to evaluate the relationship between flowering phenology and climate variables (temperature and precipitation), identifying significant correlations and trends across species, regions, and time. My code calculates statistics of the state, Southern California itself, and climate division 6 to view the relationship between flowering phenology and climate variables (temperature and precipitation) using linear regression:\n\nData Preparation: For each species, the average annual temperature, precipitation, and flowering day-of-year (DOY) are grouped by year and filtered to ensure overlapping years.\nRegression Analysis: Linear regression models are applied separately to assess the relationship between DOY and temperature, as well as DOY and precipitation.\nResults Compilation: The species name, p-values, R-squared, and adjusted R-squared values for both models are stored in a summary DataFrame (stateSum).\nSignificant Results: If the regression p-values indicate statistical significance, the corresponding data for temperature or precipitation is labeled, augmented with species and region information, and added to a significant results DataFrame (sigSum).\n\n\n# create a dictionary to store unique species names\nflowD = {}\nfor i in range(len(avgPhenologyDiv.species.unique())):\n    flowD[i] = avgPhenologyDiv.species.unique()[i]\n\n\n# create a dictionary to store species with significant p-values\nsigSum = pd.DataFrame([])\n\n# set significance level\npval = .05\n\n\n\nState Wide Summary Data\n# create a dictionary to store the state summary data\ndstate = {}\n# iterate over the unique species and calculate the linear regression for each species\nstateSum = pd.DataFrame([])\nfor i in range(len(flowD)):\n    \n    # filter the data to only include the species of interest\n    avgF = avgPhenologyDiv[avgPhenologyDiv['species'] == flowD[i]]\n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data \n    xTy = list(xT['YEAR(S)'])\n    xPy = list(xP['YEAR(S)'])\n    \n    # create a list of years that are in the flowering data \n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the state summary dataframe\n    stateSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the state summary dataframe\n    stateSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    stateSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    stateSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n    \n    stateSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    stateSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    stateSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'State'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'State'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nstateSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.045038\n0.084\n0.065\n0.530467\n0.009\n-0.013\n\n\n1\nBrassica tournefortii Gouan\n0.656550\n0.005\n-0.018\n0.230165\n0.033\n0.011\n\n\n2\nCentaurea solstitialis\n0.663545\n0.004\n-0.017\n0.447359\n0.012\n-0.009\n\n\n3\nChaenactis glabriuscula\n0.022766\n0.101\n0.083\n0.966052\n0.000\n-0.020\n\n\n4\nClarkia bottae\n0.047639\n0.084\n0.064\n0.084706\n0.065\n0.044\n\n\n5\nClarkia purpurea\n0.030003\n0.093\n0.074\n0.096125\n0.055\n0.036\n\n\n6\nLasthenia californica\n0.226127\n0.030\n0.010\n0.116397\n0.050\n0.030\n\n\n7\nMedicago polymorpha\n0.738173\n0.002\n-0.018\n0.261980\n0.026\n0.006\n\n\n8\nPlantago erecta Morris\n0.097705\n0.055\n0.036\n0.765565\n0.002\n-0.019\n\n\n\n\n\n\n\n\n\nSocal Summary Data\n# create a dictionary to store the south state summary data\nsouSum = pd.DataFrame([])\n\n# iterate over the unique species and calculate the linear regression for each species\nfor i in range(len(flowD)):\n    # filter the data to only include the species of interest in climate divisions 6-9\n    avgF = avgPhenologyDiv[avgPhenologyDiv['ClimateDivision'] &gt;= 6] \n    avgF = avgF[avgF['species'] == flowD[i]]    \n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data\n    xTy = list(xT['YEAR(S)']) \n    xPy = list(xP['YEAR(S)']) \n    # create a list of years that are in the flowering data\n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    \n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the south summary dataframe\n    souSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the south summary dataframe\n    souSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    souSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    souSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n    \n    souSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    souSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    souSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'South'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n        sigSum = pd.concat(dfT)\n        \n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'South'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nsouSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.875755\n0.001\n-0.022\n0.875616\n0.001\n-0.022\n\n\n1\nBrassica tournefortii Gouan\n0.904122\n0.000\n-0.022\n0.404617\n0.016\n-0.007\n\n\n2\nCentaurea solstitialis\n0.702031\n0.004\n-0.024\n0.440332\n0.017\n-0.011\n\n\n3\nChaenactis glabriuscula\n0.115176\n0.050\n0.030\n0.594184\n0.006\n-0.014\n\n\n4\nClarkia bottae\n0.270753\n0.029\n0.006\n0.728577\n0.003\n-0.021\n\n\n5\nClarkia purpurea\n0.336247\n0.019\n-0.001\n0.203625\n0.033\n0.013\n\n\n6\nLasthenia californica\n0.263063\n0.027\n0.006\n0.752329\n0.002\n-0.020\n\n\n7\nMedicago polymorpha\n0.199275\n0.035\n0.014\n0.897705\n0.000\n-0.021\n\n\n8\nPlantago erecta Morris\n0.336801\n0.020\n-0.001\n0.425241\n0.014\n-0.007\n\n\n\n\n\n\n\n\n\nClimate Division 6 Summary Data\n# create a dictionary to store the average flowering days\nflowD = {}\n\n# iterate over the unique species and average flowering days\nfor i in range(len(avgPhenologyDiv.species.unique())):\n    flowD[i] = avgPhenologyDiv.species.unique()[i]\n    \n# create a dataframe to store the significant summary data for climate divisions 6\nsixSum = pd.DataFrame([])\n\n# iterate over the unique species and calculate the linear regression for each species\nfor i in range(len(flowD)):\n    # filter the data to only include the species of interest in climate division 6\n    avgF = avgPhenologyDiv[avgPhenologyDiv['ClimateDivision'] == 6] \n    avgF = avgF[avgF['species'] == flowD[i]]    \n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data\n    xTy = list(xT['YEAR(S)']) \n    xPy = list(xP['YEAR(S)']) \n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    \n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the six summary dataframe\n    sixSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the six summary dataframe\n    sixSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    sixSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    sixSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n\n    sixSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    sixSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    sixSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'Six'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'Six'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nsixSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.804356\n0.001\n-0.022\n0.656283\n0.005\n-0.019\n\n\n1\nBrassica tournefortii Gouan\n0.753239\n0.003\n-0.030\n0.424593\n0.021\n-0.011\n\n\n2\nCentaurea solstitialis\n0.494795\n0.014\n-0.015\n0.483818\n0.015\n-0.014\n\n\n3\nChaenactis glabriuscula\n0.056238\n0.072\n0.053\n0.353304\n0.018\n-0.002\n\n\n4\nClarkia bottae\n0.270753\n0.029\n0.006\n0.728577\n0.003\n-0.021\n\n\n5\nClarkia purpurea\n0.040614\n0.083\n0.064\n0.049008\n0.077\n0.058\n\n\n6\nLasthenia californica\n0.458737\n0.014\n-0.011\n0.461362\n0.014\n-0.011\n\n\n7\nMedicago polymorpha\n0.121612\n0.050\n0.030\n0.987780\n0.000\n-0.021\n\n\n8\nPlantago erecta Morris\n0.362461\n0.018\n-0.003\n0.393343\n0.016\n-0.005\n\n\n\n\n\n\n\n\n\n\n\n\n\nsigSum\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n0\n57.374035\n132.000000\nT\nAmsinckia menziesii\nState\n\n\n1\n57.411930\n105.500000\nT\nAmsinckia menziesii\nState\n\n\n2\n57.764483\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n3\n57.798136\n114.333333\nT\nAmsinckia menziesii\nState\n\n\n4\n57.946538\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n...\n...\n...\n...\n...\n...\n\n\n294\n22.954211\n151.000000\nP\nClarkia purpurea\nSix\n\n\n295\n24.774386\n149.000000\nP\nClarkia purpurea\nSix\n\n\n296\n25.309153\n154.000000\nP\nClarkia purpurea\nSix\n\n\n297\n26.406271\n154.000000\nP\nClarkia purpurea\nSix\n\n\n298\n30.957931\n149.000000\nP\nClarkia purpurea\nSix\n\n\n\n\n299 rows × 5 columns\n\n\n\n\n# filter the significant summary data to each region\nstateSig = sigSum[sigSum['Region'] == 'State']\nsouSig = sigSum[sigSum['Region'] == 'South']\nsixSig = sigSum[sigSum['Region'] == 'Six']\n\n\nstateSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n0\n57.374035\n132.000000\nT\nAmsinckia menziesii\nState\n\n\n1\n57.411930\n105.500000\nT\nAmsinckia menziesii\nState\n\n\n2\n57.764483\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n3\n57.798136\n114.333333\nT\nAmsinckia menziesii\nState\n\n\n4\n57.946538\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n\n\n\n\n\n\nsouSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n\n\n\n\n\n\nsixSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n197\n57.374035\n145.0\nT\nClarkia purpurea\nSix\n\n\n198\n57.411930\n145.0\nT\nClarkia purpurea\nSix\n\n\n199\n57.764483\n140.0\nT\nClarkia purpurea\nSix\n\n\n200\n57.798136\n129.0\nT\nClarkia purpurea\nSix\n\n\n201\n57.946538\n152.0\nT\nClarkia purpurea\nSix\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Temperature for Native Flowers in California\n# set plot size\ng = plt.figure(figsize = [10,8])\n# empty list to store legend\nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(stateSig.Species.unique())):\n    g = sb.regplot(data = stateSig[stateSig['Species'] == stateSig.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{stateSig.Species.unique()[i]}')\n    l.append(red_patch)\ng.set_title(\"Flowering DOY vs Temperature for Native Flowers in California\")\ng.set_xlabel(\"Average Yearly Temperature (F)\", fontsize = 15)\ng.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('stateSigT.png')\n\n\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Temperature for Clarkia Purpurea in CA06\n# set plot size\nh = plt.figure(figsize = [10,8])\n# empty list to store legend \nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# filter the significant summary data to temperature only\nsixSigT = sixSig[sixSig['Type'] == 'T']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(sixSigT.Species.unique())):\n    h = sb.regplot(data = sixSigT[sixSigT['Species'] == sixSigT.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{sixSigT.Species.unique()[i]}')\n    l.append(red_patch)\nh.set_title(\"Flowering DOY vs Temperature for Clarkia Purpurea in CA06\")\nh.set_xlabel(\"Average Yearly Temperature (F)\", fontsize = 15)\nh.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('sixSigT.png')\n\n\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Precipitation for Clarkia Purpurea in CA06\n# set plot size\nh = plt.figure(figsize = [10,8])\n# empty list to store legend\nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# filter the significant summary data to precipitation only\nsixSigP = sixSig[sixSig['Type'] == 'P']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(sixSig.Species.unique())):\n    h = sb.regplot(data = sixSigP[sixSigP['Species'] == sixSigP.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{sixSigP.Species.unique()[i]}')\n    l.append(red_patch)\nh.set_title(\"Flowering DOY vs Precipitation for Clarkia Purpurea in CA06\")\nh.set_xlabel(\"Average Yearly Precipitation (In.)\", fontsize = 15)\nh.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('sixSigP.png')\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis study addressed two key questions: (1) whether average flowering observation dates are influenced by temperature or precipitation changes, and (2) if specific climate zones, like coastal Southern California, exhibit more pronounced phenological shifts compared to statewide trends.\nKey Findings: 1. Temperature and Phenology: Across all species, significant correlations with temperature exhibited negative coefficients, indicating earlier flowering with rising temperatures. For instance, Clarkia bottae blooms ~11 days earlier for every 1°C temperature increase. Over 50 years, California’s average temperature rose by ~1°C, significantly impacting native species.\n\nPrecipitation and Phenology: Significant correlations with precipitation were positive, meaning reduced rainfall led to earlier flowering. Though annual precipitation trends were not statistically significant, extreme events likely influence phenology and destabilize communities.\nRegional Patterns: Statewide, only native species showed significant correlations with temperature. In coastal Southern California (climate division 6), significant responses were observed in Clarkia purpurea and Chaenactis glabriuscula, with Clarkia purpurea being sensitive to both temperature and precipitation.\nNative vs. Invasive Species: Native species were more affected by climate change than invasive species, potentially giving invasives a competitive advantage. Earlier flowering in natives could lead to ecosystem shifts and competitive displacement by invasives.\n\nLimitations and Recommendations: - Limited species count and uneven data distribution across regions and species. - Precipitation analysis could be refined by focusing on seasonal rather than annual totals. - More comprehensive studies are needed, especially with equal representation of native and invasive species.\nImplications: Native species like Clarkia purpurea, critical to ecosystem stability, are highly vulnerable to climate change. Differential impacts across climate divisions necessitate tailored conservation strategies. Without intervention, these shifts could lead to ecosystem reorganization, favoring invasive species and jeopardizing native biodiversity."
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#about",
    "href": "posts/2025-01-26-bloom-shift/index.html#about",
    "title": "Bloom Shift",
    "section": "",
    "text": "Sedgewick Reserve\n\n\nImage credits: UCNRS\n\n\nThis study investigates how climate change influences the flowering phenology of native and invasive Californian annual forbs. Given California’s status as a biodiversity hotspot and the region’s susceptibility to hotter and drier conditions, this research aims to understand how shifts in temperature and precipitation affect plant communities. Specifically, we address two primary questions:\n\nDoes the average flowering observation date correlate with changes in annual temperature or precipitation?\nAre particular climate zones, such as coastal Southern California, experiencing more pronounced phenological shifts compared to the state as a whole?\n\nBy analyzing 50 years of data on nine plant species and correlating it with climate trends, this research seeks to highlight the potential impacts of climate change on native and invasive species, with implications for ecosystem stability and conservation planning.\n\n\n\n\nPhenological Shifts: Investigate if flowering times correlate with changes in temperature and precipitation over time.\nSpatial Analysis: Determine if shifts are more pronounced in certain climate zones, e.g., coastal Southern California.\nConservation Implications: Understand how these changes impact the ecosystem dynamics and inform conservation strategies for native biodiversity.\nFocused on California, a biodiversity hotspot particularly sensitive to climate changes.\nIdentified trends for each species using statistical models (OLS regression) to link phenology with climate trends.\nHighlights differences between native and invasive species in their response to environmental changes.\n\n\n\n\nThe study relies on 50 years of data (1966–2016) on flowering observations for nine Californian annual forb species, including both native and invasive types. This dataset integrates:\n\nFlowering data: Derived from occurrence records supplied, focusing on observations from California.\nClimate data: Compiled from the National Weather Service Cooperative Observer Program (NWS COOP), including annual temperature and precipitation records.\nSpatial data: Uses shapefiles from NOAA to map flowering data to specific climate divisions in California.\nData preprocessing ensured temporal consistency and excluded irrelevant records."
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#import-libraries",
    "href": "posts/2025-01-26-bloom-shift/index.html#import-libraries",
    "title": "Bloom Shift",
    "section": "",
    "text": "Import Modules\n# Import modules\nimport pandas as pd\nimport os\nfrom plotly import express as px\nimport plotly.graph_objects as go\nimport numpy as np\nimport geopandas as gpd\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sb\nimport statsmodels.formula.api as smf\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#climate-data",
    "href": "posts/2025-01-26-bloom-shift/index.html#climate-data",
    "title": "Bloom Shift",
    "section": "",
    "text": "Load Climate Data\n# set the directory to the climate data\ndirectory = './data/climate/'\n\n# create a dictionary to store all files in this directory\nd = {}\n# iterate over files in this directory, add each name of file and its contents into a dictionary\nfor filename in os.listdir(directory):\n        d[filename] = pd.read_csv(f'./data/climate/{filename}', encoding= 'unicode_escape')\ndel d['.DS_Store']\n\n\n\n# iterate over the dictionary and add the COOP_ID and type of data to each dataframe\nmaxMinT = []\nmaxMinP = []\n\nfor key, value in d.items():\n    if key[7:8] == 'p':\n        maxMinP.append(d[key]['YEAR(S)'].min())\n    else:\n        maxMinT.append(d[key]['YEAR(S)'].min())\n    value['COOP_ID'] = key[1:6]\n    value['type'] = key[7:8]\n    d[key] = d[key].loc[:, ~d[key].columns.str.contains('^Unnamed')]\n\nThe National Weather Service (NWS) Cooperative Observer Program (COOP) is a network of daily weather observations taken by more than 8,500 volunteers. Here we import and clean the data to be manipulated in out dataset.\n\n# Create a dataframe with COOP information \ncoopNames = pd.read_csv('./data/Coopnames.csv')\ncoopNames = coopNames.drop([0,1,2]).reset_index(drop=True)\ncoopNames = coopNames[['COOP_ID', 'COOP_NAME', 'DIV', 'LATITUDE', 'LONGITUDE']]\n\n# convert COOP_ID to int\ncoopNames.COOP_ID = coopNames.COOP_ID.astype(int)\n\n\n# merge the COOP information with the climate data\ncoop = pd.concat(d.values(), ignore_index=True)\n\n# filter the data to only include years 1966-2016\ncoop = coop[coop['YEAR(S)']&gt;=1966]\ncoop = coop[coop['YEAR(S)']&lt;=2016]\n\n# drop rows with irrelevant data\ncoop = coop.replace(['-----'], np.nan).reset_index(drop=True)\ncoop = coop.loc[:, ~coop.columns.str.contains('^Unnamed')]\ncoop = coop.drop(['January'], axis =1)\n\n\n\nCOOP Data\ncoop\n\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nt\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nt\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nt\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nt\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nt\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5929\n2012\n0.62\n0.45\n1.73\n1.39\n0.03\n0.00\n0.00\n0.00\n0.00\n0.28\n0.49\n1.90\n4.09\n43747\np\n\n\n5930\n2013\n0.22\n0.48\n0.79\n0.08\n0.17\n0.00\n0.00\n0.00\n0.01\n0.00\n0.33\n0.16\n2.24\n43747\np\n\n\n5931\n2014\n0.30\n1.38\n0.27\n0.35\n0.00\n0.00\n0.00\n0.00\n0.03\n0.00\n0.94\n2.52\n5.79\n43747\np\n\n\n5932\n2015\n0.08\n0.72\n0.02\n0.77\n0.10\n0.00\n0.45\n0.00\n0.00\n0.38\n0.91\n1.40\n4.83\n43747\np\n\n\n5933\n2016\n2.56\n0.58\n1.99\n0.57\n0.02\n0.09\n0.00\n0.00\n0.00\n0.76\n0.40\n1.60\n8.57\n43747\np\n\n\n\n\n5934 rows × 16 columns\n\n\n\n\n# assign the correct data types to the columns\ncoop = coop.astype({col: float for col in coop.columns[1:-2]})\ncoop = coop.astype({col: int for col in coop.columns[:1]})\ncoop = coop.astype({col: int for col in coop.columns[-2:-1]})\n\n\n# merge the COOP names with COOP data\ncoop = coop.merge(coopNames, left_on='COOP_ID', right_on='COOP_ID')\n\n\n# assign percipitation and temperature data to separate dataframes\ncoopT = coop[coop['type'] == 't']\ncoopP = coop[coop['type'] == 'p']\n\n\ncoopT.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n\n\n\n\n\n\ncoopP.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n102\n1966\n1.35\n1.40\n1.16\n0.05\n0.07\n0.22\n0.39\n0.19\n0.20\n0.46\n0.83\nNaN\n6.32\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n103\n1967\n1.42\n0.00\n1.03\n3.54\n0.48\n0.06\n0.34\n0.49\n0.82\n0.00\n3.65\n4.23\n16.06\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n104\n1968\n0.58\n0.73\n2.19\n0.85\n0.28\n0.03\n1.88\n0.06\n0.00\n0.05\n0.72\n1.66\n9.03\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n105\n1969\n8.30\n5.67\n1.96\n0.10\n0.43\n0.12\n0.01\n0.00\n0.20\n0.02\n1.85\n0.26\n18.92\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n106\n1970\n0.85\n0.96\n3.95\n1.18\n0.00\n0.03\n0.03\n2.66\n0.08\n0.12\n1.28\n2.66\n13.80\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n\n\n\n\n\n\n# drop the type column from the dataframes\ncoopP = coopP.drop(['type'], axis =1).reset_index(drop = True)\ncoopT = coopT.drop(['type'], axis =1).reset_index(drop = True)\n\n\ncoopT.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n\n\n\n\n\n\ncoopP.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n1.35\n1.40\n1.16\n0.05\n0.07\n0.22\n0.39\n0.19\n0.20\n0.46\n0.83\nNaN\n6.32\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n1\n1967\n1.42\n0.00\n1.03\n3.54\n0.48\n0.06\n0.34\n0.49\n0.82\n0.00\n3.65\n4.23\n16.06\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n2\n1968\n0.58\n0.73\n2.19\n0.85\n0.28\n0.03\n1.88\n0.06\n0.00\n0.05\n0.72\n1.66\n9.03\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n3\n1969\n8.30\n5.67\n1.96\n0.10\n0.43\n0.12\n0.01\n0.00\n0.20\n0.02\n1.85\n0.26\n18.92\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n4\n1970\n0.85\n0.96\n3.95\n1.18\n0.00\n0.03\n0.03\n2.66\n0.08\n0.12\n1.28\n2.66\n13.80\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n\n\n\n\n\n\n# group the data by year and calculate the average temperature and precipitation\ncoopTavg = coopT.groupby(['YEAR(S)'])[['ANN']].mean()\ncoopPavg = coopP.groupby(['YEAR(S)'])[['ANN']].mean()\n\n\ncoopPavg.head()\n\n\n\n\n\n\n\n\nANN\n\n\nYEAR(S)\n\n\n\n\n\n1966\n13.723684\n\n\n1967\n18.576316\n\n\n1968\n13.371930\n\n\n1969\n24.774386\n\n\n1970\n19.625789\n\n\n\n\n\n\n\n\n\ncoopTavg.head()\n\n\n\n\n\n\n\n\nANN\n\n\nYEAR(S)\n\n\n\n\n\n1966\n59.034815\n\n\n1967\n58.699091\n\n\n1968\n58.755893\n\n\n1969\n58.758750\n\n\n1970\n59.136316"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#flowering-data",
    "href": "posts/2025-01-26-bloom-shift/index.html#flowering-data",
    "title": "Bloom Shift",
    "section": "",
    "text": "The flowerDataFrame function processes and filters occurrence data for a specified plant species in California, returning a clean, structured DataFrame with relevant details such as geographic coordinates, flowering dates, and native status.\n\n\nFlowering Data Function\ndef flowerDataFrame(name, isNative):\n    '''\n    Returns a dataframe of the species data for a specific species in California\n\n    @param name: a string of the name of the species that you want to obtain data for\n    @param isNative: a string stating whether the species is native to california or not\n    '''\n    # Load csv of the species data into a pandas dataframe\n    df = pd.read_csv(f\"./data/{name}/occurrence.txt\", sep='\\t', low_memory=False)\n    #take only specific columns from the bigger dataframe\n    df = df[['scientificName', 'decimalLongitude', 'decimalLatitude', 'day', 'month', 'year', 'stateProvince', 'countryCode']]\n\n    #add a column stating if it is native or not\n    df['native'] = isNative\n\n    #make new column that will drop any unnecessary abbreviations at the end of each name of observation\n    df['species'] = df['scientificName'].str[:len(name)]\n    #make sure dataframe only includes desired species\n    df = df[df['species'] == name]\n    #drop now unused column\n    df = df.drop(['scientificName'], axis=1)\n\n    #make sure dataframe only includes observations from Califronia\n    df = df[(df['countryCode'] == \"US\")]\n    df = df[(df['stateProvince'] == \"California\") | (df['stateProvince'] == \"Ca\")]\n    df = df[df['decimalLongitude'] &gt; -125]\n    df = df[df['decimalLongitude'] &lt; -113]\n    #drop because we know all measurements in entire dataset are in california\n    df = df.drop(['stateProvince'], axis=1)\n    df = df.drop(['countryCode'], axis=1)\n    df = df.dropna()\n    df = df.reset_index(drop=True)\n    \n    #add column called day of year\n    df[list([\"day\", \"month\", \"year\"])] = df[list([\"day\", \"month\", \"year\"])].astype(int)\n    df[list([\"day\", \"month\", \"year\"])] = df[list([\"day\", \"month\", \"year\"])].astype(str)\n    \n    df['month'] = df['month'].apply(lambda x: '{0:0&gt;2}'.format(x))\n    df['day'] = df['day'].apply(lambda x: '{0:0&gt;2}'.format(x))\n    \n    df[\"DOY\"] = df[\"year\"].copy()\n    month = df[\"month\"].copy()\n    day = df[\"day\"].copy()\n    \n    df[\"DOY\"] = df[\"DOY\"].str.cat((month, day), sep =\"-\")\n    df['DOY'] = pd.to_datetime(df['DOY'], format='%Y-%m-%d')\n    df['DOY'] = df['DOY'].dt.dayofyear\n\n    #convert months and years into ints instead of floats \n    df[list([\"year\"])] = df[list([\"year\"])].astype(int)\n    \n    #make sure occurances are of from 1920-2020\n    df = df[df['year'] &gt; 1919]\n    df = df[df['year'] &lt; 2021]\n    df = df.reset_index(drop = True)\n    \n    #give columns more readable names\n    df = df.rename(columns={'decimalLongitude': 'longitude',\n                            'decimalLatitude':  'latitude'})\n    #keep latitude rounding same as eventual climate data\n    df.longitude = df.longitude.round(3)\n    df.latitude = df.latitude.round(3)\n\n    \n    return df\n\n\n\n#native plants\nlasCal = flowerDataFrame('Lasthenia californica', 'yes')\nplntgo = flowerDataFrame(\"Plantago erecta Morris\", 'yes')\nclrkiP = flowerDataFrame(\"Clarkia purpurea\", 'yes')\nclrkiB = flowerDataFrame(\"Clarkia bottae\", 'yes')\nchaenc = flowerDataFrame(\"Chaenactis glabriuscula\", 'yes')\namsink = flowerDataFrame(\"Amsinckia menziesii\", 'yes')\n\n#non-native\nmdcgoP = flowerDataFrame(\"Medicago polymorpha\", 'no')\ncntrea = flowerDataFrame(\"Centaurea solstitialis\", 'no')\nbrssTG = flowerDataFrame(\"Brassica tournefortii Gouan\", 'no')\n\n\n#concat all species dataframes into one big one\nflowersCA = pd.concat([lasCal, plntgo, clrkiP, clrkiB, chaenc, amsink,\n                       mdcgoP, cntrea, brssTG])\n#convert into geodataframe to be easily compared wihtin shape files in the future\nflowersCA = gpd.GeoDataFrame(flowersCA, geometry=gpd.points_from_xy(flowersCA.longitude, flowersCA.latitude))"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#climate-division-wrangling",
    "href": "posts/2025-01-26-bloom-shift/index.html#climate-division-wrangling",
    "title": "Bloom Shift",
    "section": "",
    "text": "Below I take a shape file from from NOAAs database, and determine which climate divisions each observation falls under.\n\n# from NOAAs shapefile, find useful columns and determine which are within CA\nclimateDivs = gpd.read_file(\"./data/climateDiv/GIS.OFFICIAL_CLIM_DIVISIONS.shp\")\nclimateDivs = climateDivs[climateDivs[\"ST_ABBRV\"] == 'CA']\nclimateDivs = climateDivs[[\"CD_NEW\", 'geometry']]\n\n\n# set both coordinate reference systems to be the same so the dataframes are accurately compared\nclimateDivs = climateDivs.set_crs(\"EPSG:4326\", allow_override=True)\nflowersCA = flowersCA.set_crs(\"EPSG:4326\")\n\n\n# this will join the two datasets based on if flowering observation\n# geometry points are within the climate division shapefiles, \n# and add a column within each observation of said Climate Divsion\nflowersCA = gpd.sjoin(flowersCA, climateDivs, how='inner', predicate='within')\nflowersCA = flowersCA.drop(['index_right'], axis = 1)\nflowersCA = flowersCA.reset_index(drop = True)\nflowersCA = flowersCA.rename(columns={'CD_NEW' : 'ClimateDivision'})\nflowersCA = flowersCA[flowersCA['year']&gt;=1966]\nflowersCA = flowersCA[flowersCA['year']&lt;=2016]\n# write only necessary info to csv for quick web parsing\nflowersCA.to_csv('./data/flowersCA.csv')\n\n\n# group the data by species, year, native status, and climate division, and calculate the average day of year that the species flowers\navgPhenologyDiv = flowersCA.groupby(['species', 'year', 'native', 'ClimateDivision'])[[\"DOY\"]].mean().reset_index().round(0)\navgPhenologyDiv\n\n\n\n\n\n\n\n\nspecies\nyear\nnative\nClimateDivision\nDOY\n\n\n\n\n0\nAmsinckia menziesii\n1966\nyes\n4\n119.0\n\n\n1\nAmsinckia menziesii\n1966\nyes\n5\n90.0\n\n\n2\nAmsinckia menziesii\n1966\nyes\n6\n114.0\n\n\n3\nAmsinckia menziesii\n1967\nyes\n4\n125.0\n\n\n4\nAmsinckia menziesii\n1967\nyes\n5\n93.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n1497\nPlantago erecta Morris\n2016\nyes\n1\n115.0\n\n\n1498\nPlantago erecta Morris\n2016\nyes\n2\n99.0\n\n\n1499\nPlantago erecta Morris\n2016\nyes\n4\n87.0\n\n\n1500\nPlantago erecta Morris\n2016\nyes\n5\n80.0\n\n\n1501\nPlantago erecta Morris\n2016\nyes\n6\n93.0\n\n\n\n\n1502 rows × 5 columns"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#statistical-analysis",
    "href": "posts/2025-01-26-bloom-shift/index.html#statistical-analysis",
    "title": "Bloom Shift",
    "section": "",
    "text": "Now I will employ linear regression models to evaluate the relationship between flowering phenology and climate variables (temperature and precipitation), identifying significant correlations and trends across species, regions, and time. My code calculates statistics of the state, Southern California itself, and climate division 6 to view the relationship between flowering phenology and climate variables (temperature and precipitation) using linear regression:\n\nData Preparation: For each species, the average annual temperature, precipitation, and flowering day-of-year (DOY) are grouped by year and filtered to ensure overlapping years.\nRegression Analysis: Linear regression models are applied separately to assess the relationship between DOY and temperature, as well as DOY and precipitation.\nResults Compilation: The species name, p-values, R-squared, and adjusted R-squared values for both models are stored in a summary DataFrame (stateSum).\nSignificant Results: If the regression p-values indicate statistical significance, the corresponding data for temperature or precipitation is labeled, augmented with species and region information, and added to a significant results DataFrame (sigSum).\n\n\n# create a dictionary to store unique species names\nflowD = {}\nfor i in range(len(avgPhenologyDiv.species.unique())):\n    flowD[i] = avgPhenologyDiv.species.unique()[i]\n\n\n# create a dictionary to store species with significant p-values\nsigSum = pd.DataFrame([])\n\n# set significance level\npval = .05\n\n\n\nState Wide Summary Data\n# create a dictionary to store the state summary data\ndstate = {}\n# iterate over the unique species and calculate the linear regression for each species\nstateSum = pd.DataFrame([])\nfor i in range(len(flowD)):\n    \n    # filter the data to only include the species of interest\n    avgF = avgPhenologyDiv[avgPhenologyDiv['species'] == flowD[i]]\n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data \n    xTy = list(xT['YEAR(S)'])\n    xPy = list(xP['YEAR(S)'])\n    \n    # create a list of years that are in the flowering data \n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the state summary dataframe\n    stateSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the state summary dataframe\n    stateSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    stateSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    stateSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n    \n    stateSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    stateSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    stateSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'State'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'State'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nstateSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.045038\n0.084\n0.065\n0.530467\n0.009\n-0.013\n\n\n1\nBrassica tournefortii Gouan\n0.656550\n0.005\n-0.018\n0.230165\n0.033\n0.011\n\n\n2\nCentaurea solstitialis\n0.663545\n0.004\n-0.017\n0.447359\n0.012\n-0.009\n\n\n3\nChaenactis glabriuscula\n0.022766\n0.101\n0.083\n0.966052\n0.000\n-0.020\n\n\n4\nClarkia bottae\n0.047639\n0.084\n0.064\n0.084706\n0.065\n0.044\n\n\n5\nClarkia purpurea\n0.030003\n0.093\n0.074\n0.096125\n0.055\n0.036\n\n\n6\nLasthenia californica\n0.226127\n0.030\n0.010\n0.116397\n0.050\n0.030\n\n\n7\nMedicago polymorpha\n0.738173\n0.002\n-0.018\n0.261980\n0.026\n0.006\n\n\n8\nPlantago erecta Morris\n0.097705\n0.055\n0.036\n0.765565\n0.002\n-0.019\n\n\n\n\n\n\n\n\n\nSocal Summary Data\n# create a dictionary to store the south state summary data\nsouSum = pd.DataFrame([])\n\n# iterate over the unique species and calculate the linear regression for each species\nfor i in range(len(flowD)):\n    # filter the data to only include the species of interest in climate divisions 6-9\n    avgF = avgPhenologyDiv[avgPhenologyDiv['ClimateDivision'] &gt;= 6] \n    avgF = avgF[avgF['species'] == flowD[i]]    \n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data\n    xTy = list(xT['YEAR(S)']) \n    xPy = list(xP['YEAR(S)']) \n    # create a list of years that are in the flowering data\n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    \n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the south summary dataframe\n    souSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the south summary dataframe\n    souSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    souSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    souSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n    \n    souSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    souSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    souSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'South'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n        sigSum = pd.concat(dfT)\n        \n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'South'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nsouSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.875755\n0.001\n-0.022\n0.875616\n0.001\n-0.022\n\n\n1\nBrassica tournefortii Gouan\n0.904122\n0.000\n-0.022\n0.404617\n0.016\n-0.007\n\n\n2\nCentaurea solstitialis\n0.702031\n0.004\n-0.024\n0.440332\n0.017\n-0.011\n\n\n3\nChaenactis glabriuscula\n0.115176\n0.050\n0.030\n0.594184\n0.006\n-0.014\n\n\n4\nClarkia bottae\n0.270753\n0.029\n0.006\n0.728577\n0.003\n-0.021\n\n\n5\nClarkia purpurea\n0.336247\n0.019\n-0.001\n0.203625\n0.033\n0.013\n\n\n6\nLasthenia californica\n0.263063\n0.027\n0.006\n0.752329\n0.002\n-0.020\n\n\n7\nMedicago polymorpha\n0.199275\n0.035\n0.014\n0.897705\n0.000\n-0.021\n\n\n8\nPlantago erecta Morris\n0.336801\n0.020\n-0.001\n0.425241\n0.014\n-0.007\n\n\n\n\n\n\n\n\n\nClimate Division 6 Summary Data\n# create a dictionary to store the average flowering days\nflowD = {}\n\n# iterate over the unique species and average flowering days\nfor i in range(len(avgPhenologyDiv.species.unique())):\n    flowD[i] = avgPhenologyDiv.species.unique()[i]\n    \n# create a dataframe to store the significant summary data for climate divisions 6\nsixSum = pd.DataFrame([])\n\n# iterate over the unique species and calculate the linear regression for each species\nfor i in range(len(flowD)):\n    # filter the data to only include the species of interest in climate division 6\n    avgF = avgPhenologyDiv[avgPhenologyDiv['ClimateDivision'] == 6] \n    avgF = avgF[avgF['species'] == flowD[i]]    \n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data\n    xTy = list(xT['YEAR(S)']) \n    xPy = list(xP['YEAR(S)']) \n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    \n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the six summary dataframe\n    sixSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the six summary dataframe\n    sixSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    sixSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    sixSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n\n    sixSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    sixSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    sixSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'Six'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'Six'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nsixSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.804356\n0.001\n-0.022\n0.656283\n0.005\n-0.019\n\n\n1\nBrassica tournefortii Gouan\n0.753239\n0.003\n-0.030\n0.424593\n0.021\n-0.011\n\n\n2\nCentaurea solstitialis\n0.494795\n0.014\n-0.015\n0.483818\n0.015\n-0.014\n\n\n3\nChaenactis glabriuscula\n0.056238\n0.072\n0.053\n0.353304\n0.018\n-0.002\n\n\n4\nClarkia bottae\n0.270753\n0.029\n0.006\n0.728577\n0.003\n-0.021\n\n\n5\nClarkia purpurea\n0.040614\n0.083\n0.064\n0.049008\n0.077\n0.058\n\n\n6\nLasthenia californica\n0.458737\n0.014\n-0.011\n0.461362\n0.014\n-0.011\n\n\n7\nMedicago polymorpha\n0.121612\n0.050\n0.030\n0.987780\n0.000\n-0.021\n\n\n8\nPlantago erecta Morris\n0.362461\n0.018\n-0.003\n0.393343\n0.016\n-0.005"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#visualize-summary-statistics",
    "href": "posts/2025-01-26-bloom-shift/index.html#visualize-summary-statistics",
    "title": "Bloom Shift",
    "section": "",
    "text": "sigSum\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n0\n57.374035\n132.000000\nT\nAmsinckia menziesii\nState\n\n\n1\n57.411930\n105.500000\nT\nAmsinckia menziesii\nState\n\n\n2\n57.764483\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n3\n57.798136\n114.333333\nT\nAmsinckia menziesii\nState\n\n\n4\n57.946538\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n...\n...\n...\n...\n...\n...\n\n\n294\n22.954211\n151.000000\nP\nClarkia purpurea\nSix\n\n\n295\n24.774386\n149.000000\nP\nClarkia purpurea\nSix\n\n\n296\n25.309153\n154.000000\nP\nClarkia purpurea\nSix\n\n\n297\n26.406271\n154.000000\nP\nClarkia purpurea\nSix\n\n\n298\n30.957931\n149.000000\nP\nClarkia purpurea\nSix\n\n\n\n\n299 rows × 5 columns\n\n\n\n\n# filter the significant summary data to each region\nstateSig = sigSum[sigSum['Region'] == 'State']\nsouSig = sigSum[sigSum['Region'] == 'South']\nsixSig = sigSum[sigSum['Region'] == 'Six']\n\n\nstateSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n0\n57.374035\n132.000000\nT\nAmsinckia menziesii\nState\n\n\n1\n57.411930\n105.500000\nT\nAmsinckia menziesii\nState\n\n\n2\n57.764483\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n3\n57.798136\n114.333333\nT\nAmsinckia menziesii\nState\n\n\n4\n57.946538\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n\n\n\n\n\n\nsouSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n\n\n\n\n\n\nsixSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n197\n57.374035\n145.0\nT\nClarkia purpurea\nSix\n\n\n198\n57.411930\n145.0\nT\nClarkia purpurea\nSix\n\n\n199\n57.764483\n140.0\nT\nClarkia purpurea\nSix\n\n\n200\n57.798136\n129.0\nT\nClarkia purpurea\nSix\n\n\n201\n57.946538\n152.0\nT\nClarkia purpurea\nSix\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Temperature for Native Flowers in California\n# set plot size\ng = plt.figure(figsize = [10,8])\n# empty list to store legend\nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(stateSig.Species.unique())):\n    g = sb.regplot(data = stateSig[stateSig['Species'] == stateSig.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{stateSig.Species.unique()[i]}')\n    l.append(red_patch)\ng.set_title(\"Flowering DOY vs Temperature for Native Flowers in California\")\ng.set_xlabel(\"Average Yearly Temperature (F)\", fontsize = 15)\ng.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('stateSigT.png')\n\n\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Temperature for Clarkia Purpurea in CA06\n# set plot size\nh = plt.figure(figsize = [10,8])\n# empty list to store legend \nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# filter the significant summary data to temperature only\nsixSigT = sixSig[sixSig['Type'] == 'T']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(sixSigT.Species.unique())):\n    h = sb.regplot(data = sixSigT[sixSigT['Species'] == sixSigT.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{sixSigT.Species.unique()[i]}')\n    l.append(red_patch)\nh.set_title(\"Flowering DOY vs Temperature for Clarkia Purpurea in CA06\")\nh.set_xlabel(\"Average Yearly Temperature (F)\", fontsize = 15)\nh.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('sixSigT.png')\n\n\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Precipitation for Clarkia Purpurea in CA06\n# set plot size\nh = plt.figure(figsize = [10,8])\n# empty list to store legend\nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# filter the significant summary data to precipitation only\nsixSigP = sixSig[sixSig['Type'] == 'P']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(sixSig.Species.unique())):\n    h = sb.regplot(data = sixSigP[sixSigP['Species'] == sixSigP.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{sixSigP.Species.unique()[i]}')\n    l.append(red_patch)\nh.set_title(\"Flowering DOY vs Precipitation for Clarkia Purpurea in CA06\")\nh.set_xlabel(\"Average Yearly Precipitation (In.)\", fontsize = 15)\nh.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('sixSigP.png')"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#conclusion-and-discussion",
    "href": "posts/2025-01-26-bloom-shift/index.html#conclusion-and-discussion",
    "title": "Bloom Shift",
    "section": "",
    "text": "This study addressed two key questions: (1) whether average flowering observation dates are influenced by temperature or precipitation changes, and (2) if specific climate zones, like coastal Southern California, exhibit more pronounced phenological shifts compared to statewide trends.\nKey Findings: 1. Temperature and Phenology: Across all species, significant correlations with temperature exhibited negative coefficients, indicating earlier flowering with rising temperatures. For instance, Clarkia bottae blooms ~11 days earlier for every 1°C temperature increase. Over 50 years, California’s average temperature rose by ~1°C, significantly impacting native species.\n\nPrecipitation and Phenology: Significant correlations with precipitation were positive, meaning reduced rainfall led to earlier flowering. Though annual precipitation trends were not statistically significant, extreme events likely influence phenology and destabilize communities.\nRegional Patterns: Statewide, only native species showed significant correlations with temperature. In coastal Southern California (climate division 6), significant responses were observed in Clarkia purpurea and Chaenactis glabriuscula, with Clarkia purpurea being sensitive to both temperature and precipitation.\nNative vs. Invasive Species: Native species were more affected by climate change than invasive species, potentially giving invasives a competitive advantage. Earlier flowering in natives could lead to ecosystem shifts and competitive displacement by invasives.\n\nLimitations and Recommendations: - Limited species count and uneven data distribution across regions and species. - Precipitation analysis could be refined by focusing on seasonal rather than annual totals. - More comprehensive studies are needed, especially with equal representation of native and invasive species.\nImplications: Native species like Clarkia purpurea, critical to ecosystem stability, are highly vulnerable to climate change. Differential impacts across climate divisions necessitate tailored conservation strategies. Without intervention, these shifts could lead to ecosystem reorganization, favoring invasive species and jeopardizing native biodiversity."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Master in Environmental Data Science"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About",
    "section": "",
    "text": "Master in Environmental Data Science"
  },
  {
    "objectID": "about.html#previous-portfolios",
    "href": "about.html#previous-portfolios",
    "title": "About",
    "section": "Previous Portfolios",
    "text": "Previous Portfolios\nPython with Applications"
  },
  {
    "objectID": "posts/2025-03-17-purple/index.html",
    "href": "posts/2025-03-17-purple/index.html",
    "title": "A lack of Pisaster may lead to … disaster",
    "section": "",
    "text": "Sea stars and sea urchins play an important role in ocean ecosystems. Sea stars are generally population controllers. Purple sea stars (Pisaster ochraceus) in particular control sea snail, mussel, and urchin populations which allows other species, such as barnacles and algae, to thrive with adequate resources. Additionally, algae provide habitat and food for a plethora of other species - species such as the pacific purple sea urchin (Strongylocentrotus purpuratus), who are herbivores that graze on algae. In addition to algae, urchins will passively wait for detritus (kelp fragments) to float their way. However, in times of scarcity, urchins will hunt kelp forests to feed on.\nKelp forests are essential for ocean health. They provide food, shelter, and other protections for marine life. Additionally, they are an important resource in economic and commercial opportunities explored by humans. As such, maintaining kelp forest health is pertinent to protect the ocean.\nWithout sea stars, urchins may overgraze kelp. Urchins tend to feed on the “holdfast”, or base root like structure of the kelp. When grazing is focused on the holdfast, kelp forests can be quickly and systematically decimated, as without any anchor, the kelp will be swept away from the current. With urchin overgrazing, “urchin barrens” are created, reducing a thriving ecosystem to a excess of urchins and algae that cover the ocean floor.\nWith that in mind, I explored intertidal observations of the Pacific purple sea urchin and purple sea stars with the goal of diving more into the emperical relationship between these two sea species. I chose these observations to answer the question:\nHow do Purple Sea Stars and Purple Urchins interact, and what impact do environmental changes and conservation efforts have on their populations?\n\n\n\n\n  \n\n\n\n\nWhen I was younger I watched alot of TV, specifically Spongebob. The show always filled me with wonder thinking of all the sea life out there. I wanted to expand on that same feeling it gave me but present it in a more educational format.\nAs such, all aesthetic choices were borrowed from the TV show. The title and plot fonts are a recreation of the font seen on the show. When choosing the smaller text, I wanted to keep the same fun, easygoing flow with increase legibility, so I found a more subdued version of that same font. The colors are directly taken from stills that I found particularly pleasing. I did consciously choose colors that would translate well to individuals with color vision deficiencies but still retain the relaxed and fun atmosphere that Spongebob had in every episode. Similarly, an alt text was added to the entire inforgraphic to support individuals who are blind or have visual impairments.\nTo have the overall design fit the theme, I broke up the main question into three separate subquestions:\n\nHow do these two species spatially interact?\n\nTo illustrate the geographic relationship between the Pacific purple sea urchin and the purple sea star, I created a geographic scatter plot from the obserations data. By grouping the region (North, Central, South) and species variables, I calculated the centroids of the locations by year. This gave me a dataframe of all locations, which I then overlayed on a shapefile of California and exported all years into a .gif to see the movement over time.\n\nHave the total abundances changed over time?\n\nFor my second visualization, I used a the overall abundances over 5 binned year ranges to gauge the general trends in which the species populations have fluctuated in the past twenty years.\n\nDo environmental regulations provide protections for a more balanced ecosystem\n\nTo answer this question, I grouped the species by MPA status, and created a relative abundance plot. The goal of this visualization was to envision how populations fluctuate relative to each other depending on if they are in protected waters or not.\nThough these questions are not explicitly stated within the infographic, this choice was intentional. I found there to be too much text if they were included. I wanted readers to easily guide themselves down the infographic without having to feel like they were learning something. By doing this, I hope the reader will learn through osmosis (ie. sponge-like) and come to conclusions themselves. Additionally, I added small paragraphs to add context to each visualizations with key words. These key words were provided without much context for the reader to continue their own exploration into this subject if they desired to. The overall infographic was meant for more sparking intrigue within the subject, rather than detailing a full analysis.\nThough my infographic is focused on ecological relationships within the sea, it is important to recognize that these are not just data points of animals in a far off land. Fluctuations in sea star and urchin populations affect coastal communities that may rely on the commercial aspect of kelp forests. These especially include as food and income, especially within the growing kelp farming industry. Indigenous communities may have deep cultural ties to kelp forests, such as the Tolowa Dee-ni’ Nation. These flucuations threaten their traditional practices and food security as kelp forests decline. Climate change, an issue that affects us all, may further exacerbates threats to marine habitats and species distributions, which in turn may disproportionately affect marginalized communities with fewer resources to adapt.\n\n\n\n\nSpatial Interaction: Purple sea stars and urchins have shifting geographic distributions over time, with often sea stars and sea urchins remaining in similar locations.\nPopulation Trends: Over the past 20 years, fluctuations in the populations of purple sea stars and urchins indicate an imbalance, with some years seeing a sharp decline in urchin and sea star numbers.\nEnvironmental Protections: Marine Protected Areas (MPAs) show more balanced populations of sea stars and urchins, suggesting that protections can help maintain healthy ecosystems.\n\nThis infographic highlights how the dynamic between purple sea stars and purple sea urchins shapes marine ecosystems, and explores differing scales in which either populations are impacted.\n\n\n\nIf wanting to replicated my code, follow the steps below. Please contact me for any data if you would like to replicate.\nAll graphs, as you will see, were created in R. However the infographic itself was compiled using Affinity Designer 2.\n\n\n\n\nCode\n# Load packages \nlibrary(tidyverse)\nlibrary(here)\nlibrary(sf)\nlibrary(gganimate)\nlibrary(sysfonts)\nlibrary(rnaturalearth)  \nlibrary(rnaturalearthdata)\nlibrary(zoo)\nlibrary(ggimage)\nlibrary(scales)\nlibrary(readxl)\nlibrary(ggtext)\n\n# Load Fonts\nsysfonts::font_add_google(\"Slackey\")\nsysfonts::font_add_google(\"Inter\")\n\n# SpongeBob color palette\n# Define your colors\ncolors &lt;- c(\n  \"Purple\" = \"#56446E\", \n  \"Light Purple\" = \"#C187D4\",\n  \"Blue\" = \"#859ED7\",      \n  \"Gold\" = \"#CEA940\",    \n  \"Pink\" = \"#CB6D75\",    \n  \"Green\" = \"#2A584C\",\n  \"Sand\" = \"#F2F0DF\",\n  \"Black\" = \"#49484D\"\n)\n\n# Custom SpongeBob Theme - without background image\ntheme_spongebob &lt;- function() {\n  theme_minimal(base_size = 14) +\n    theme(\n      text = element_text(family = \"Slackey\", color = colors[\"Black\"]),\n      axis.title = element_text(face = \"bold\"),\n      axis.text = element_text(face = \"italic\"),\n      legend.text = element_text(face = \"bold\"),\n      panel.background = element_blank(),\n      plot.background = element_rect(fill = \"transparent\", color = \"transparent\"),  # Use a color, not an image path\n      panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank(),\n      legend.box.background = element_rect(fill='transparent'),\n      panel.border = element_blank()\n    )\n}\n\n# Read in three excel files from MARINe biodiversity data \npoint_contact_raw &lt;- read_excel(here('data', 'MARINe_biodiversity_data',\n                                     'cbs_data_CA_2023.xlsx'), sheet = 'point_contact_summary_data')\nquadrat_raw &lt;- read_excel(here('data', 'MARINe_biodiversity_data',\n                               'cbs_data_CA_2023.xlsx'), sheet = 'quadrat_summary_data')\nswath_raw &lt;- read_excel(here('data', 'MARINe_biodiversity_data',\n                             'cbs_data_CA_2023.xlsx'), sheet = 'swath_summary_data')\n\n# Read in Dangermond preserve shape file \ndangermond &lt;- read_sf(here('data', 'dangermond_shapefile', 'jldp_boundary.shp'))\n\n# Read in California state boundary \ncalifornia &lt;- spData::us_states %&gt;% \n  filter(NAME == \"California\")\n\n# Clean point_contact dataset \npoint_contact_clean &lt;- point_contact_raw %&gt;% \n  # Remove non-matching columns \n  select(!c('number_of_transect_locations', 'percent_cover')) %&gt;% \n  # Rename num of hits to total count \n  rename(total_count = number_of_hits) %&gt;% \n  # Create new data collection source column \n  mutate(collection_source = \"point contact\") %&gt;% \n  # Remove certain species lumps \n  filter(!species_lump %in% c(\"Rock\", \"Sand\", \"Tar\", \"Blue Green Algae\", \"Red Crust\", \"Diatom\", \"Ceramiales\"))\n\n# Clean quadrat dataset \nquadrat_clean &lt;- quadrat_raw %&gt;% \n  # Remove non-matching columns \n  select(!c('number_of_quadrats_sampled', 'total_area_sampled_m2', 'density_per_m2')) %&gt;% \n  # Create new data collection source column \n  mutate(collection_source = \"quadrat\") %&gt;% \n  # Remove certain species lumps \n  filter(!species_lump %in% c(\"Rock\", \"Sand\", \"Tar\", \"Blue Green Algae\", \"Red Crust\", \"Diatom\", \"Ceramiales\"))\n\n# Clean swath dataset \nswath_clean &lt;- swath_raw %&gt;% \n  # Remove non-matching columns \n  select(!c('number_of_transects_sampled', 'est_swath_area_searched_m2',  'density_per_m2')) %&gt;% \n  # Create new data collection source column \n  mutate(collection_source = \"swath\") %&gt;% \n  # Remove certain species lumps \n  filter(!species_lump %in% c(\"Rock\", \"Sand\", \"Tar\", \"Blue Green Algae\", \"Red Crust\", \"Diatom\", \"Ceramiales\"))\n\n# Merge the 3 dataset together\n\nbiodiv_merge &lt;- bind_rows(point_contact_clean, quadrat_clean, swath_clean) %&gt;% \n  filter(year&lt;2021,\n         year&gt;2000)\n\n# Convert to WGS84 to lat long\ncalifornia &lt;- st_transform(california, crs = 4326)\n\n# Categorize into regions, mpa status, bin years\npurple_df &lt;- biodiv_merge %&gt;% \n  filter(total_count &gt;= 1,\n         species_lump  %in% c(\"Pisaster ochraceus\",\n                              \"Strongylocentrotus purpuratus\"\n         )) %&gt;%  \n  mutate(\n    mpa = case_when(\n      mpa_designation == \"NONE\" ~ FALSE,\n      TRUE ~ TRUE\n    ),\n    region = case_when(\n      latitude &lt;= 34.44 ~ \"South\",\n      latitude &gt; 34.44 & latitude &lt;= 37.82 ~ \"Central\",\n      latitude &gt; 37.82 ~ \"North\"\n    )\n  ) %&gt;% \n  mutate(year_bin = round(year/5) * 5) %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = st_crs(california), remove = FALSE) %&gt;% \n  mutate(region = factor(region, levels = c(\"North\", \"Central\", \"South\")))\n\n# Check that the crs matches \nif(st_crs(california) != st_crs(purple_df)) {\n  stop()\n}\n\n#----------------Relative Abundance-------------\npurple_sum &lt;- purple_df %&gt;% \n  group_by(species_lump, year, mpa) %&gt;% \n  summarise(num_count = sum(total_count)) \n\n# Apply smoothing beforehand\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi = 250)\nsmoothed_data &lt;- purple_sum %&gt;%\n  group_by(species_lump, mpa) %&gt;%\n  mutate(num_count_smooth = predict(loess(num_count ~ year, span = 0.5)))\n\n# Plot the smoothed data\np2 &lt;- ggplot(smoothed_data, aes(x = year, y = num_count_smooth, \n                          fill = factor(species_lump, \n                                        levels = c(\"Strongylocentrotus purpuratus\",\n                                                   \"Pisaster ochraceus\")))) +  \n  facet_wrap(~mpa, \n             labeller = labeller(\n               mpa = c(\"TRUE\" = \"MPAs\", \"FALSE\" = \"non MPAs\" )\n             )) +\n  geom_area(position = \"fill\") +  \n  scale_fill_manual(values = c(\"Pisaster ochraceus\" = \"#56446E\" , \n                               \"Strongylocentrotus purpuratus\" = \"#C187D4\" \n  )) +\n  labs(\n    x = \"Year\",\n    y = \"Relative Abundance\",\n    fill = \"Species\"\n  ) +\n  scale_y_continuous(breaks=c(.5,1), labels = scales::percent) +\n  scale_x_continuous(breaks=c(2001, 2010, 2020)) +\n  coord_flip() +\n  theme_spongebob() +\n  theme(\n    axis.ticks.x = element_line(color = colors[\"Purple\"]),\n    axis.ticks.length = unit(3, \"pt\"),\n    axis.title.y = element_blank(),\n    axis.text = element_text(size=16, margin = margin(8,8,8,8, \"pt\")),\n    axis.title = element_markdown(size = 18, color = colors[\"Black\"], margin = margin(25, 0, 0, 0)),\n    panel.grid.major = element_blank(),\n    legend.position = \"none\", \n    plot.title.position = \"plot\", \n    plot.margin = margin(1, 1, 1, 1, \"cm\"),  # Increased margins\n    panel.spacing = unit(3, \"lines\"),  # Increased panel spacing\n    plot.title = element_markdown(hjust = .5, vjust = 0, size = 22, color = colors[\"Purple\"], \n                              margin = margin(0, 0, 20, 0, \"pt\")),  # Added bottom margin to title\n    plot.subtitle = element_text(hjust = .5, vjust = 0, size = 22, color = colors[\"Green\"],\n                             margin = margin(0, 0, 25, 0, \"pt\")),  # Added bottom margin to subtitle\n    strip.text = element_text(hjust = .5, vjust = 0, size = 18, color = colors[\"Blue\"])\n  ) \n\n#ggsave(filename=here(\"images/rel_abund.png\"), width = 20, height = 16, units = \"cm\", dpi = 300)\n\np2\n\n\n#----------------Latitudenal Shift Map-------------\n# Load California map\ncalifornia &lt;- ne_states(country = \"United States of America\", returnclass = \"sf\") %&gt;% \n  filter(name == \"California\") %&gt;% \n  st_transform(crs = 4326)\n\ncentroids &lt;- purple_df %&gt;%\n  # find average location by region and species\n  group_by(year, region, species_lump) %&gt;%  \n  summarize(lon = mean(longitude, na.rm = TRUE),  \n            lat = mean(latitude, na.rm = TRUE)) %&gt;% \n  ungroup() %&gt;% \n  # interpolate missing data for smooth transitions\n  complete(year, region, species_lump, fill = list(lon = NA, lat = NA)) %&gt;%\n  group_by(region, species_lump) %&gt;% \n  mutate(lon = na.approx(lon, na.rm = FALSE),  \n         lat = na.approx(lat, na.rm = FALSE)) %&gt;%  \n  ungroup()\n\n\n\ncentroids_draft &lt;- centroids \n\n# Uncomment for animation (takes a while)\n\n# p1 &lt;- ggplot() +\n#   # Add California map\n#   geom_sf(data = california, fill = \"#b8dab3\") + \n#   \n#   geom_image(data = centroids_draft %&gt;% \n#                filter(species_lump == \"Strongylocentrotus purpuratus\"),\n#              image = here(\"images\", \"purple-urchin.png\"),\n#              aes(x = lon, y = lat, group = region, color = species_lump), size = .07) + \n#   \n#   geom_image(data = centroids_draft %&gt;%\n#                filter(species_lump == \"Strongylocentrotus purpuratus\"),\n#              image = here(\"images\", \"purple-urchin.png\"),\n#              aes(x = lon, y = lat, group = region), size = .06) +\n#   \n#   geom_image(data = centroids_draft %&gt;% \n#                filter(species_lump == \"Pisaster ochraceus\"),\n#              image = here(\"images\", \"purple-sea-star.png\"),\n#              aes(x = lon, y = lat, color = species_lump, group = region), size = .11) +\n#   \n#   geom_image(data = centroids_draft %&gt;%\n#                filter(species_lump == \"Pisaster ochraceus\"),\n#              image = here(\"images\", \"purple-sea-star.png\"),\n#              aes(x = lon, y = lat, group = region), size = .1) +\n#   \n#   scale_color_manual(values = c(\"Pisaster ochraceus\" = \"#859ED7\", \n#                                 \"Strongylocentrotus purpuratus\" = \"#859ED7\")) +\n#   \n#   \n#   geom_hline(yintercept=34.44, linetype=\"dashed\", color = colors[\"Blue\"]) +\n#   \n#   geom_hline(yintercept=37.82, linetype=\"dashed\", color = colors[\"Blue\"]) +\n#   \n#   annotate(\"text\", x=-122.75, y=39.5, hjust=0, vjust=0, \n#            label = \"North\\nCoast\", \n#            family=\"Slackey\", color=colors[\"Purple\"]) +\n#   annotate(\"text\", x=-120, y=35.5, hjust=0, vjust=0, \n#            label = \"Central\\nCoast\", \n#            family=\"Slackey\", color=colors[\"Purple\"]) +\n#   annotate(\"text\", x=-117.25, y=33, hjust=0, vjust=0, \n#            label = \"South\\nCoast\", \n#            family=\"Slackey\", color=colors[\"Purple\"]) +\n#   \n#   labs(title = \"{frame_time}\") +\n#   theme_spongebob() +\n#   theme(\n#     axis.title = element_blank(),\n#     axis.text = element_blank(),\n#     panel.grid.major = element_blank(),\n#     legend.position = \"none\", \n#     plot.title.position = \"plot\", \n#     plot.title = element_text(hjust = .22, vjust = 0, size = 12, color = colors[\"Purple\"])\n#   ) +\n#   \n#   # Animate over years\n#   transition_time(as.integer(year)) +\n#   ease_aes(\"linear\")\n\n#animate(p1, fps = 20, res = 200, height = 480, width = 480, duration=11, bg = 'transparent')\n#anim_save(here(\"images/distributions.gif\"))\n\n\n# Static example\n\nggplot() +\n  # Add California map\n  geom_sf(data = california, fill = \"#b8dab3\") + \n  \n  geom_image(data = centroids_draft %&gt;% \n               filter(year==2016) %&gt;% \n               filter(species_lump == \"Strongylocentrotus purpuratus\"),\n             image = here(\"images\", \"purple-urchin.png\"),\n             aes(x = lon, y = lat, group = region, color = species_lump), size = .07) + \n  \n  geom_image(data = centroids_draft %&gt;%\n               filter(year==2016) %&gt;% \n               filter(species_lump == \"Strongylocentrotus purpuratus\"),\n             image = here(\"images\", \"purple-urchin.png\"),\n             aes(x = lon, y = lat, group = region), size = .06) +\n  \n  geom_image(data = centroids_draft %&gt;% \n               filter(year==2016) %&gt;% \n               filter(species_lump == \"Pisaster ochraceus\"),\n             image = here(\"images\", \"purple-sea-star.png\"),\n             aes(x = lon, y = lat, color = species_lump, group = region), size = .11) +\n  \n  geom_image(data = centroids_draft %&gt;%\n               filter(year==2016) %&gt;% \n               filter(species_lump == \"Pisaster ochraceus\"),\n             image = here(\"images\", \"purple-sea-star.png\"),\n             aes(x = lon, y = lat, group = region), size = .1) +\n  \n  scale_color_manual(values = c(\"Pisaster ochraceus\" = \"#859ED7\", \n                                \"Strongylocentrotus purpuratus\" = \"#859ED7\")) +\n  \n  \n  geom_hline(yintercept=34.44, linetype=\"dashed\", color = colors[\"Blue\"]) +\n  \n  geom_hline(yintercept=37.82, linetype=\"dashed\", color = colors[\"Blue\"]) +\n  \n  annotate(\"text\", x=-122.75, y=39.5, hjust=0, vjust=0, \n           label = \"North\\nCoast\", \n           family=\"Slackey\", color=colors[\"Purple\"]) +\n  annotate(\"text\", x=-120, y=35.5, hjust=0, vjust=0, \n           label = \"Central\\nCoast\", \n           family=\"Slackey\", color=colors[\"Purple\"]) +\n  annotate(\"text\", x=-117.25, y=33, hjust=0, vjust=0, \n           label = \"South\\nCoast\", \n           family=\"Slackey\", color=colors[\"Purple\"]) +\n  \n  labs(title = \"{frame_time}\") +\n  theme_spongebob() +\n  theme(\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    panel.grid.major = element_blank(),\n    legend.position = \"none\", \n    plot.title.position = \"plot\", \n    plot.title = element_text(hjust = .22, vjust = 0, size = 12, color = colors[\"Purple\"])\n  )\n\n\n#----------------Absolute Abundace Plot-------------\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi = 250)\n# Compute total_count_sum first using summarise()\npisaster_sum_perc &lt;- purple_df %&gt;%\n  group_by(species_lump, year_bin) %&gt;%\n  summarise(total_count_sum = sum(total_count, na.rm = TRUE), .groups = \"drop\") \n\n\n# Plot with corrected normalized count\np3 &lt;- ggplot(pisaster_sum_perc, aes(x = year_bin, y = total_count_sum, \n                              fill = factor(species_lump, \n                                        levels = c(\"Strongylocentrotus purpuratus\",\n                                                   \"Pisaster ochraceus\")))) +\n  geom_col(position = \"stack\") +  # Dodge to see separate species\n  scale_fill_manual(labels = c(\"Purple Sea Star\", \"Purple Sea Urchin\"),\n                    values = c(\"Pisaster ochraceus\" = \"#56446E\", \n                               \"Strongylocentrotus purpuratus\" = \"#C187D4\"\n  )) +\n  labs(\n    #title = \"&lt;span style='color:#56446E;'&gt;Purple Sea Stars&lt;/span&gt;\n    #&lt;span style='color:#49484D;'&gt;**vs**&lt;/span&gt;\n    #&lt;span style='color:#C187D4;'&gt;Purple Urchins&lt;/span&gt;\n    #&lt;/span&gt;\",\n    #subtitle = \"Populations recover asymetrically after shock\",\n    x = \"Year\",\n    y = \"Total Counts\",\n    fill = \"Species\"\n  ) +\n  coord_flip() +\n  scale_y_continuous(labels = unit_format(unit = \"k\", scale = 1e-3)) +\n  theme_spongebob() +\n  theme(\n    axis.ticks.x = element_line(color = colors[\"Purple\"]),\n    axis.ticks.length = unit(3, \"pt\"),\n    plot.subtitle = element_markdown(hjust=.5, color=colors[\"Green\"]),\n    axis.title.y = element_blank(),\n    axis.title.x = element_text(color=colors[\"Black\"]),\n    legend.position = \"none\",\n    panel.grid.minor = element_blank(),\n    axis.text = element_text(size = 16, color=colors[\"Black\"]),\n    axis.title = element_markdown(size = 18),\n    plot.title = element_markdown(size = 20, face = \"bold\", hjust = .5),\n    theme(aspect.ratio=3/5)\n  ) \n#ggsave(filename=here(\"images/abundance.png\"), width = 17, height = 13, units = \"cm\", dpi = 300)\np3"
  },
  {
    "objectID": "posts/2025-03-17-purple/index.html#introduction",
    "href": "posts/2025-03-17-purple/index.html#introduction",
    "title": "A lack of Pisaster may lead to … disaster",
    "section": "",
    "text": "Sea stars and sea urchins play an important role in ocean ecosystems. Sea stars are generally population controllers. Purple sea stars (Pisaster ochraceus) in particular control sea snail, mussel, and urchin populations which allows other species, such as barnacles and algae, to thrive with adequate resources. Additionally, algae provide habitat and food for a plethora of other species - species such as the pacific purple sea urchin (Strongylocentrotus purpuratus), who are herbivores that graze on algae. In addition to algae, urchins will passively wait for detritus (kelp fragments) to float their way. However, in times of scarcity, urchins will hunt kelp forests to feed on.\nKelp forests are essential for ocean health. They provide food, shelter, and other protections for marine life. Additionally, they are an important resource in economic and commercial opportunities explored by humans. As such, maintaining kelp forest health is pertinent to protect the ocean.\nWithout sea stars, urchins may overgraze kelp. Urchins tend to feed on the “holdfast”, or base root like structure of the kelp. When grazing is focused on the holdfast, kelp forests can be quickly and systematically decimated, as without any anchor, the kelp will be swept away from the current. With urchin overgrazing, “urchin barrens” are created, reducing a thriving ecosystem to a excess of urchins and algae that cover the ocean floor.\nWith that in mind, I explored intertidal observations of the Pacific purple sea urchin and purple sea stars with the goal of diving more into the emperical relationship between these two sea species. I chose these observations to answer the question:\nHow do Purple Sea Stars and Purple Urchins interact, and what impact do environmental changes and conservation efforts have on their populations?"
  },
  {
    "objectID": "posts/2025-03-17-purple/index.html#design-process",
    "href": "posts/2025-03-17-purple/index.html#design-process",
    "title": "A lack of Pisaster may lead to … disaster",
    "section": "",
    "text": "When I was younger I watched alot of TV, specifically Spongebob. The show always filled me with wonder thinking of all the sea life out there. I wanted to expand on that same feeling it gave me but present it in a more educational format.\nAs such, all aesthetic choices were borrowed from the TV show. The title and plot fonts are a recreation of the font seen on the show. When choosing the smaller text, I wanted to keep the same fun, easygoing flow with increase legibility, so I found a more subdued version of that same font. The colors are directly taken from stills that I found particularly pleasing. I did consciously choose colors that would translate well to individuals with color vision deficiencies but still retain the relaxed and fun atmosphere that Spongebob had in every episode. Similarly, an alt text was added to the entire inforgraphic to support individuals who are blind or have visual impairments.\nTo have the overall design fit the theme, I broke up the main question into three separate subquestions:\n\nHow do these two species spatially interact?\n\nTo illustrate the geographic relationship between the Pacific purple sea urchin and the purple sea star, I created a geographic scatter plot from the obserations data. By grouping the region (North, Central, South) and species variables, I calculated the centroids of the locations by year. This gave me a dataframe of all locations, which I then overlayed on a shapefile of California and exported all years into a .gif to see the movement over time.\n\nHave the total abundances changed over time?\n\nFor my second visualization, I used a the overall abundances over 5 binned year ranges to gauge the general trends in which the species populations have fluctuated in the past twenty years.\n\nDo environmental regulations provide protections for a more balanced ecosystem\n\nTo answer this question, I grouped the species by MPA status, and created a relative abundance plot. The goal of this visualization was to envision how populations fluctuate relative to each other depending on if they are in protected waters or not.\nThough these questions are not explicitly stated within the infographic, this choice was intentional. I found there to be too much text if they were included. I wanted readers to easily guide themselves down the infographic without having to feel like they were learning something. By doing this, I hope the reader will learn through osmosis (ie. sponge-like) and come to conclusions themselves. Additionally, I added small paragraphs to add context to each visualizations with key words. These key words were provided without much context for the reader to continue their own exploration into this subject if they desired to. The overall infographic was meant for more sparking intrigue within the subject, rather than detailing a full analysis.\nThough my infographic is focused on ecological relationships within the sea, it is important to recognize that these are not just data points of animals in a far off land. Fluctuations in sea star and urchin populations affect coastal communities that may rely on the commercial aspect of kelp forests. These especially include as food and income, especially within the growing kelp farming industry. Indigenous communities may have deep cultural ties to kelp forests, such as the Tolowa Dee-ni’ Nation. These flucuations threaten their traditional practices and food security as kelp forests decline. Climate change, an issue that affects us all, may further exacerbates threats to marine habitats and species distributions, which in turn may disproportionately affect marginalized communities with fewer resources to adapt."
  },
  {
    "objectID": "posts/2025-03-17-purple/index.html#key-takeaways",
    "href": "posts/2025-03-17-purple/index.html#key-takeaways",
    "title": "A lack of Pisaster may lead to … disaster",
    "section": "",
    "text": "Spatial Interaction: Purple sea stars and urchins have shifting geographic distributions over time, with often sea stars and sea urchins remaining in similar locations.\nPopulation Trends: Over the past 20 years, fluctuations in the populations of purple sea stars and urchins indicate an imbalance, with some years seeing a sharp decline in urchin and sea star numbers.\nEnvironmental Protections: Marine Protected Areas (MPAs) show more balanced populations of sea stars and urchins, suggesting that protections can help maintain healthy ecosystems.\n\nThis infographic highlights how the dynamic between purple sea stars and purple sea urchins shapes marine ecosystems, and explores differing scales in which either populations are impacted."
  },
  {
    "objectID": "posts/2025-03-17-purple/index.html#code-replication",
    "href": "posts/2025-03-17-purple/index.html#code-replication",
    "title": "A lack of Pisaster may lead to … disaster",
    "section": "",
    "text": "If wanting to replicated my code, follow the steps below. Please contact me for any data if you would like to replicate.\nAll graphs, as you will see, were created in R. However the infographic itself was compiled using Affinity Designer 2.\n\n\n\n\nCode\n# Load packages \nlibrary(tidyverse)\nlibrary(here)\nlibrary(sf)\nlibrary(gganimate)\nlibrary(sysfonts)\nlibrary(rnaturalearth)  \nlibrary(rnaturalearthdata)\nlibrary(zoo)\nlibrary(ggimage)\nlibrary(scales)\nlibrary(readxl)\nlibrary(ggtext)\n\n# Load Fonts\nsysfonts::font_add_google(\"Slackey\")\nsysfonts::font_add_google(\"Inter\")\n\n# SpongeBob color palette\n# Define your colors\ncolors &lt;- c(\n  \"Purple\" = \"#56446E\", \n  \"Light Purple\" = \"#C187D4\",\n  \"Blue\" = \"#859ED7\",      \n  \"Gold\" = \"#CEA940\",    \n  \"Pink\" = \"#CB6D75\",    \n  \"Green\" = \"#2A584C\",\n  \"Sand\" = \"#F2F0DF\",\n  \"Black\" = \"#49484D\"\n)\n\n# Custom SpongeBob Theme - without background image\ntheme_spongebob &lt;- function() {\n  theme_minimal(base_size = 14) +\n    theme(\n      text = element_text(family = \"Slackey\", color = colors[\"Black\"]),\n      axis.title = element_text(face = \"bold\"),\n      axis.text = element_text(face = \"italic\"),\n      legend.text = element_text(face = \"bold\"),\n      panel.background = element_blank(),\n      plot.background = element_rect(fill = \"transparent\", color = \"transparent\"),  # Use a color, not an image path\n      panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank(),\n      legend.box.background = element_rect(fill='transparent'),\n      panel.border = element_blank()\n    )\n}\n\n# Read in three excel files from MARINe biodiversity data \npoint_contact_raw &lt;- read_excel(here('data', 'MARINe_biodiversity_data',\n                                     'cbs_data_CA_2023.xlsx'), sheet = 'point_contact_summary_data')\nquadrat_raw &lt;- read_excel(here('data', 'MARINe_biodiversity_data',\n                               'cbs_data_CA_2023.xlsx'), sheet = 'quadrat_summary_data')\nswath_raw &lt;- read_excel(here('data', 'MARINe_biodiversity_data',\n                             'cbs_data_CA_2023.xlsx'), sheet = 'swath_summary_data')\n\n# Read in Dangermond preserve shape file \ndangermond &lt;- read_sf(here('data', 'dangermond_shapefile', 'jldp_boundary.shp'))\n\n# Read in California state boundary \ncalifornia &lt;- spData::us_states %&gt;% \n  filter(NAME == \"California\")\n\n# Clean point_contact dataset \npoint_contact_clean &lt;- point_contact_raw %&gt;% \n  # Remove non-matching columns \n  select(!c('number_of_transect_locations', 'percent_cover')) %&gt;% \n  # Rename num of hits to total count \n  rename(total_count = number_of_hits) %&gt;% \n  # Create new data collection source column \n  mutate(collection_source = \"point contact\") %&gt;% \n  # Remove certain species lumps \n  filter(!species_lump %in% c(\"Rock\", \"Sand\", \"Tar\", \"Blue Green Algae\", \"Red Crust\", \"Diatom\", \"Ceramiales\"))\n\n# Clean quadrat dataset \nquadrat_clean &lt;- quadrat_raw %&gt;% \n  # Remove non-matching columns \n  select(!c('number_of_quadrats_sampled', 'total_area_sampled_m2', 'density_per_m2')) %&gt;% \n  # Create new data collection source column \n  mutate(collection_source = \"quadrat\") %&gt;% \n  # Remove certain species lumps \n  filter(!species_lump %in% c(\"Rock\", \"Sand\", \"Tar\", \"Blue Green Algae\", \"Red Crust\", \"Diatom\", \"Ceramiales\"))\n\n# Clean swath dataset \nswath_clean &lt;- swath_raw %&gt;% \n  # Remove non-matching columns \n  select(!c('number_of_transects_sampled', 'est_swath_area_searched_m2',  'density_per_m2')) %&gt;% \n  # Create new data collection source column \n  mutate(collection_source = \"swath\") %&gt;% \n  # Remove certain species lumps \n  filter(!species_lump %in% c(\"Rock\", \"Sand\", \"Tar\", \"Blue Green Algae\", \"Red Crust\", \"Diatom\", \"Ceramiales\"))\n\n# Merge the 3 dataset together\n\nbiodiv_merge &lt;- bind_rows(point_contact_clean, quadrat_clean, swath_clean) %&gt;% \n  filter(year&lt;2021,\n         year&gt;2000)\n\n# Convert to WGS84 to lat long\ncalifornia &lt;- st_transform(california, crs = 4326)\n\n# Categorize into regions, mpa status, bin years\npurple_df &lt;- biodiv_merge %&gt;% \n  filter(total_count &gt;= 1,\n         species_lump  %in% c(\"Pisaster ochraceus\",\n                              \"Strongylocentrotus purpuratus\"\n         )) %&gt;%  \n  mutate(\n    mpa = case_when(\n      mpa_designation == \"NONE\" ~ FALSE,\n      TRUE ~ TRUE\n    ),\n    region = case_when(\n      latitude &lt;= 34.44 ~ \"South\",\n      latitude &gt; 34.44 & latitude &lt;= 37.82 ~ \"Central\",\n      latitude &gt; 37.82 ~ \"North\"\n    )\n  ) %&gt;% \n  mutate(year_bin = round(year/5) * 5) %&gt;% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"), crs = st_crs(california), remove = FALSE) %&gt;% \n  mutate(region = factor(region, levels = c(\"North\", \"Central\", \"South\")))\n\n# Check that the crs matches \nif(st_crs(california) != st_crs(purple_df)) {\n  stop()\n}\n\n#----------------Relative Abundance-------------\npurple_sum &lt;- purple_df %&gt;% \n  group_by(species_lump, year, mpa) %&gt;% \n  summarise(num_count = sum(total_count)) \n\n# Apply smoothing beforehand\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi = 250)\nsmoothed_data &lt;- purple_sum %&gt;%\n  group_by(species_lump, mpa) %&gt;%\n  mutate(num_count_smooth = predict(loess(num_count ~ year, span = 0.5)))\n\n# Plot the smoothed data\np2 &lt;- ggplot(smoothed_data, aes(x = year, y = num_count_smooth, \n                          fill = factor(species_lump, \n                                        levels = c(\"Strongylocentrotus purpuratus\",\n                                                   \"Pisaster ochraceus\")))) +  \n  facet_wrap(~mpa, \n             labeller = labeller(\n               mpa = c(\"TRUE\" = \"MPAs\", \"FALSE\" = \"non MPAs\" )\n             )) +\n  geom_area(position = \"fill\") +  \n  scale_fill_manual(values = c(\"Pisaster ochraceus\" = \"#56446E\" , \n                               \"Strongylocentrotus purpuratus\" = \"#C187D4\" \n  )) +\n  labs(\n    x = \"Year\",\n    y = \"Relative Abundance\",\n    fill = \"Species\"\n  ) +\n  scale_y_continuous(breaks=c(.5,1), labels = scales::percent) +\n  scale_x_continuous(breaks=c(2001, 2010, 2020)) +\n  coord_flip() +\n  theme_spongebob() +\n  theme(\n    axis.ticks.x = element_line(color = colors[\"Purple\"]),\n    axis.ticks.length = unit(3, \"pt\"),\n    axis.title.y = element_blank(),\n    axis.text = element_text(size=16, margin = margin(8,8,8,8, \"pt\")),\n    axis.title = element_markdown(size = 18, color = colors[\"Black\"], margin = margin(25, 0, 0, 0)),\n    panel.grid.major = element_blank(),\n    legend.position = \"none\", \n    plot.title.position = \"plot\", \n    plot.margin = margin(1, 1, 1, 1, \"cm\"),  # Increased margins\n    panel.spacing = unit(3, \"lines\"),  # Increased panel spacing\n    plot.title = element_markdown(hjust = .5, vjust = 0, size = 22, color = colors[\"Purple\"], \n                              margin = margin(0, 0, 20, 0, \"pt\")),  # Added bottom margin to title\n    plot.subtitle = element_text(hjust = .5, vjust = 0, size = 22, color = colors[\"Green\"],\n                             margin = margin(0, 0, 25, 0, \"pt\")),  # Added bottom margin to subtitle\n    strip.text = element_text(hjust = .5, vjust = 0, size = 18, color = colors[\"Blue\"])\n  ) \n\n#ggsave(filename=here(\"images/rel_abund.png\"), width = 20, height = 16, units = \"cm\", dpi = 300)\n\np2\n\n\n#----------------Latitudenal Shift Map-------------\n# Load California map\ncalifornia &lt;- ne_states(country = \"United States of America\", returnclass = \"sf\") %&gt;% \n  filter(name == \"California\") %&gt;% \n  st_transform(crs = 4326)\n\ncentroids &lt;- purple_df %&gt;%\n  # find average location by region and species\n  group_by(year, region, species_lump) %&gt;%  \n  summarize(lon = mean(longitude, na.rm = TRUE),  \n            lat = mean(latitude, na.rm = TRUE)) %&gt;% \n  ungroup() %&gt;% \n  # interpolate missing data for smooth transitions\n  complete(year, region, species_lump, fill = list(lon = NA, lat = NA)) %&gt;%\n  group_by(region, species_lump) %&gt;% \n  mutate(lon = na.approx(lon, na.rm = FALSE),  \n         lat = na.approx(lat, na.rm = FALSE)) %&gt;%  \n  ungroup()\n\n\n\ncentroids_draft &lt;- centroids \n\n# Uncomment for animation (takes a while)\n\n# p1 &lt;- ggplot() +\n#   # Add California map\n#   geom_sf(data = california, fill = \"#b8dab3\") + \n#   \n#   geom_image(data = centroids_draft %&gt;% \n#                filter(species_lump == \"Strongylocentrotus purpuratus\"),\n#              image = here(\"images\", \"purple-urchin.png\"),\n#              aes(x = lon, y = lat, group = region, color = species_lump), size = .07) + \n#   \n#   geom_image(data = centroids_draft %&gt;%\n#                filter(species_lump == \"Strongylocentrotus purpuratus\"),\n#              image = here(\"images\", \"purple-urchin.png\"),\n#              aes(x = lon, y = lat, group = region), size = .06) +\n#   \n#   geom_image(data = centroids_draft %&gt;% \n#                filter(species_lump == \"Pisaster ochraceus\"),\n#              image = here(\"images\", \"purple-sea-star.png\"),\n#              aes(x = lon, y = lat, color = species_lump, group = region), size = .11) +\n#   \n#   geom_image(data = centroids_draft %&gt;%\n#                filter(species_lump == \"Pisaster ochraceus\"),\n#              image = here(\"images\", \"purple-sea-star.png\"),\n#              aes(x = lon, y = lat, group = region), size = .1) +\n#   \n#   scale_color_manual(values = c(\"Pisaster ochraceus\" = \"#859ED7\", \n#                                 \"Strongylocentrotus purpuratus\" = \"#859ED7\")) +\n#   \n#   \n#   geom_hline(yintercept=34.44, linetype=\"dashed\", color = colors[\"Blue\"]) +\n#   \n#   geom_hline(yintercept=37.82, linetype=\"dashed\", color = colors[\"Blue\"]) +\n#   \n#   annotate(\"text\", x=-122.75, y=39.5, hjust=0, vjust=0, \n#            label = \"North\\nCoast\", \n#            family=\"Slackey\", color=colors[\"Purple\"]) +\n#   annotate(\"text\", x=-120, y=35.5, hjust=0, vjust=0, \n#            label = \"Central\\nCoast\", \n#            family=\"Slackey\", color=colors[\"Purple\"]) +\n#   annotate(\"text\", x=-117.25, y=33, hjust=0, vjust=0, \n#            label = \"South\\nCoast\", \n#            family=\"Slackey\", color=colors[\"Purple\"]) +\n#   \n#   labs(title = \"{frame_time}\") +\n#   theme_spongebob() +\n#   theme(\n#     axis.title = element_blank(),\n#     axis.text = element_blank(),\n#     panel.grid.major = element_blank(),\n#     legend.position = \"none\", \n#     plot.title.position = \"plot\", \n#     plot.title = element_text(hjust = .22, vjust = 0, size = 12, color = colors[\"Purple\"])\n#   ) +\n#   \n#   # Animate over years\n#   transition_time(as.integer(year)) +\n#   ease_aes(\"linear\")\n\n#animate(p1, fps = 20, res = 200, height = 480, width = 480, duration=11, bg = 'transparent')\n#anim_save(here(\"images/distributions.gif\"))\n\n\n# Static example\n\nggplot() +\n  # Add California map\n  geom_sf(data = california, fill = \"#b8dab3\") + \n  \n  geom_image(data = centroids_draft %&gt;% \n               filter(year==2016) %&gt;% \n               filter(species_lump == \"Strongylocentrotus purpuratus\"),\n             image = here(\"images\", \"purple-urchin.png\"),\n             aes(x = lon, y = lat, group = region, color = species_lump), size = .07) + \n  \n  geom_image(data = centroids_draft %&gt;%\n               filter(year==2016) %&gt;% \n               filter(species_lump == \"Strongylocentrotus purpuratus\"),\n             image = here(\"images\", \"purple-urchin.png\"),\n             aes(x = lon, y = lat, group = region), size = .06) +\n  \n  geom_image(data = centroids_draft %&gt;% \n               filter(year==2016) %&gt;% \n               filter(species_lump == \"Pisaster ochraceus\"),\n             image = here(\"images\", \"purple-sea-star.png\"),\n             aes(x = lon, y = lat, color = species_lump, group = region), size = .11) +\n  \n  geom_image(data = centroids_draft %&gt;%\n               filter(year==2016) %&gt;% \n               filter(species_lump == \"Pisaster ochraceus\"),\n             image = here(\"images\", \"purple-sea-star.png\"),\n             aes(x = lon, y = lat, group = region), size = .1) +\n  \n  scale_color_manual(values = c(\"Pisaster ochraceus\" = \"#859ED7\", \n                                \"Strongylocentrotus purpuratus\" = \"#859ED7\")) +\n  \n  \n  geom_hline(yintercept=34.44, linetype=\"dashed\", color = colors[\"Blue\"]) +\n  \n  geom_hline(yintercept=37.82, linetype=\"dashed\", color = colors[\"Blue\"]) +\n  \n  annotate(\"text\", x=-122.75, y=39.5, hjust=0, vjust=0, \n           label = \"North\\nCoast\", \n           family=\"Slackey\", color=colors[\"Purple\"]) +\n  annotate(\"text\", x=-120, y=35.5, hjust=0, vjust=0, \n           label = \"Central\\nCoast\", \n           family=\"Slackey\", color=colors[\"Purple\"]) +\n  annotate(\"text\", x=-117.25, y=33, hjust=0, vjust=0, \n           label = \"South\\nCoast\", \n           family=\"Slackey\", color=colors[\"Purple\"]) +\n  \n  labs(title = \"{frame_time}\") +\n  theme_spongebob() +\n  theme(\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    panel.grid.major = element_blank(),\n    legend.position = \"none\", \n    plot.title.position = \"plot\", \n    plot.title = element_text(hjust = .22, vjust = 0, size = 12, color = colors[\"Purple\"])\n  )\n\n\n#----------------Absolute Abundace Plot-------------\nshowtext::showtext_auto()\nshowtext::showtext_opts(dpi = 250)\n# Compute total_count_sum first using summarise()\npisaster_sum_perc &lt;- purple_df %&gt;%\n  group_by(species_lump, year_bin) %&gt;%\n  summarise(total_count_sum = sum(total_count, na.rm = TRUE), .groups = \"drop\") \n\n\n# Plot with corrected normalized count\np3 &lt;- ggplot(pisaster_sum_perc, aes(x = year_bin, y = total_count_sum, \n                              fill = factor(species_lump, \n                                        levels = c(\"Strongylocentrotus purpuratus\",\n                                                   \"Pisaster ochraceus\")))) +\n  geom_col(position = \"stack\") +  # Dodge to see separate species\n  scale_fill_manual(labels = c(\"Purple Sea Star\", \"Purple Sea Urchin\"),\n                    values = c(\"Pisaster ochraceus\" = \"#56446E\", \n                               \"Strongylocentrotus purpuratus\" = \"#C187D4\"\n  )) +\n  labs(\n    #title = \"&lt;span style='color:#56446E;'&gt;Purple Sea Stars&lt;/span&gt;\n    #&lt;span style='color:#49484D;'&gt;**vs**&lt;/span&gt;\n    #&lt;span style='color:#C187D4;'&gt;Purple Urchins&lt;/span&gt;\n    #&lt;/span&gt;\",\n    #subtitle = \"Populations recover asymetrically after shock\",\n    x = \"Year\",\n    y = \"Total Counts\",\n    fill = \"Species\"\n  ) +\n  coord_flip() +\n  scale_y_continuous(labels = unit_format(unit = \"k\", scale = 1e-3)) +\n  theme_spongebob() +\n  theme(\n    axis.ticks.x = element_line(color = colors[\"Purple\"]),\n    axis.ticks.length = unit(3, \"pt\"),\n    plot.subtitle = element_markdown(hjust=.5, color=colors[\"Green\"]),\n    axis.title.y = element_blank(),\n    axis.title.x = element_text(color=colors[\"Black\"]),\n    legend.position = \"none\",\n    panel.grid.minor = element_blank(),\n    axis.text = element_text(size = 16, color=colors[\"Black\"]),\n    axis.title = element_markdown(size = 18),\n    plot.title = element_markdown(size = 20, face = \"bold\", hjust = .5),\n    theme(aspect.ratio=3/5)\n  ) \n#ggsave(filename=here(\"images/abundance.png\"), width = 17, height = 13, units = \"cm\", dpi = 300)\np3"
  },
  {
    "objectID": "posts/2025-03-17-purple/index.html#infographic",
    "href": "posts/2025-03-17-purple/index.html#infographic",
    "title": "A lack of Pisaster may lead to … disaster",
    "section": "Infographic",
    "text": "Infographic"
  }
]