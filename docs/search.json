[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog",
    "section": "",
    "text": "Bloom Shift\n\n\n\n\n\n\nIan Morris-Sibaja\n\n\nJan 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nThe Environmental Effects of the 2017 Thomas Fire\n\n\n\n\n\n\nIan Morris-Sibaja\n\n\nDec 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello World!\n\n\n\nQuarto\n\n\nMEDS\n\n\n\nMy first blog\n\n\n\nIMS\n\n\nOct 18, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ian Morris-Sibaja",
    "section": "",
    "text": "Drawing on his research and fieldwork experiences, Ian is now pursuing a Master of Environmental Data Science from the UCSB Bren School. His ultimate goal is to utilize his analytical toolkit to develop data-driven solutions that measure and mediate human impacts on the natural environments of Southern California."
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html",
    "href": "posts/2024-12-13-thomas-fire/index.html",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "Author: Ian Morris-Sibaja\n\n\n Image credits: spookysnoopy via Imgur\n\n\nThis notebook explores the 2017 Thomas Fire, one of California’s largest wildfires, which burned over 280,000 acres across Ventura and Santa Barbara counties, causing extensive environmental damage, including vegetation loss, soil erosion, and increased flood risks. This notebook examines the fire’s impact on air quality using AQI data from the US Environmental Protection Agency and visualizes burn severity and fire scars using false-colored Landsat multispectral geospatial data.\n\n\n\n\nAnalyzed Thomas Fires using AQI and Landsat data, creating time-series maps to explore wildfire impacts\nDeveloped true and false color imagery to highlight fire extent and visualize fire scars alongside perimeter data\nCombined and wrangled date and string data, merging data frames for streamlined analysis\nVisualized time series and polished workflows while manipulating raster and vector data with Rasterio and GeoPandas\nEnsured collaboration and reproducibility through structured workflows and Git version control best practices\n\n\n\n\n\n\nThe U.S. Air Quality Index (AQI), developed by the EPA, communicates outdoor air quality and associated health risks through six color-coded categories, ranging from “Good” (AQI ≤ 50) to “Hazardous” (AQI &gt; 300). AQI values up to 100 indicate satisfactory air quality, aligned with national health standards, while values above 100 signal unhealthy conditions—initially for sensitive groups and eventually for all as pollution levels rise. The color-coded system enables quick identification of air quality concerns in communities.\n\n\n\nThis dataset consists of simplified bands (red, green, blue, near-infrared, and shortwave infrared) from Landsat Collection 2 Level-2 surface reflectance data, which was atmospherically corrected and captured by NASA’s Landsat 8 satellite. It was sourced from the Microsoft Planetary Computer data catalog and preprocessed to exclude non-land areas and reduce spatial resolution for ease of computation.\n\n\n\nThis database contains spatial distribution information of both wild and prescribed fires in California. The data comes with a warning of its incompleteness. Some records were lost or damaged, so fire perimeters may be missing. There may also be duplicate or an over estimation of fire perimeters. The database is maintained by the California Department of Forestry and Fire Protection’s Fire and Resource Assessment Program.\n\n\n\n\nThe full repository can be found here.\n\n\n\n\n\n\nImport Modules\n# Import modules\nimport rioxarray as rioxr\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport os\n\n\n\n\nImport AQI data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\",\n                     compression=\"zip\")\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\",\n                     compression=\"zip\")\n\n\n\n\nImport landsat data\nlandsat_fp = os.path.join(\"data\", \"landsat8-2018-01-26-sb-simplified.nc\")\nlandsat = rioxr.open_rasterio(landsat_fp)\n\n\n\n\nImport Thomas Fire data\nthomas_fp = os.path.join(\"data\", \"thomas_2017.geojson\")\nthomas_2017 = gpd.read_file(thomas_fp)\n\n\n\n\n\n\n\nWe begin this section by excecuting preliminary explorations of our data.\n\n\nView first five rows of 2017 AQI\naqi_17_head\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n\nView first five rows of 2018 AQI\naqi_18_head\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n42\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n45\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2018-01-08\n20\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2018-01-11\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2018-01-14\n33\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n# Compare the differing shapes\nprint(aqi_17.shape, aqi_18.shape)\n# Compare dataframe columns and dtypes\nprint(aqi_17.dtypes == aqi_18.dtypes)\n\n(326801, 10) (327543, 10)\nState Name                   True\ncounty Name                  True\nState Code                   True\nCounty Code                  True\nDate                         True\nAQI                          True\nCategory                     True\nDefining Parameter           True\nDefining Site                True\nNumber of Sites Reporting    True\ndtype: bool\n\n\nWe started by examining the shape and data types of each dataframe to assess their compatibility for comparison. This step is crucial for ensuring the legitimacy of directly analyzing these two datasets together. Lucky for us, the dataframes share identical columns with matching data types. This consistency allows for seamless comparison and concatenation, aiding in our analysis.\n\n\n\nTo aid in our comparisons, we begin by cleaning up our data.\n\n\nConcatenate the two dataframes together\naqi = pd.concat([aqi_17, aqi_18])\naqi\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n327538\nWyoming\nWeston\n56\n45\n2018-12-27\n36\nGood\nOzone\n56-045-0003\n1\n\n\n327539\nWyoming\nWeston\n56\n45\n2018-12-28\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327540\nWyoming\nWeston\n56\n45\n2018-12-29\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327541\nWyoming\nWeston\n56\n45\n2018-12-30\n31\nGood\nOzone\n56-045-0003\n1\n\n\n327542\nWyoming\nWeston\n56\n45\n2018-12-31\n35\nGood\nOzone\n56-045-0003\n1\n\n\n\n\n654344 rows × 10 columns\n\n\n\n\n\nClean column names\n# Initial column names: notice caps and spaces (difficult to work with!)\nprint(aqi.columns, '\\n')\n\n# Simplify column names\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_')\n                )\nprint(aqi.columns, '\\n')\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object') \n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object') \n\n\n\nConcatenating and cleaning our column names help us create a clean dataframe that will aid in filtering. We want to filter for Santa Barbara only and our necessary column names.\n\n\nFilter and clean data\n# Filter AQI to only Santa Barbara\naqi_sb = aqi[aqi[\"county_name\"] == \"Santa Barbara\"]\n# Drop unnecessary columns\naqi_sb = aqi_sb.drop(columns=['state_name', 'county_name', 'state_code', 'county_code'])\n\n# Find data type of date column\ndate_type = aqi_sb[\"date\"].dtype\n# Update the date column to be pd.datetime object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n# Update index to the date column\naqi_sb = aqi_sb.set_index(\"date\")\naqi_sb.sort_index(inplace=True)\n\n\nNow with our data cleaned, we can begin with our analysis. We want to calculate the AQI average over a 5 day rolling window.\n\n# Calculate AQI rolling average over 5 days\nrolling_average = aqi_sb[\"aqi\"].rolling(\"5D\").mean()\n# Add rolling mean to SB dataframe\naqi_sb[\"five_day_average\"] = rolling_average.values\n\nHooray! We have completed our data cleaning and now we have a easy to plot data frame full of rolling average values. All we have left is to…\n\n\n\n\n\nPlot AQI Rolling Average\n# Visualize the AQI data\naqi_sb.plot(kind=\"line\",\n            y=[\"aqi\", \"five_day_average\"],\n            xlabel=\"Date\",\n            ylabel=\"PM 2.5\",\n            label=[\"Daily AQI Level\", \"5-Day Average AQI\"],\n            title=\"Daily and Rolling Average AQI\\nof Santa Barbara County from 2017-18\")\n\n\n\n\n\n\n\n\n\nAs you can see, there is a large spike in PM 2.5 during the same time frame of the Thomas Fire in late 2017. Next, we will visualize the fire scars left by the fire using landsat data and false color imagery.\n\n\n\n\n\n\nWe will examine the dataset to understand its structure. After exploring the data, we will summarize in paragraph form.\n\n# Show preliminary xarrary.Dataset\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\n\n# Show dimensions of dataset \nprint(landsat.dims)\n\nFrozenMappingWarningOnValuesAccess({'band': 1, 'x': 870, 'y': 731})\n\n\n\n# Show CRS of dataset \nprint(landsat.rio.crs)\n\nEPSG:32611\n\n\n\n# Show datatypes of dataset \nprint(landsat.dtypes)\n\nFrozen({'red': dtype('float64'), 'green': dtype('float64'), 'blue': dtype('float64'), 'nir08': dtype('float64'), 'swir22': dtype('float64')})\n\n\n\n\nThis dataset is a 2D dataset with a single band. There are five wavelength ranges captures, red, green, blue, near infrared and short wave infrared. The dataset is of CRS EPSG:32611.\n\n\n\n\nTo ease visualizations, we will simplify the dataset by removing unnecessary dimensions.\n\n\nDrop band dimension of data\nlandsat = landsat.drop_vars(\"band\").squeeze()\n\n\n\n# View updated dataset\nlandsat.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1kB\nDimensions:      (x: 5, y: 5)\nCoordinates:\n  * x            (x) float64 40B 1.213e+05 1.216e+05 ... 1.221e+05 1.224e+05\n  * y            (y) float64 40B 3.952e+06 3.952e+06 ... 3.952e+06 3.951e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (y, x) float64 200B ...\n    green        (y, x) float64 200B ...\n    blue         (y, x) float64 200B ...\n    nir08        (y, x) float64 200B ...\n    swir22       (y, x) float64 200B ...xarray.DatasetDimensions:x: 5y: 5Coordinates: (3)x(x)float641.213e+05 1.216e+05 ... 1.224e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., 122115., 122385.])y(y)float643.952e+06 3.952e+06 ... 3.951e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., 3951585., 3951315.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]green(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]blue(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]nir08(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]swir22(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]Indexes: (2)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0], dtype='float64', name='x'))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0], dtype='float64', name='y'))Attributes: (0)\n\n\n\n\n\nBy extracting the red, green, and blue bands we can begin to create an RGB image.\n\n\nFilter and clean data\n# Filter AQI to only Santa Barbara\naqi_sb = aqi[aqi[\"county_name\"] == \"Santa Barbara\"]\n# Drop unnecessary columns\naqi_sb = aqi_sb.drop(columns=['state_name', 'county_name', 'state_code', 'county_code'])\n\n\nConverting the dataframe to an array will easily allow us to plot using the plot.imshow() method.\n\n# Convert to array\nlandsat[[\"red\", \"green\", \"blue\"]].to_array()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (variable: 3, y: 731, x: 870)&gt; Size: 15MB\narray([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])\nCoordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\n  * variable     (variable) object 24B 'red' 'green' 'blue'xarray.DataArrayvariable: 3y: 731x: 8700.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])Coordinates: (4)x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)variable(variable)object'red' 'green' 'blue'array(['red', 'green', 'blue'], dtype=object)Indexes: (3)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))variablePandasIndexPandasIndex(Index(['red', 'green', 'blue'], dtype='object', name='variable'))Attributes: (0)\n\n\n\n\n\nNow we will plot the RGB data to visualize it as a true color image.\n\n# Visualize with simple plot\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\nWell we did not alter the robust parameter. Let’s set it to True and see what happens!\n\n# Visualize with true color plot\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\nThe output of a) shows a black and white outline of the area we are working with, while b) shows us a more true to color rendering. The robust=True parameter that we added will eliminate any outliers that may alter the data. It uses 2nd and 98th percentiles of the data to compute the color limits.\n\n\n\nTo visualize specific features like vegetation health or fire impacts, we can create false color imagery using the red, near infrared, and short wave infrared bands.\n\n# Visualize with false color plot\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, we can overlay the false color imagery with critical geographical features like the fire perimeters we imported before.\n\n# Compare CRS\nprint(landsat.rio.crs)\nprint(thomas_2017.crs)\n\nEPSG:32611\nEPSG:4326\n\n\n\n\nReproject data\nthomas_2017 = thomas_2017.to_crs(landsat.rio.crs)\nprint('Matched CRS?:',  landsat.rio.crs == thomas_2017.crs)\n\n\nMatched CRS?: True\n\n\n\n\nVisualize Thomas Fire scar\n# Plot of false color raster with buffer overlay\nfig, ax = plt.subplots(figsize=(6, 7))  # Directly set size and aspect\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(\n                robust=True,\n                ax=ax)\nthomas_2017.boundary.plot(ax=ax, color=\"maroon\")\nax.axis(\"off\")\nax.legend([\"Thomas Fire Boundary\"])\nfig.suptitle(\"2017 Thomas Fire Scar\", color = 'black', fontsize = 14, fontweight='light', y=0.855)\nax.set_title(\"False colors with Short Wave Infrared, Near-Infrared, & Red Wavelengths\", fontsize=9)\nfig.text(x=.5,y=.2,\n        s='Data Source: CAL FIRE via Data.gov &  Microsof Planetary Computer data catalogue',\n        ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nfig.text(x=.5,y=.18,\n        s='Date Accessed: 11/19/24',\n        ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThis map uses false-color imagery to highlight vegetation and fire-affected areas within the Thomas Fire boundary from 2017. In this visualization, near-infrared (NIR) is represented as green, shortwave infrared (SWIR) as red, and red light as blue. Healthy vegetation strongly reflects NIR, making those areas appear green, while it absorbs red and SWIR wavelengths. Burned areas, often rich in iron oxides, reflect SWIR more strongly, appearing red in the image. This method helps distinguish fire scars and vegetation loss more effectively compared to true-color images, which use visible red, green, and blue wavelengths and may not clearly show such contrasts.\n\n\n\n\nLandsat Data from Microsoft’s Planetary Computer Data Catalogue, AQI Data from the EPA’s daily AQI summaries\n\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 4-5 Thematic Mapper Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9IAXOVV\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 7 Enhanced Thematic Mapper Plus Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9C7I13B\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 8-9 Operational Land Imager / Thermal Infrared Sensor Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9OGBGM6\n\nGalaz García, Carmen. Assignment4 – EDS 220 - Working with Environmental Datasets. (n.d.). https://meds-eds-220.github.io/MEDS-eds-220-course/assignments/assignment4.html"
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html#about",
    "href": "posts/2024-12-13-thomas-fire/index.html#about",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "Image credits: spookysnoopy via Imgur\n\n\nThis notebook explores the 2017 Thomas Fire, one of California’s largest wildfires, which burned over 280,000 acres across Ventura and Santa Barbara counties, causing extensive environmental damage, including vegetation loss, soil erosion, and increased flood risks. This notebook examines the fire’s impact on air quality using AQI data from the US Environmental Protection Agency and visualizes burn severity and fire scars using false-colored Landsat multispectral geospatial data.\n\n\n\n\nAnalyzed Thomas Fires using AQI and Landsat data, creating time-series maps to explore wildfire impacts\nDeveloped true and false color imagery to highlight fire extent and visualize fire scars alongside perimeter data\nCombined and wrangled date and string data, merging data frames for streamlined analysis\nVisualized time series and polished workflows while manipulating raster and vector data with Rasterio and GeoPandas\nEnsured collaboration and reproducibility through structured workflows and Git version control best practices\n\n\n\n\n\n\nThe U.S. Air Quality Index (AQI), developed by the EPA, communicates outdoor air quality and associated health risks through six color-coded categories, ranging from “Good” (AQI ≤ 50) to “Hazardous” (AQI &gt; 300). AQI values up to 100 indicate satisfactory air quality, aligned with national health standards, while values above 100 signal unhealthy conditions—initially for sensitive groups and eventually for all as pollution levels rise. The color-coded system enables quick identification of air quality concerns in communities.\n\n\n\nThis dataset consists of simplified bands (red, green, blue, near-infrared, and shortwave infrared) from Landsat Collection 2 Level-2 surface reflectance data, which was atmospherically corrected and captured by NASA’s Landsat 8 satellite. It was sourced from the Microsoft Planetary Computer data catalog and preprocessed to exclude non-land areas and reduce spatial resolution for ease of computation.\n\n\n\nThis database contains spatial distribution information of both wild and prescribed fires in California. The data comes with a warning of its incompleteness. Some records were lost or damaged, so fire perimeters may be missing. There may also be duplicate or an over estimation of fire perimeters. The database is maintained by the California Department of Forestry and Fire Protection’s Fire and Resource Assessment Program.\n\n\n\n\nThe full repository can be found here."
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html#import-data-and-modules",
    "href": "posts/2024-12-13-thomas-fire/index.html#import-data-and-modules",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "Import Modules\n# Import modules\nimport rioxarray as rioxr\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport os\n\n\n\n\nImport AQI data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\",\n                     compression=\"zip\")\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\",\n                     compression=\"zip\")\n\n\n\n\nImport landsat data\nlandsat_fp = os.path.join(\"data\", \"landsat8-2018-01-26-sb-simplified.nc\")\nlandsat = rioxr.open_rasterio(landsat_fp)\n\n\n\n\nImport Thomas Fire data\nthomas_fp = os.path.join(\"data\", \"thomas_2017.geojson\")\nthomas_2017 = gpd.read_file(thomas_fp)"
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html#visualizing-aqi-during-the-2017-thomas-fire-in-santa-barbara-county",
    "href": "posts/2024-12-13-thomas-fire/index.html#visualizing-aqi-during-the-2017-thomas-fire-in-santa-barbara-county",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "We begin this section by excecuting preliminary explorations of our data.\n\n\nView first five rows of 2017 AQI\naqi_17_head\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n\nView first five rows of 2018 AQI\naqi_18_head\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2018-01-02\n42\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2018-01-05\n45\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2018-01-08\n20\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2018-01-11\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2018-01-14\n33\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\n\n# Compare the differing shapes\nprint(aqi_17.shape, aqi_18.shape)\n# Compare dataframe columns and dtypes\nprint(aqi_17.dtypes == aqi_18.dtypes)\n\n(326801, 10) (327543, 10)\nState Name                   True\ncounty Name                  True\nState Code                   True\nCounty Code                  True\nDate                         True\nAQI                          True\nCategory                     True\nDefining Parameter           True\nDefining Site                True\nNumber of Sites Reporting    True\ndtype: bool\n\n\nWe started by examining the shape and data types of each dataframe to assess their compatibility for comparison. This step is crucial for ensuring the legitimacy of directly analyzing these two datasets together. Lucky for us, the dataframes share identical columns with matching data types. This consistency allows for seamless comparison and concatenation, aiding in our analysis.\n\n\n\nTo aid in our comparisons, we begin by cleaning up our data.\n\n\nConcatenate the two dataframes together\naqi = pd.concat([aqi_17, aqi_18])\naqi\n\n\n\n\n\n\n\n\n\nState Name\ncounty Name\nState Code\nCounty Code\nDate\nAQI\nCategory\nDefining Parameter\nDefining Site\nNumber of Sites Reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n28\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n29\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n25\nGood\nPM2.5\n01-003-0010\n1\n\n\n3\nAlabama\nBaldwin\n1\n3\n2017-01-13\n40\nGood\nPM2.5\n01-003-0010\n1\n\n\n4\nAlabama\nBaldwin\n1\n3\n2017-01-16\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n327538\nWyoming\nWeston\n56\n45\n2018-12-27\n36\nGood\nOzone\n56-045-0003\n1\n\n\n327539\nWyoming\nWeston\n56\n45\n2018-12-28\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327540\nWyoming\nWeston\n56\n45\n2018-12-29\n35\nGood\nOzone\n56-045-0003\n1\n\n\n327541\nWyoming\nWeston\n56\n45\n2018-12-30\n31\nGood\nOzone\n56-045-0003\n1\n\n\n327542\nWyoming\nWeston\n56\n45\n2018-12-31\n35\nGood\nOzone\n56-045-0003\n1\n\n\n\n\n654344 rows × 10 columns\n\n\n\n\n\nClean column names\n# Initial column names: notice caps and spaces (difficult to work with!)\nprint(aqi.columns, '\\n')\n\n# Simplify column names\naqi.columns = (aqi.columns\n                  .str.lower()\n                  .str.replace(' ','_')\n                )\nprint(aqi.columns, '\\n')\n\n\nIndex(['State Name', 'county Name', 'State Code', 'County Code', 'Date', 'AQI',\n       'Category', 'Defining Parameter', 'Defining Site',\n       'Number of Sites Reporting'],\n      dtype='object') \n\nIndex(['state_name', 'county_name', 'state_code', 'county_code', 'date', 'aqi',\n       'category', 'defining_parameter', 'defining_site',\n       'number_of_sites_reporting'],\n      dtype='object') \n\n\n\nConcatenating and cleaning our column names help us create a clean dataframe that will aid in filtering. We want to filter for Santa Barbara only and our necessary column names.\n\n\nFilter and clean data\n# Filter AQI to only Santa Barbara\naqi_sb = aqi[aqi[\"county_name\"] == \"Santa Barbara\"]\n# Drop unnecessary columns\naqi_sb = aqi_sb.drop(columns=['state_name', 'county_name', 'state_code', 'county_code'])\n\n# Find data type of date column\ndate_type = aqi_sb[\"date\"].dtype\n# Update the date column to be pd.datetime object\naqi_sb.date = pd.to_datetime(aqi_sb.date)\n# Update index to the date column\naqi_sb = aqi_sb.set_index(\"date\")\naqi_sb.sort_index(inplace=True)\n\n\nNow with our data cleaned, we can begin with our analysis. We want to calculate the AQI average over a 5 day rolling window.\n\n# Calculate AQI rolling average over 5 days\nrolling_average = aqi_sb[\"aqi\"].rolling(\"5D\").mean()\n# Add rolling mean to SB dataframe\naqi_sb[\"five_day_average\"] = rolling_average.values\n\nHooray! We have completed our data cleaning and now we have a easy to plot data frame full of rolling average values. All we have left is to…\n\n\n\n\n\nPlot AQI Rolling Average\n# Visualize the AQI data\naqi_sb.plot(kind=\"line\",\n            y=[\"aqi\", \"five_day_average\"],\n            xlabel=\"Date\",\n            ylabel=\"PM 2.5\",\n            label=[\"Daily AQI Level\", \"5-Day Average AQI\"],\n            title=\"Daily and Rolling Average AQI\\nof Santa Barbara County from 2017-18\")\n\n\n\n\n\n\n\n\n\nAs you can see, there is a large spike in PM 2.5 during the same time frame of the Thomas Fire in late 2017. Next, we will visualize the fire scars left by the fire using landsat data and false color imagery."
  },
  {
    "objectID": "posts/2024-12-13-thomas-fire/index.html#thomas-fire-false-color",
    "href": "posts/2024-12-13-thomas-fire/index.html#thomas-fire-false-color",
    "title": "The Environmental Effects of the 2017 Thomas Fire",
    "section": "",
    "text": "We will examine the dataset to understand its structure. After exploring the data, we will summarize in paragraph form.\n\n# Show preliminary xarrary.Dataset\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 25MB\nDimensions:      (band: 1, x: 870, y: 731)\nCoordinates:\n  * band         (band) int64 8B 1\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (band, y, x) float64 5MB ...\n    green        (band, y, x) float64 5MB ...\n    blue         (band, y, x) float64 5MB ...\n    nir08        (band, y, x) float64 5MB ...\n    swir22       (band, y, x) float64 5MB ...xarray.DatasetDimensions:band: 1x: 870y: 731Coordinates: (4)band(band)int641array([1])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))Attributes: (0)\n\n\n\n# Show dimensions of dataset \nprint(landsat.dims)\n\nFrozenMappingWarningOnValuesAccess({'band': 1, 'x': 870, 'y': 731})\n\n\n\n# Show CRS of dataset \nprint(landsat.rio.crs)\n\nEPSG:32611\n\n\n\n# Show datatypes of dataset \nprint(landsat.dtypes)\n\nFrozen({'red': dtype('float64'), 'green': dtype('float64'), 'blue': dtype('float64'), 'nir08': dtype('float64'), 'swir22': dtype('float64')})\n\n\n\n\nThis dataset is a 2D dataset with a single band. There are five wavelength ranges captures, red, green, blue, near infrared and short wave infrared. The dataset is of CRS EPSG:32611.\n\n\n\n\nTo ease visualizations, we will simplify the dataset by removing unnecessary dimensions.\n\n\nDrop band dimension of data\nlandsat = landsat.drop_vars(\"band\").squeeze()\n\n\n\n# View updated dataset\nlandsat.head()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 1kB\nDimensions:      (x: 5, y: 5)\nCoordinates:\n  * x            (x) float64 40B 1.213e+05 1.216e+05 ... 1.221e+05 1.224e+05\n  * y            (y) float64 40B 3.952e+06 3.952e+06 ... 3.952e+06 3.951e+06\n    spatial_ref  int64 8B 0\nData variables:\n    red          (y, x) float64 200B ...\n    green        (y, x) float64 200B ...\n    blue         (y, x) float64 200B ...\n    nir08        (y, x) float64 200B ...\n    swir22       (y, x) float64 200B ...xarray.DatasetDimensions:x: 5y: 5Coordinates: (3)x(x)float641.213e+05 1.216e+05 ... 1.224e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., 122115., 122385.])y(y)float643.952e+06 3.952e+06 ... 3.951e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., 3951585., 3951315.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]green(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]blue(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]nir08(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]swir22(y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[25 values with dtype=float64]Indexes: (2)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0], dtype='float64', name='x'))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0], dtype='float64', name='y'))Attributes: (0)\n\n\n\n\n\nBy extracting the red, green, and blue bands we can begin to create an RGB image.\n\n\nFilter and clean data\n# Filter AQI to only Santa Barbara\naqi_sb = aqi[aqi[\"county_name\"] == \"Santa Barbara\"]\n# Drop unnecessary columns\naqi_sb = aqi_sb.drop(columns=['state_name', 'county_name', 'state_code', 'county_code'])\n\n\nConverting the dataframe to an array will easily allow us to plot using the plot.imshow() method.\n\n# Convert to array\nlandsat[[\"red\", \"green\", \"blue\"]].to_array()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (variable: 3, y: 731, x: 870)&gt; Size: 15MB\narray([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])\nCoordinates:\n  * x            (x) float64 7kB 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * y            (y) float64 6kB 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n    spatial_ref  int64 8B 0\n  * variable     (variable) object 24B 'red' 'green' 'blue'xarray.DataArrayvariable: 3y: 731x: 8700.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0array([[[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])Coordinates: (4)x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)variable(variable)object'red' 'green' 'blue'array(['red', 'green', 'blue'], dtype=object)Indexes: (3)xPandasIndexPandasIndex(Index([121305.0, 121575.0, 121845.0, 122115.0, 122385.0, 122655.0, 122925.0,\n       123195.0, 123465.0, 123735.0,\n       ...\n       353505.0, 353775.0, 354045.0, 354315.0, 354585.0, 354855.0, 355125.0,\n       355395.0, 355665.0, 355935.0],\n      dtype='float64', name='x', length=870))yPandasIndexPandasIndex(Index([3952395.0, 3952125.0, 3951855.0, 3951585.0, 3951315.0, 3951045.0,\n       3950775.0, 3950505.0, 3950235.0, 3949965.0,\n       ...\n       3757725.0, 3757455.0, 3757185.0, 3756915.0, 3756645.0, 3756375.0,\n       3756105.0, 3755835.0, 3755565.0, 3755295.0],\n      dtype='float64', name='y', length=731))variablePandasIndexPandasIndex(Index(['red', 'green', 'blue'], dtype='object', name='variable'))Attributes: (0)\n\n\n\n\n\nNow we will plot the RGB data to visualize it as a true color image.\n\n# Visualize with simple plot\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow()\n\nClipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n\n\n\n\n\n\n\n\n\n\n\nWell we did not alter the robust parameter. Let’s set it to True and see what happens!\n\n# Visualize with true color plot\nlandsat[[\"red\", \"green\", \"blue\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\nThe output of a) shows a black and white outline of the area we are working with, while b) shows us a more true to color rendering. The robust=True parameter that we added will eliminate any outliers that may alter the data. It uses 2nd and 98th percentiles of the data to compute the color limits.\n\n\n\nTo visualize specific features like vegetation health or fire impacts, we can create false color imagery using the red, near infrared, and short wave infrared bands.\n\n# Visualize with false color plot\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(robust=True)\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, we can overlay the false color imagery with critical geographical features like the fire perimeters we imported before.\n\n# Compare CRS\nprint(landsat.rio.crs)\nprint(thomas_2017.crs)\n\nEPSG:32611\nEPSG:4326\n\n\n\n\nReproject data\nthomas_2017 = thomas_2017.to_crs(landsat.rio.crs)\nprint('Matched CRS?:',  landsat.rio.crs == thomas_2017.crs)\n\n\nMatched CRS?: True\n\n\n\n\nVisualize Thomas Fire scar\n# Plot of false color raster with buffer overlay\nfig, ax = plt.subplots(figsize=(6, 7))  # Directly set size and aspect\nlandsat[[\"swir22\", \"nir08\", \"red\"]].to_array().plot.imshow(\n                robust=True,\n                ax=ax)\nthomas_2017.boundary.plot(ax=ax, color=\"maroon\")\nax.axis(\"off\")\nax.legend([\"Thomas Fire Boundary\"])\nfig.suptitle(\"2017 Thomas Fire Scar\", color = 'black', fontsize = 14, fontweight='light', y=0.855)\nax.set_title(\"False colors with Short Wave Infrared, Near-Infrared, & Red Wavelengths\", fontsize=9)\nfig.text(x=.5,y=.2,\n        s='Data Source: CAL FIRE via Data.gov &  Microsof Planetary Computer data catalogue',\n        ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nfig.text(x=.5,y=.18,\n        s='Date Accessed: 11/19/24',\n        ha='center', va='center', fontsize=8, color='black', fontstyle='italic')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThis map uses false-color imagery to highlight vegetation and fire-affected areas within the Thomas Fire boundary from 2017. In this visualization, near-infrared (NIR) is represented as green, shortwave infrared (SWIR) as red, and red light as blue. Healthy vegetation strongly reflects NIR, making those areas appear green, while it absorbs red and SWIR wavelengths. Burned areas, often rich in iron oxides, reflect SWIR more strongly, appearing red in the image. This method helps distinguish fire scars and vegetation loss more effectively compared to true-color images, which use visible red, green, and blue wavelengths and may not clearly show such contrasts.\n\n\n\n\nLandsat Data from Microsoft’s Planetary Computer Data Catalogue, AQI Data from the EPA’s daily AQI summaries\n\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 4-5 Thematic Mapper Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9IAXOVV\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 7 Enhanced Thematic Mapper Plus Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9C7I13B\nEarth Resources Observation and Science (EROS) Center. (2020). Landsat 8-9 Operational Land Imager / Thermal Infrared Sensor Level-2, Collection 2. U.S. Geological Survey. https://doi.org/10.5066/P9OGBGM6\n\nGalaz García, Carmen. Assignment4 – EDS 220 - Working with Environmental Datasets. (n.d.). https://meds-eds-220.github.io/MEDS-eds-220-course/assignments/assignment4.html"
  },
  {
    "objectID": "posts/2024-10-18-hello-world/index.html",
    "href": "posts/2024-10-18-hello-world/index.html",
    "title": "Hello World!",
    "section": "",
    "text": "In my first language, C++\n#include &lt;iostream&gt;\n\nint main(){\n  std::cout&lt;&lt;\"Hello, World!\"&lt;&lt;std::endl;\n  return 0;\n}\nIn my favorite language, Python:\nprint(\"Hello, World!\")\nIn a language I am forced to use, R:\nprint(\"Hello, World!\")\nErm… How original…\nNo programmer is complete without the proverbial “Hello World!”. Now that that is done, I’ll the rest of the blog will be dedicated to Environmental Data Science. What’s that you say? Why don’t you check out my other posts and find out!"
  },
  {
    "objectID": "posts/2024-10-18-hello-world/index.html#hello-world",
    "href": "posts/2024-10-18-hello-world/index.html#hello-world",
    "title": "Hello World!",
    "section": "",
    "text": "In my first language, C++\n#include &lt;iostream&gt;\n\nint main(){\n  std::cout&lt;&lt;\"Hello, World!\"&lt;&lt;std::endl;\n  return 0;\n}\nIn my favorite language, Python:\nprint(\"Hello, World!\")\nIn a language I am forced to use, R:\nprint(\"Hello, World!\")\nErm… How original…\nNo programmer is complete without the proverbial “Hello World!”. Now that that is done, I’ll the rest of the blog will be dedicated to Environmental Data Science. What’s that you say? Why don’t you check out my other posts and find out!"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html",
    "href": "posts/2025-01-26-bloom-shift/index.html",
    "title": "Bloom Shift",
    "section": "",
    "text": "Author: Ian Morris-Sibaja\n\n\n\n\n\nSedgewick Reserve\n\n\nImage credits: UCNRS\n\n\nThis study investigates how climate change influences the flowering phenology of native and invasive Californian annual forbs. Given California’s status as a biodiversity hotspot and the region’s susceptibility to hotter and drier conditions, this research aims to understand how shifts in temperature and precipitation affect plant communities. Specifically, we address two primary questions:\n\nDoes the average flowering observation date correlate with changes in annual temperature or precipitation?\nAre particular climate zones, such as coastal Southern California, experiencing more pronounced phenological shifts compared to the state as a whole?\n\nBy analyzing 50 years of data on nine plant species and correlating it with climate trends, this research seeks to highlight the potential impacts of climate change on native and invasive species, with implications for ecosystem stability and conservation planning.\n\n\n\n\nPhenological Shifts: Investigate if flowering times correlate with changes in temperature and precipitation over time.\nSpatial Analysis: Determine if shifts are more pronounced in certain climate zones, e.g., coastal Southern California.\nConservation Implications: Understand how these changes impact the ecosystem dynamics and inform conservation strategies for native biodiversity.\nFocused on California, a biodiversity hotspot particularly sensitive to climate changes.\nIdentified trends for each species using statistical models (OLS regression) to link phenology with climate trends.\nHighlights differences between native and invasive species in their response to environmental changes.\n\n\n\n\nThe study relies on 50 years of data (1966–2016) on flowering observations for nine Californian annual forb species, including both native and invasive types. This dataset integrates:\n\nFlowering data: Derived from occurrence records supplied, focusing on observations from California.\nClimate data: Compiled from the National Weather Service Cooperative Observer Program (NWS COOP), including annual temperature and precipitation records.\nSpatial data: Uses shapefiles from NOAA to map flowering data to specific climate divisions in California.\nData preprocessing ensured temporal consistency and excluded irrelevant records.\n\n\n\n\n\n\n\nImport Modules\n# Import modules\nimport pandas as pd\nimport os\nfrom plotly import express as px\nimport plotly.graph_objects as go\nimport numpy as np\nimport geopandas as gpd\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sb\nimport statsmodels.formula.api as smf\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\n\n\n\n\n\n\n\nLoad Climate Data\n# set the directory to the climate data\ndirectory = './data/climate/'\n\n# create a dictionary to store all files in this directory\nd = {}\n# iterate over files in this directory, add each name of file and its contents into a dictionary\nfor filename in os.listdir(directory):\n        d[filename] = pd.read_csv(f'./data/climate/{filename}', encoding= 'unicode_escape')\ndel d['.DS_Store']\n\n\n\n# iterate over the dictionary and add the COOP_ID and type of data to each dataframe\nmaxMinT = []\nmaxMinP = []\n\nfor key, value in d.items():\n    if key[7:8] == 'p':\n        maxMinP.append(d[key]['YEAR(S)'].min())\n    else:\n        maxMinT.append(d[key]['YEAR(S)'].min())\n    value['COOP_ID'] = key[1:6]\n    value['type'] = key[7:8]\n    d[key] = d[key].loc[:, ~d[key].columns.str.contains('^Unnamed')]\n\nThe National Weather Service (NWS) Cooperative Observer Program (COOP) is a network of daily weather observations taken by more than 8,500 volunteers. Here we import and clean the data to be manipulated in out dataset.\n\n# Create a dataframe with COOP information \ncoopNames = pd.read_csv('./data/Coopnames.csv')\ncoopNames = coopNames.drop([0,1,2]).reset_index(drop=True)\ncoopNames = coopNames[['COOP_ID', 'COOP_NAME', 'DIV', 'LATITUDE', 'LONGITUDE']]\n\n# convert COOP_ID to int\ncoopNames.COOP_ID = coopNames.COOP_ID.astype(int)\n\n\n# merge the COOP information with the climate data\ncoop = pd.concat(d.values(), ignore_index=True)\n\n# filter the data to only include years 1966-2016\ncoop = coop[coop['YEAR(S)']&gt;=1966]\ncoop = coop[coop['YEAR(S)']&lt;=2016]\n\n# drop rows with irrelevant data\ncoop = coop.replace(['-----'], np.nan).reset_index(drop=True)\ncoop = coop.loc[:, ~coop.columns.str.contains('^Unnamed')]\ncoop = coop.drop(['January'], axis =1)\n\n\n\nCOOP Data\ncoop\n\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nt\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nt\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nt\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nt\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nt\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5929\n2012\n0.62\n0.45\n1.73\n1.39\n0.03\n0.00\n0.00\n0.00\n0.00\n0.28\n0.49\n1.90\n4.09\n43747\np\n\n\n5930\n2013\n0.22\n0.48\n0.79\n0.08\n0.17\n0.00\n0.00\n0.00\n0.01\n0.00\n0.33\n0.16\n2.24\n43747\np\n\n\n5931\n2014\n0.30\n1.38\n0.27\n0.35\n0.00\n0.00\n0.00\n0.00\n0.03\n0.00\n0.94\n2.52\n5.79\n43747\np\n\n\n5932\n2015\n0.08\n0.72\n0.02\n0.77\n0.10\n0.00\n0.45\n0.00\n0.00\n0.38\n0.91\n1.40\n4.83\n43747\np\n\n\n5933\n2016\n2.56\n0.58\n1.99\n0.57\n0.02\n0.09\n0.00\n0.00\n0.00\n0.76\n0.40\n1.60\n8.57\n43747\np\n\n\n\n\n5934 rows × 16 columns\n\n\n\n\n# assign the correct data types to the columns\ncoop = coop.astype({col: float for col in coop.columns[1:-2]})\ncoop = coop.astype({col: int for col in coop.columns[:1]})\ncoop = coop.astype({col: int for col in coop.columns[-2:-1]})\n\n\n# merge the COOP names with COOP data\ncoop = coop.merge(coopNames, left_on='COOP_ID', right_on='COOP_ID')\n\n\n# assign percipitation and temperature data to separate dataframes\ncoopT = coop[coop['type'] == 't']\ncoopP = coop[coop['type'] == 'p']\n\n\ncoopT.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n\n\n\n\n\n\ncoopP.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n102\n1966\n1.35\n1.40\n1.16\n0.05\n0.07\n0.22\n0.39\n0.19\n0.20\n0.46\n0.83\nNaN\n6.32\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n103\n1967\n1.42\n0.00\n1.03\n3.54\n0.48\n0.06\n0.34\n0.49\n0.82\n0.00\n3.65\n4.23\n16.06\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n104\n1968\n0.58\n0.73\n2.19\n0.85\n0.28\n0.03\n1.88\n0.06\n0.00\n0.05\n0.72\n1.66\n9.03\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n105\n1969\n8.30\n5.67\n1.96\n0.10\n0.43\n0.12\n0.01\n0.00\n0.20\n0.02\n1.85\n0.26\n18.92\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n106\n1970\n0.85\n0.96\n3.95\n1.18\n0.00\n0.03\n0.03\n2.66\n0.08\n0.12\n1.28\n2.66\n13.80\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n\n\n\n\n\n\n# drop the type column from the dataframes\ncoopP = coopP.drop(['type'], axis =1).reset_index(drop = True)\ncoopT = coopT.drop(['type'], axis =1).reset_index(drop = True)\n\n\ncoopT.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n\n\n\n\n\n\ncoopP.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n1.35\n1.40\n1.16\n0.05\n0.07\n0.22\n0.39\n0.19\n0.20\n0.46\n0.83\nNaN\n6.32\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n1\n1967\n1.42\n0.00\n1.03\n3.54\n0.48\n0.06\n0.34\n0.49\n0.82\n0.00\n3.65\n4.23\n16.06\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n2\n1968\n0.58\n0.73\n2.19\n0.85\n0.28\n0.03\n1.88\n0.06\n0.00\n0.05\n0.72\n1.66\n9.03\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n3\n1969\n8.30\n5.67\n1.96\n0.10\n0.43\n0.12\n0.01\n0.00\n0.20\n0.02\n1.85\n0.26\n18.92\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n4\n1970\n0.85\n0.96\n3.95\n1.18\n0.00\n0.03\n0.03\n2.66\n0.08\n0.12\n1.28\n2.66\n13.80\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n\n\n\n\n\n\n# group the data by year and calculate the average temperature and precipitation\ncoopTavg = coopT.groupby(['YEAR(S)'])[['ANN']].mean()\ncoopPavg = coopP.groupby(['YEAR(S)'])[['ANN']].mean()\n\n\ncoopPavg.head()\n\n\n\n\n\n\n\n\nANN\n\n\nYEAR(S)\n\n\n\n\n\n1966\n13.723684\n\n\n1967\n18.576316\n\n\n1968\n13.371930\n\n\n1969\n24.774386\n\n\n1970\n19.625789\n\n\n\n\n\n\n\n\n\ncoopTavg.head()\n\n\n\n\n\n\n\n\nANN\n\n\nYEAR(S)\n\n\n\n\n\n1966\n59.034815\n\n\n1967\n58.699091\n\n\n1968\n58.755893\n\n\n1969\n58.758750\n\n\n1970\n59.136316\n\n\n\n\n\n\n\n\n\n\nThe flowerDataFrame function processes and filters occurrence data for a specified plant species in California, returning a clean, structured DataFrame with relevant details such as geographic coordinates, flowering dates, and native status.\n\n\nFlowering Data Function\ndef flowerDataFrame(name, isNative):\n    '''\n    Returns a dataframe of the species data for a specific species in California\n\n    @param name: a string of the name of the species that you want to obtain data for\n    @param isNative: a string stating whether the species is native to california or not\n    '''\n    # Load csv of the species data into a pandas dataframe\n    df = pd.read_csv(f\"./data/{name}/occurrence.txt\", sep='\\t', low_memory=False)\n    #take only specific columns from the bigger dataframe\n    df = df[['scientificName', 'decimalLongitude', 'decimalLatitude', 'day', 'month', 'year', 'stateProvince', 'countryCode']]\n\n    #add a column stating if it is native or not\n    df['native'] = isNative\n\n    #make new column that will drop any unnecessary abbreviations at the end of each name of observation\n    df['species'] = df['scientificName'].str[:len(name)]\n    #make sure dataframe only includes desired species\n    df = df[df['species'] == name]\n    #drop now unused column\n    df = df.drop(['scientificName'], axis=1)\n\n    #make sure dataframe only includes observations from Califronia\n    df = df[(df['countryCode'] == \"US\")]\n    df = df[(df['stateProvince'] == \"California\") | (df['stateProvince'] == \"Ca\")]\n    df = df[df['decimalLongitude'] &gt; -125]\n    df = df[df['decimalLongitude'] &lt; -113]\n    #drop because we know all measurements in entire dataset are in california\n    df = df.drop(['stateProvince'], axis=1)\n    df = df.drop(['countryCode'], axis=1)\n    df = df.dropna()\n    df = df.reset_index(drop=True)\n    \n    #add column called day of year\n    df[list([\"day\", \"month\", \"year\"])] = df[list([\"day\", \"month\", \"year\"])].astype(int)\n    df[list([\"day\", \"month\", \"year\"])] = df[list([\"day\", \"month\", \"year\"])].astype(str)\n    \n    df['month'] = df['month'].apply(lambda x: '{0:0&gt;2}'.format(x))\n    df['day'] = df['day'].apply(lambda x: '{0:0&gt;2}'.format(x))\n    \n    df[\"DOY\"] = df[\"year\"].copy()\n    month = df[\"month\"].copy()\n    day = df[\"day\"].copy()\n    \n    df[\"DOY\"] = df[\"DOY\"].str.cat((month, day), sep =\"-\")\n    df['DOY'] = pd.to_datetime(df['DOY'], format='%Y-%m-%d')\n    df['DOY'] = df['DOY'].dt.dayofyear\n\n    #convert months and years into ints instead of floats \n    df[list([\"year\"])] = df[list([\"year\"])].astype(int)\n    \n    #make sure occurances are of from 1920-2020\n    df = df[df['year'] &gt; 1919]\n    df = df[df['year'] &lt; 2021]\n    df = df.reset_index(drop = True)\n    \n    #give columns more readable names\n    df = df.rename(columns={'decimalLongitude': 'longitude',\n                            'decimalLatitude':  'latitude'})\n    #keep latitude rounding same as eventual climate data\n    df.longitude = df.longitude.round(3)\n    df.latitude = df.latitude.round(3)\n\n    \n    return df\n\n\n\n#native plants\nlasCal = flowerDataFrame('Lasthenia californica', 'yes')\nplntgo = flowerDataFrame(\"Plantago erecta Morris\", 'yes')\nclrkiP = flowerDataFrame(\"Clarkia purpurea\", 'yes')\nclrkiB = flowerDataFrame(\"Clarkia bottae\", 'yes')\nchaenc = flowerDataFrame(\"Chaenactis glabriuscula\", 'yes')\namsink = flowerDataFrame(\"Amsinckia menziesii\", 'yes')\n\n#non-native\nmdcgoP = flowerDataFrame(\"Medicago polymorpha\", 'no')\ncntrea = flowerDataFrame(\"Centaurea solstitialis\", 'no')\nbrssTG = flowerDataFrame(\"Brassica tournefortii Gouan\", 'no')\n\n\n#concat all species dataframes into one big one\nflowersCA = pd.concat([lasCal, plntgo, clrkiP, clrkiB, chaenc, amsink,\n                       mdcgoP, cntrea, brssTG])\n#convert into geodataframe to be easily compared wihtin shape files in the future\nflowersCA = gpd.GeoDataFrame(flowersCA, geometry=gpd.points_from_xy(flowersCA.longitude, flowersCA.latitude))\n\n\n\n\nBelow I take a shape file from from NOAAs database, and determine which climate divisions each observation falls under.\n\n# from NOAAs shapefile, find useful columns and determine which are within CA\nclimateDivs = gpd.read_file(\"./data/climateDiv/GIS.OFFICIAL_CLIM_DIVISIONS.shp\")\nclimateDivs = climateDivs[climateDivs[\"ST_ABBRV\"] == 'CA']\nclimateDivs = climateDivs[[\"CD_NEW\", 'geometry']]\n\n\n# set both coordinate reference systems to be the same so the dataframes are accurately compared\nclimateDivs = climateDivs.set_crs(\"EPSG:4326\", allow_override=True)\nflowersCA = flowersCA.set_crs(\"EPSG:4326\")\n\n\n# this will join the two datasets based on if flowering observation\n# geometry points are within the climate division shapefiles, \n# and add a column within each observation of said Climate Divsion\nflowersCA = gpd.sjoin(flowersCA, climateDivs, how='inner', predicate='within')\nflowersCA = flowersCA.drop(['index_right'], axis = 1)\nflowersCA = flowersCA.reset_index(drop = True)\nflowersCA = flowersCA.rename(columns={'CD_NEW' : 'ClimateDivision'})\nflowersCA = flowersCA[flowersCA['year']&gt;=1966]\nflowersCA = flowersCA[flowersCA['year']&lt;=2016]\n# write only necessary info to csv for quick web parsing\nflowersCA.to_csv('./data/flowersCA.csv')\n\n\n# group the data by species, year, native status, and climate division, and calculate the average day of year that the species flowers\navgPhenologyDiv = flowersCA.groupby(['species', 'year', 'native', 'ClimateDivision'])[[\"DOY\"]].mean().reset_index().round(0)\navgPhenologyDiv\n\n\n\n\n\n\n\n\nspecies\nyear\nnative\nClimateDivision\nDOY\n\n\n\n\n0\nAmsinckia menziesii\n1966\nyes\n4\n119.0\n\n\n1\nAmsinckia menziesii\n1966\nyes\n5\n90.0\n\n\n2\nAmsinckia menziesii\n1966\nyes\n6\n114.0\n\n\n3\nAmsinckia menziesii\n1967\nyes\n4\n125.0\n\n\n4\nAmsinckia menziesii\n1967\nyes\n5\n93.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n1497\nPlantago erecta Morris\n2016\nyes\n1\n115.0\n\n\n1498\nPlantago erecta Morris\n2016\nyes\n2\n99.0\n\n\n1499\nPlantago erecta Morris\n2016\nyes\n4\n87.0\n\n\n1500\nPlantago erecta Morris\n2016\nyes\n5\n80.0\n\n\n1501\nPlantago erecta Morris\n2016\nyes\n6\n93.0\n\n\n\n\n1502 rows × 5 columns\n\n\n\n\n\n\nNow I will employ linear regression models to evaluate the relationship between flowering phenology and climate variables (temperature and precipitation), identifying significant correlations and trends across species, regions, and time. My code calculates statistics of the state, Southern California itself, and climate division 6 to view the relationship between flowering phenology and climate variables (temperature and precipitation) using linear regression:\n\nData Preparation: For each species, the average annual temperature, precipitation, and flowering day-of-year (DOY) are grouped by year and filtered to ensure overlapping years.\nRegression Analysis: Linear regression models are applied separately to assess the relationship between DOY and temperature, as well as DOY and precipitation.\nResults Compilation: The species name, p-values, R-squared, and adjusted R-squared values for both models are stored in a summary DataFrame (stateSum).\nSignificant Results: If the regression p-values indicate statistical significance, the corresponding data for temperature or precipitation is labeled, augmented with species and region information, and added to a significant results DataFrame (sigSum).\n\n\n# create a dictionary to store unique species names\nflowD = {}\nfor i in range(len(avgPhenologyDiv.species.unique())):\n    flowD[i] = avgPhenologyDiv.species.unique()[i]\n\n\n# create a dictionary to store species with significant p-values\nsigSum = pd.DataFrame([])\n\n# set significance level\npval = .05\n\n\n\nState Wide Summary Data\n# create a dictionary to store the state summary data\ndstate = {}\n# iterate over the unique species and calculate the linear regression for each species\nstateSum = pd.DataFrame([])\nfor i in range(len(flowD)):\n    \n    # filter the data to only include the species of interest\n    avgF = avgPhenologyDiv[avgPhenologyDiv['species'] == flowD[i]]\n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data \n    xTy = list(xT['YEAR(S)'])\n    xPy = list(xP['YEAR(S)'])\n    \n    # create a list of years that are in the flowering data \n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the state summary dataframe\n    stateSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the state summary dataframe\n    stateSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    stateSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    stateSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n    \n    stateSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    stateSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    stateSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'State'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'State'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nstateSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.045038\n0.084\n0.065\n0.530467\n0.009\n-0.013\n\n\n1\nBrassica tournefortii Gouan\n0.656550\n0.005\n-0.018\n0.230165\n0.033\n0.011\n\n\n2\nCentaurea solstitialis\n0.663545\n0.004\n-0.017\n0.447359\n0.012\n-0.009\n\n\n3\nChaenactis glabriuscula\n0.022766\n0.101\n0.083\n0.966052\n0.000\n-0.020\n\n\n4\nClarkia bottae\n0.047639\n0.084\n0.064\n0.084706\n0.065\n0.044\n\n\n5\nClarkia purpurea\n0.030003\n0.093\n0.074\n0.096125\n0.055\n0.036\n\n\n6\nLasthenia californica\n0.226127\n0.030\n0.010\n0.116397\n0.050\n0.030\n\n\n7\nMedicago polymorpha\n0.738173\n0.002\n-0.018\n0.261980\n0.026\n0.006\n\n\n8\nPlantago erecta Morris\n0.097705\n0.055\n0.036\n0.765565\n0.002\n-0.019\n\n\n\n\n\n\n\n\n\nSocal Summary Data\n# create a dictionary to store the south state summary data\nsouSum = pd.DataFrame([])\n\n# iterate over the unique species and calculate the linear regression for each species\nfor i in range(len(flowD)):\n    # filter the data to only include the species of interest in climate divisions 6-9\n    avgF = avgPhenologyDiv[avgPhenologyDiv['ClimateDivision'] &gt;= 6] \n    avgF = avgF[avgF['species'] == flowD[i]]    \n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data\n    xTy = list(xT['YEAR(S)']) \n    xPy = list(xP['YEAR(S)']) \n    # create a list of years that are in the flowering data\n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    \n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the south summary dataframe\n    souSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the south summary dataframe\n    souSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    souSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    souSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n    \n    souSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    souSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    souSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'South'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n        sigSum = pd.concat(dfT)\n        \n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'South'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nsouSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.875755\n0.001\n-0.022\n0.875616\n0.001\n-0.022\n\n\n1\nBrassica tournefortii Gouan\n0.904122\n0.000\n-0.022\n0.404617\n0.016\n-0.007\n\n\n2\nCentaurea solstitialis\n0.702031\n0.004\n-0.024\n0.440332\n0.017\n-0.011\n\n\n3\nChaenactis glabriuscula\n0.115176\n0.050\n0.030\n0.594184\n0.006\n-0.014\n\n\n4\nClarkia bottae\n0.270753\n0.029\n0.006\n0.728577\n0.003\n-0.021\n\n\n5\nClarkia purpurea\n0.336247\n0.019\n-0.001\n0.203625\n0.033\n0.013\n\n\n6\nLasthenia californica\n0.263063\n0.027\n0.006\n0.752329\n0.002\n-0.020\n\n\n7\nMedicago polymorpha\n0.199275\n0.035\n0.014\n0.897705\n0.000\n-0.021\n\n\n8\nPlantago erecta Morris\n0.336801\n0.020\n-0.001\n0.425241\n0.014\n-0.007\n\n\n\n\n\n\n\n\n\nClimate Division 6 Summary Data\n# create a dictionary to store the average flowering days\nflowD = {}\n\n# iterate over the unique species and average flowering days\nfor i in range(len(avgPhenologyDiv.species.unique())):\n    flowD[i] = avgPhenologyDiv.species.unique()[i]\n    \n# create a dataframe to store the significant summary data for climate divisions 6\nsixSum = pd.DataFrame([])\n\n# iterate over the unique species and calculate the linear regression for each species\nfor i in range(len(flowD)):\n    # filter the data to only include the species of interest in climate division 6\n    avgF = avgPhenologyDiv[avgPhenologyDiv['ClimateDivision'] == 6] \n    avgF = avgF[avgF['species'] == flowD[i]]    \n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data\n    xTy = list(xT['YEAR(S)']) \n    xPy = list(xP['YEAR(S)']) \n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    \n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the six summary dataframe\n    sixSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the six summary dataframe\n    sixSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    sixSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    sixSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n\n    sixSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    sixSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    sixSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'Six'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'Six'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nsixSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.804356\n0.001\n-0.022\n0.656283\n0.005\n-0.019\n\n\n1\nBrassica tournefortii Gouan\n0.753239\n0.003\n-0.030\n0.424593\n0.021\n-0.011\n\n\n2\nCentaurea solstitialis\n0.494795\n0.014\n-0.015\n0.483818\n0.015\n-0.014\n\n\n3\nChaenactis glabriuscula\n0.056238\n0.072\n0.053\n0.353304\n0.018\n-0.002\n\n\n4\nClarkia bottae\n0.270753\n0.029\n0.006\n0.728577\n0.003\n-0.021\n\n\n5\nClarkia purpurea\n0.040614\n0.083\n0.064\n0.049008\n0.077\n0.058\n\n\n6\nLasthenia californica\n0.458737\n0.014\n-0.011\n0.461362\n0.014\n-0.011\n\n\n7\nMedicago polymorpha\n0.121612\n0.050\n0.030\n0.987780\n0.000\n-0.021\n\n\n8\nPlantago erecta Morris\n0.362461\n0.018\n-0.003\n0.393343\n0.016\n-0.005\n\n\n\n\n\n\n\n\n\n\n\n\n\nsigSum\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n0\n57.374035\n132.000000\nT\nAmsinckia menziesii\nState\n\n\n1\n57.411930\n105.500000\nT\nAmsinckia menziesii\nState\n\n\n2\n57.764483\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n3\n57.798136\n114.333333\nT\nAmsinckia menziesii\nState\n\n\n4\n57.946538\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n...\n...\n...\n...\n...\n...\n\n\n294\n22.954211\n151.000000\nP\nClarkia purpurea\nSix\n\n\n295\n24.774386\n149.000000\nP\nClarkia purpurea\nSix\n\n\n296\n25.309153\n154.000000\nP\nClarkia purpurea\nSix\n\n\n297\n26.406271\n154.000000\nP\nClarkia purpurea\nSix\n\n\n298\n30.957931\n149.000000\nP\nClarkia purpurea\nSix\n\n\n\n\n299 rows × 5 columns\n\n\n\n\n# filter the significant summary data to each region\nstateSig = sigSum[sigSum['Region'] == 'State']\nsouSig = sigSum[sigSum['Region'] == 'South']\nsixSig = sigSum[sigSum['Region'] == 'Six']\n\n\nstateSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n0\n57.374035\n132.000000\nT\nAmsinckia menziesii\nState\n\n\n1\n57.411930\n105.500000\nT\nAmsinckia menziesii\nState\n\n\n2\n57.764483\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n3\n57.798136\n114.333333\nT\nAmsinckia menziesii\nState\n\n\n4\n57.946538\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n\n\n\n\n\n\nsouSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n\n\n\n\n\n\nsixSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n197\n57.374035\n145.0\nT\nClarkia purpurea\nSix\n\n\n198\n57.411930\n145.0\nT\nClarkia purpurea\nSix\n\n\n199\n57.764483\n140.0\nT\nClarkia purpurea\nSix\n\n\n200\n57.798136\n129.0\nT\nClarkia purpurea\nSix\n\n\n201\n57.946538\n152.0\nT\nClarkia purpurea\nSix\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Temperature for Native Flowers in California\n# set plot size\ng = plt.figure(figsize = [10,8])\n# empty list to store legend\nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(stateSig.Species.unique())):\n    g = sb.regplot(data = stateSig[stateSig['Species'] == stateSig.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{stateSig.Species.unique()[i]}')\n    l.append(red_patch)\ng.set_title(\"Flowering DOY vs Temperature for Native Flowers in California\")\ng.set_xlabel(\"Average Yearly Temperature (F)\", fontsize = 15)\ng.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('stateSigT.png')\n\n\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Temperature for Clarkia Purpurea in CA06\n# set plot size\nh = plt.figure(figsize = [10,8])\n# empty list to store legend \nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# filter the significant summary data to temperature only\nsixSigT = sixSig[sixSig['Type'] == 'T']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(sixSigT.Species.unique())):\n    h = sb.regplot(data = sixSigT[sixSigT['Species'] == sixSigT.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{sixSigT.Species.unique()[i]}')\n    l.append(red_patch)\nh.set_title(\"Flowering DOY vs Temperature for Clarkia Purpurea in CA06\")\nh.set_xlabel(\"Average Yearly Temperature (F)\", fontsize = 15)\nh.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('sixSigT.png')\n\n\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Precipitation for Clarkia Purpurea in CA06\n# set plot size\nh = plt.figure(figsize = [10,8])\n# empty list to store legend\nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# filter the significant summary data to precipitation only\nsixSigP = sixSig[sixSig['Type'] == 'P']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(sixSig.Species.unique())):\n    h = sb.regplot(data = sixSigP[sixSigP['Species'] == sixSigP.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{sixSigP.Species.unique()[i]}')\n    l.append(red_patch)\nh.set_title(\"Flowering DOY vs Precipitation for Clarkia Purpurea in CA06\")\nh.set_xlabel(\"Average Yearly Precipitation (In.)\", fontsize = 15)\nh.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('sixSigP.png')\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis study addressed two key questions: (1) whether average flowering observation dates are influenced by temperature or precipitation changes, and (2) if specific climate zones, like coastal Southern California, exhibit more pronounced phenological shifts compared to statewide trends.\nKey Findings: 1. Temperature and Phenology: Across all species, significant correlations with temperature exhibited negative coefficients, indicating earlier flowering with rising temperatures. For instance, Clarkia bottae blooms ~11 days earlier for every 1°C temperature increase. Over 50 years, California’s average temperature rose by ~1°C, significantly impacting native species.\n\nPrecipitation and Phenology: Significant correlations with precipitation were positive, meaning reduced rainfall led to earlier flowering. Though annual precipitation trends were not statistically significant, extreme events likely influence phenology and destabilize communities.\nRegional Patterns: Statewide, only native species showed significant correlations with temperature. In coastal Southern California (climate division 6), significant responses were observed in Clarkia purpurea and Chaenactis glabriuscula, with Clarkia purpurea being sensitive to both temperature and precipitation.\nNative vs. Invasive Species: Native species were more affected by climate change than invasive species, potentially giving invasives a competitive advantage. Earlier flowering in natives could lead to ecosystem shifts and competitive displacement by invasives.\n\nLimitations and Recommendations: - Limited species count and uneven data distribution across regions and species. - Precipitation analysis could be refined by focusing on seasonal rather than annual totals. - More comprehensive studies are needed, especially with equal representation of native and invasive species.\nImplications: Native species like Clarkia purpurea, critical to ecosystem stability, are highly vulnerable to climate change. Differential impacts across climate divisions necessitate tailored conservation strategies. Without intervention, these shifts could lead to ecosystem reorganization, favoring invasive species and jeopardizing native biodiversity."
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#about",
    "href": "posts/2025-01-26-bloom-shift/index.html#about",
    "title": "Bloom Shift",
    "section": "",
    "text": "Sedgewick Reserve\n\n\nImage credits: UCNRS\n\n\nThis study investigates how climate change influences the flowering phenology of native and invasive Californian annual forbs. Given California’s status as a biodiversity hotspot and the region’s susceptibility to hotter and drier conditions, this research aims to understand how shifts in temperature and precipitation affect plant communities. Specifically, we address two primary questions:\n\nDoes the average flowering observation date correlate with changes in annual temperature or precipitation?\nAre particular climate zones, such as coastal Southern California, experiencing more pronounced phenological shifts compared to the state as a whole?\n\nBy analyzing 50 years of data on nine plant species and correlating it with climate trends, this research seeks to highlight the potential impacts of climate change on native and invasive species, with implications for ecosystem stability and conservation planning.\n\n\n\n\nPhenological Shifts: Investigate if flowering times correlate with changes in temperature and precipitation over time.\nSpatial Analysis: Determine if shifts are more pronounced in certain climate zones, e.g., coastal Southern California.\nConservation Implications: Understand how these changes impact the ecosystem dynamics and inform conservation strategies for native biodiversity.\nFocused on California, a biodiversity hotspot particularly sensitive to climate changes.\nIdentified trends for each species using statistical models (OLS regression) to link phenology with climate trends.\nHighlights differences between native and invasive species in their response to environmental changes.\n\n\n\n\nThe study relies on 50 years of data (1966–2016) on flowering observations for nine Californian annual forb species, including both native and invasive types. This dataset integrates:\n\nFlowering data: Derived from occurrence records supplied, focusing on observations from California.\nClimate data: Compiled from the National Weather Service Cooperative Observer Program (NWS COOP), including annual temperature and precipitation records.\nSpatial data: Uses shapefiles from NOAA to map flowering data to specific climate divisions in California.\nData preprocessing ensured temporal consistency and excluded irrelevant records."
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#import-libraries",
    "href": "posts/2025-01-26-bloom-shift/index.html#import-libraries",
    "title": "Bloom Shift",
    "section": "",
    "text": "Import Modules\n# Import modules\nimport pandas as pd\nimport os\nfrom plotly import express as px\nimport plotly.graph_objects as go\nimport numpy as np\nimport geopandas as gpd\nfrom plotly.offline import iplot\nfrom plotly.subplots import make_subplots\nfrom sklearn.linear_model import LinearRegression\nimport seaborn as sb\nimport statsmodels.formula.api as smf\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#climate-data",
    "href": "posts/2025-01-26-bloom-shift/index.html#climate-data",
    "title": "Bloom Shift",
    "section": "",
    "text": "Load Climate Data\n# set the directory to the climate data\ndirectory = './data/climate/'\n\n# create a dictionary to store all files in this directory\nd = {}\n# iterate over files in this directory, add each name of file and its contents into a dictionary\nfor filename in os.listdir(directory):\n        d[filename] = pd.read_csv(f'./data/climate/{filename}', encoding= 'unicode_escape')\ndel d['.DS_Store']\n\n\n\n# iterate over the dictionary and add the COOP_ID and type of data to each dataframe\nmaxMinT = []\nmaxMinP = []\n\nfor key, value in d.items():\n    if key[7:8] == 'p':\n        maxMinP.append(d[key]['YEAR(S)'].min())\n    else:\n        maxMinT.append(d[key]['YEAR(S)'].min())\n    value['COOP_ID'] = key[1:6]\n    value['type'] = key[7:8]\n    d[key] = d[key].loc[:, ~d[key].columns.str.contains('^Unnamed')]\n\nThe National Weather Service (NWS) Cooperative Observer Program (COOP) is a network of daily weather observations taken by more than 8,500 volunteers. Here we import and clean the data to be manipulated in out dataset.\n\n# Create a dataframe with COOP information \ncoopNames = pd.read_csv('./data/Coopnames.csv')\ncoopNames = coopNames.drop([0,1,2]).reset_index(drop=True)\ncoopNames = coopNames[['COOP_ID', 'COOP_NAME', 'DIV', 'LATITUDE', 'LONGITUDE']]\n\n# convert COOP_ID to int\ncoopNames.COOP_ID = coopNames.COOP_ID.astype(int)\n\n\n# merge the COOP information with the climate data\ncoop = pd.concat(d.values(), ignore_index=True)\n\n# filter the data to only include years 1966-2016\ncoop = coop[coop['YEAR(S)']&gt;=1966]\ncoop = coop[coop['YEAR(S)']&lt;=2016]\n\n# drop rows with irrelevant data\ncoop = coop.replace(['-----'], np.nan).reset_index(drop=True)\ncoop = coop.loc[:, ~coop.columns.str.contains('^Unnamed')]\ncoop = coop.drop(['January'], axis =1)\n\n\n\nCOOP Data\ncoop\n\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nt\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nt\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nt\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nt\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nt\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5929\n2012\n0.62\n0.45\n1.73\n1.39\n0.03\n0.00\n0.00\n0.00\n0.00\n0.28\n0.49\n1.90\n4.09\n43747\np\n\n\n5930\n2013\n0.22\n0.48\n0.79\n0.08\n0.17\n0.00\n0.00\n0.00\n0.01\n0.00\n0.33\n0.16\n2.24\n43747\np\n\n\n5931\n2014\n0.30\n1.38\n0.27\n0.35\n0.00\n0.00\n0.00\n0.00\n0.03\n0.00\n0.94\n2.52\n5.79\n43747\np\n\n\n5932\n2015\n0.08\n0.72\n0.02\n0.77\n0.10\n0.00\n0.45\n0.00\n0.00\n0.38\n0.91\n1.40\n4.83\n43747\np\n\n\n5933\n2016\n2.56\n0.58\n1.99\n0.57\n0.02\n0.09\n0.00\n0.00\n0.00\n0.76\n0.40\n1.60\n8.57\n43747\np\n\n\n\n\n5934 rows × 16 columns\n\n\n\n\n# assign the correct data types to the columns\ncoop = coop.astype({col: float for col in coop.columns[1:-2]})\ncoop = coop.astype({col: int for col in coop.columns[:1]})\ncoop = coop.astype({col: int for col in coop.columns[-2:-1]})\n\n\n# merge the COOP names with COOP data\ncoop = coop.merge(coopNames, left_on='COOP_ID', right_on='COOP_ID')\n\n\n# assign percipitation and temperature data to separate dataframes\ncoopT = coop[coop['type'] == 't']\ncoopP = coop[coop['type'] == 'p']\n\n\ncoopT.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nt\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n\n\n\n\n\n\ncoopP.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\ntype\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n102\n1966\n1.35\n1.40\n1.16\n0.05\n0.07\n0.22\n0.39\n0.19\n0.20\n0.46\n0.83\nNaN\n6.32\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n103\n1967\n1.42\n0.00\n1.03\n3.54\n0.48\n0.06\n0.34\n0.49\n0.82\n0.00\n3.65\n4.23\n16.06\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n104\n1968\n0.58\n0.73\n2.19\n0.85\n0.28\n0.03\n1.88\n0.06\n0.00\n0.05\n0.72\n1.66\n9.03\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n105\n1969\n8.30\n5.67\n1.96\n0.10\n0.43\n0.12\n0.01\n0.00\n0.20\n0.02\n1.85\n0.26\n18.92\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n106\n1970\n0.85\n0.96\n3.95\n1.18\n0.00\n0.03\n0.03\n2.66\n0.08\n0.12\n1.28\n2.66\n13.80\n41424\np\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n\n\n\n\n\n\n# drop the type column from the dataframes\ncoopP = coopP.drop(['type'], axis =1).reset_index(drop = True)\ncoopT = coopT.drop(['type'], axis =1).reset_index(drop = True)\n\n\ncoopT.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n38.29\n42.33\n48.13\n57.52\n64.40\n64.77\n70.23\n75.16\n67.30\n58.00\n47.87\n42.13\n57.64\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n1\n1967\n39.70\n45.12\n45.50\n44.10\n60.74\n68.47\n75.90\n77.66\n71.48\n57.37\n51.82\n34.60\n70.18\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n2\n1968\n37.07\n47.96\n48.62\nNaN\n58.58\n67.92\n75.92\n70.52\n68.95\n57.45\n44.73\n37.63\n60.21\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n3\n1969\n36.94\n40.71\n46.44\n52.65\n64.53\n68.70\n74.35\n72.60\n69.97\n54.28\n48.15\n43.06\n57.21\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n4\n1970\n42.75\n47.15\n49.00\n48.63\n61.53\n70.80\n76.71\n74.50\n65.97\n56.77\n47.27\n36.48\n59.85\n40738\nBIG BAR 4\n1\n40 44 27\n-123 12 33\n\n\n\n\n\n\n\n\ncoopP.head()\n\n\n\n\n\n\n\n\nYEAR(S)\nJAN\nFEB\nMAR\nAPR\nMAY\nJUN\nJUL\nAUG\nSEP\nOCT\nNOV\nDEC\nANN\nCOOP_ID\nCOOP_NAME\nDIV\nLATITUDE\nLONGITUDE\n\n\n\n\n0\n1966\n1.35\n1.40\n1.16\n0.05\n0.07\n0.22\n0.39\n0.19\n0.20\n0.46\n0.83\nNaN\n6.32\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n1\n1967\n1.42\n0.00\n1.03\n3.54\n0.48\n0.06\n0.34\n0.49\n0.82\n0.00\n3.65\n4.23\n16.06\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n2\n1968\n0.58\n0.73\n2.19\n0.85\n0.28\n0.03\n1.88\n0.06\n0.00\n0.05\n0.72\n1.66\n9.03\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n3\n1969\n8.30\n5.67\n1.96\n0.10\n0.43\n0.12\n0.01\n0.00\n0.20\n0.02\n1.85\n0.26\n18.92\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n4\n1970\n0.85\n0.96\n3.95\n1.18\n0.00\n0.03\n0.03\n2.66\n0.08\n0.12\n1.28\n2.66\n13.80\n41424\nCAMPO\n6\n32 37 24\n-116 28 22\n\n\n\n\n\n\n\n\n# group the data by year and calculate the average temperature and precipitation\ncoopTavg = coopT.groupby(['YEAR(S)'])[['ANN']].mean()\ncoopPavg = coopP.groupby(['YEAR(S)'])[['ANN']].mean()\n\n\ncoopPavg.head()\n\n\n\n\n\n\n\n\nANN\n\n\nYEAR(S)\n\n\n\n\n\n1966\n13.723684\n\n\n1967\n18.576316\n\n\n1968\n13.371930\n\n\n1969\n24.774386\n\n\n1970\n19.625789\n\n\n\n\n\n\n\n\n\ncoopTavg.head()\n\n\n\n\n\n\n\n\nANN\n\n\nYEAR(S)\n\n\n\n\n\n1966\n59.034815\n\n\n1967\n58.699091\n\n\n1968\n58.755893\n\n\n1969\n58.758750\n\n\n1970\n59.136316"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#flowering-data",
    "href": "posts/2025-01-26-bloom-shift/index.html#flowering-data",
    "title": "Bloom Shift",
    "section": "",
    "text": "The flowerDataFrame function processes and filters occurrence data for a specified plant species in California, returning a clean, structured DataFrame with relevant details such as geographic coordinates, flowering dates, and native status.\n\n\nFlowering Data Function\ndef flowerDataFrame(name, isNative):\n    '''\n    Returns a dataframe of the species data for a specific species in California\n\n    @param name: a string of the name of the species that you want to obtain data for\n    @param isNative: a string stating whether the species is native to california or not\n    '''\n    # Load csv of the species data into a pandas dataframe\n    df = pd.read_csv(f\"./data/{name}/occurrence.txt\", sep='\\t', low_memory=False)\n    #take only specific columns from the bigger dataframe\n    df = df[['scientificName', 'decimalLongitude', 'decimalLatitude', 'day', 'month', 'year', 'stateProvince', 'countryCode']]\n\n    #add a column stating if it is native or not\n    df['native'] = isNative\n\n    #make new column that will drop any unnecessary abbreviations at the end of each name of observation\n    df['species'] = df['scientificName'].str[:len(name)]\n    #make sure dataframe only includes desired species\n    df = df[df['species'] == name]\n    #drop now unused column\n    df = df.drop(['scientificName'], axis=1)\n\n    #make sure dataframe only includes observations from Califronia\n    df = df[(df['countryCode'] == \"US\")]\n    df = df[(df['stateProvince'] == \"California\") | (df['stateProvince'] == \"Ca\")]\n    df = df[df['decimalLongitude'] &gt; -125]\n    df = df[df['decimalLongitude'] &lt; -113]\n    #drop because we know all measurements in entire dataset are in california\n    df = df.drop(['stateProvince'], axis=1)\n    df = df.drop(['countryCode'], axis=1)\n    df = df.dropna()\n    df = df.reset_index(drop=True)\n    \n    #add column called day of year\n    df[list([\"day\", \"month\", \"year\"])] = df[list([\"day\", \"month\", \"year\"])].astype(int)\n    df[list([\"day\", \"month\", \"year\"])] = df[list([\"day\", \"month\", \"year\"])].astype(str)\n    \n    df['month'] = df['month'].apply(lambda x: '{0:0&gt;2}'.format(x))\n    df['day'] = df['day'].apply(lambda x: '{0:0&gt;2}'.format(x))\n    \n    df[\"DOY\"] = df[\"year\"].copy()\n    month = df[\"month\"].copy()\n    day = df[\"day\"].copy()\n    \n    df[\"DOY\"] = df[\"DOY\"].str.cat((month, day), sep =\"-\")\n    df['DOY'] = pd.to_datetime(df['DOY'], format='%Y-%m-%d')\n    df['DOY'] = df['DOY'].dt.dayofyear\n\n    #convert months and years into ints instead of floats \n    df[list([\"year\"])] = df[list([\"year\"])].astype(int)\n    \n    #make sure occurances are of from 1920-2020\n    df = df[df['year'] &gt; 1919]\n    df = df[df['year'] &lt; 2021]\n    df = df.reset_index(drop = True)\n    \n    #give columns more readable names\n    df = df.rename(columns={'decimalLongitude': 'longitude',\n                            'decimalLatitude':  'latitude'})\n    #keep latitude rounding same as eventual climate data\n    df.longitude = df.longitude.round(3)\n    df.latitude = df.latitude.round(3)\n\n    \n    return df\n\n\n\n#native plants\nlasCal = flowerDataFrame('Lasthenia californica', 'yes')\nplntgo = flowerDataFrame(\"Plantago erecta Morris\", 'yes')\nclrkiP = flowerDataFrame(\"Clarkia purpurea\", 'yes')\nclrkiB = flowerDataFrame(\"Clarkia bottae\", 'yes')\nchaenc = flowerDataFrame(\"Chaenactis glabriuscula\", 'yes')\namsink = flowerDataFrame(\"Amsinckia menziesii\", 'yes')\n\n#non-native\nmdcgoP = flowerDataFrame(\"Medicago polymorpha\", 'no')\ncntrea = flowerDataFrame(\"Centaurea solstitialis\", 'no')\nbrssTG = flowerDataFrame(\"Brassica tournefortii Gouan\", 'no')\n\n\n#concat all species dataframes into one big one\nflowersCA = pd.concat([lasCal, plntgo, clrkiP, clrkiB, chaenc, amsink,\n                       mdcgoP, cntrea, brssTG])\n#convert into geodataframe to be easily compared wihtin shape files in the future\nflowersCA = gpd.GeoDataFrame(flowersCA, geometry=gpd.points_from_xy(flowersCA.longitude, flowersCA.latitude))"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#climate-division-wrangling",
    "href": "posts/2025-01-26-bloom-shift/index.html#climate-division-wrangling",
    "title": "Bloom Shift",
    "section": "",
    "text": "Below I take a shape file from from NOAAs database, and determine which climate divisions each observation falls under.\n\n# from NOAAs shapefile, find useful columns and determine which are within CA\nclimateDivs = gpd.read_file(\"./data/climateDiv/GIS.OFFICIAL_CLIM_DIVISIONS.shp\")\nclimateDivs = climateDivs[climateDivs[\"ST_ABBRV\"] == 'CA']\nclimateDivs = climateDivs[[\"CD_NEW\", 'geometry']]\n\n\n# set both coordinate reference systems to be the same so the dataframes are accurately compared\nclimateDivs = climateDivs.set_crs(\"EPSG:4326\", allow_override=True)\nflowersCA = flowersCA.set_crs(\"EPSG:4326\")\n\n\n# this will join the two datasets based on if flowering observation\n# geometry points are within the climate division shapefiles, \n# and add a column within each observation of said Climate Divsion\nflowersCA = gpd.sjoin(flowersCA, climateDivs, how='inner', predicate='within')\nflowersCA = flowersCA.drop(['index_right'], axis = 1)\nflowersCA = flowersCA.reset_index(drop = True)\nflowersCA = flowersCA.rename(columns={'CD_NEW' : 'ClimateDivision'})\nflowersCA = flowersCA[flowersCA['year']&gt;=1966]\nflowersCA = flowersCA[flowersCA['year']&lt;=2016]\n# write only necessary info to csv for quick web parsing\nflowersCA.to_csv('./data/flowersCA.csv')\n\n\n# group the data by species, year, native status, and climate division, and calculate the average day of year that the species flowers\navgPhenologyDiv = flowersCA.groupby(['species', 'year', 'native', 'ClimateDivision'])[[\"DOY\"]].mean().reset_index().round(0)\navgPhenologyDiv\n\n\n\n\n\n\n\n\nspecies\nyear\nnative\nClimateDivision\nDOY\n\n\n\n\n0\nAmsinckia menziesii\n1966\nyes\n4\n119.0\n\n\n1\nAmsinckia menziesii\n1966\nyes\n5\n90.0\n\n\n2\nAmsinckia menziesii\n1966\nyes\n6\n114.0\n\n\n3\nAmsinckia menziesii\n1967\nyes\n4\n125.0\n\n\n4\nAmsinckia menziesii\n1967\nyes\n5\n93.0\n\n\n...\n...\n...\n...\n...\n...\n\n\n1497\nPlantago erecta Morris\n2016\nyes\n1\n115.0\n\n\n1498\nPlantago erecta Morris\n2016\nyes\n2\n99.0\n\n\n1499\nPlantago erecta Morris\n2016\nyes\n4\n87.0\n\n\n1500\nPlantago erecta Morris\n2016\nyes\n5\n80.0\n\n\n1501\nPlantago erecta Morris\n2016\nyes\n6\n93.0\n\n\n\n\n1502 rows × 5 columns"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#statistical-analysis",
    "href": "posts/2025-01-26-bloom-shift/index.html#statistical-analysis",
    "title": "Bloom Shift",
    "section": "",
    "text": "Now I will employ linear regression models to evaluate the relationship between flowering phenology and climate variables (temperature and precipitation), identifying significant correlations and trends across species, regions, and time. My code calculates statistics of the state, Southern California itself, and climate division 6 to view the relationship between flowering phenology and climate variables (temperature and precipitation) using linear regression:\n\nData Preparation: For each species, the average annual temperature, precipitation, and flowering day-of-year (DOY) are grouped by year and filtered to ensure overlapping years.\nRegression Analysis: Linear regression models are applied separately to assess the relationship between DOY and temperature, as well as DOY and precipitation.\nResults Compilation: The species name, p-values, R-squared, and adjusted R-squared values for both models are stored in a summary DataFrame (stateSum).\nSignificant Results: If the regression p-values indicate statistical significance, the corresponding data for temperature or precipitation is labeled, augmented with species and region information, and added to a significant results DataFrame (sigSum).\n\n\n# create a dictionary to store unique species names\nflowD = {}\nfor i in range(len(avgPhenologyDiv.species.unique())):\n    flowD[i] = avgPhenologyDiv.species.unique()[i]\n\n\n# create a dictionary to store species with significant p-values\nsigSum = pd.DataFrame([])\n\n# set significance level\npval = .05\n\n\n\nState Wide Summary Data\n# create a dictionary to store the state summary data\ndstate = {}\n# iterate over the unique species and calculate the linear regression for each species\nstateSum = pd.DataFrame([])\nfor i in range(len(flowD)):\n    \n    # filter the data to only include the species of interest\n    avgF = avgPhenologyDiv[avgPhenologyDiv['species'] == flowD[i]]\n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data \n    xTy = list(xT['YEAR(S)'])\n    xPy = list(xP['YEAR(S)'])\n    \n    # create a list of years that are in the flowering data \n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the state summary dataframe\n    stateSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the state summary dataframe\n    stateSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    stateSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    stateSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n    \n    stateSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    stateSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    stateSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'State'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'State'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nstateSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.045038\n0.084\n0.065\n0.530467\n0.009\n-0.013\n\n\n1\nBrassica tournefortii Gouan\n0.656550\n0.005\n-0.018\n0.230165\n0.033\n0.011\n\n\n2\nCentaurea solstitialis\n0.663545\n0.004\n-0.017\n0.447359\n0.012\n-0.009\n\n\n3\nChaenactis glabriuscula\n0.022766\n0.101\n0.083\n0.966052\n0.000\n-0.020\n\n\n4\nClarkia bottae\n0.047639\n0.084\n0.064\n0.084706\n0.065\n0.044\n\n\n5\nClarkia purpurea\n0.030003\n0.093\n0.074\n0.096125\n0.055\n0.036\n\n\n6\nLasthenia californica\n0.226127\n0.030\n0.010\n0.116397\n0.050\n0.030\n\n\n7\nMedicago polymorpha\n0.738173\n0.002\n-0.018\n0.261980\n0.026\n0.006\n\n\n8\nPlantago erecta Morris\n0.097705\n0.055\n0.036\n0.765565\n0.002\n-0.019\n\n\n\n\n\n\n\n\n\nSocal Summary Data\n# create a dictionary to store the south state summary data\nsouSum = pd.DataFrame([])\n\n# iterate over the unique species and calculate the linear regression for each species\nfor i in range(len(flowD)):\n    # filter the data to only include the species of interest in climate divisions 6-9\n    avgF = avgPhenologyDiv[avgPhenologyDiv['ClimateDivision'] &gt;= 6] \n    avgF = avgF[avgF['species'] == flowD[i]]    \n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data\n    xTy = list(xT['YEAR(S)']) \n    xPy = list(xP['YEAR(S)']) \n    # create a list of years that are in the flowering data\n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    \n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the south summary dataframe\n    souSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the south summary dataframe\n    souSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    souSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    souSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n    \n    souSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    souSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    souSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'South'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n        sigSum = pd.concat(dfT)\n        \n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'South'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nsouSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.875755\n0.001\n-0.022\n0.875616\n0.001\n-0.022\n\n\n1\nBrassica tournefortii Gouan\n0.904122\n0.000\n-0.022\n0.404617\n0.016\n-0.007\n\n\n2\nCentaurea solstitialis\n0.702031\n0.004\n-0.024\n0.440332\n0.017\n-0.011\n\n\n3\nChaenactis glabriuscula\n0.115176\n0.050\n0.030\n0.594184\n0.006\n-0.014\n\n\n4\nClarkia bottae\n0.270753\n0.029\n0.006\n0.728577\n0.003\n-0.021\n\n\n5\nClarkia purpurea\n0.336247\n0.019\n-0.001\n0.203625\n0.033\n0.013\n\n\n6\nLasthenia californica\n0.263063\n0.027\n0.006\n0.752329\n0.002\n-0.020\n\n\n7\nMedicago polymorpha\n0.199275\n0.035\n0.014\n0.897705\n0.000\n-0.021\n\n\n8\nPlantago erecta Morris\n0.336801\n0.020\n-0.001\n0.425241\n0.014\n-0.007\n\n\n\n\n\n\n\n\n\nClimate Division 6 Summary Data\n# create a dictionary to store the average flowering days\nflowD = {}\n\n# iterate over the unique species and average flowering days\nfor i in range(len(avgPhenologyDiv.species.unique())):\n    flowD[i] = avgPhenologyDiv.species.unique()[i]\n    \n# create a dataframe to store the significant summary data for climate divisions 6\nsixSum = pd.DataFrame([])\n\n# iterate over the unique species and calculate the linear regression for each species\nfor i in range(len(flowD)):\n    # filter the data to only include the species of interest in climate division 6\n    avgF = avgPhenologyDiv[avgPhenologyDiv['ClimateDivision'] == 6] \n    avgF = avgF[avgF['species'] == flowD[i]]    \n    \n    # group the data by year and calculate the average temperature and precipitation\n    xT = coopT.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    xP = coopP.groupby(['YEAR(S)'])[['ANN']].mean().reset_index()\n    \n    # group the data by year and calculate the average day of year that the species flowers\n    y = avgF.groupby(['year'])[['DOY']].mean().reset_index()\n\n    # create a list of years that are in the temperature and precipitation data\n    xTy = list(xT['YEAR(S)']) \n    xPy = list(xP['YEAR(S)']) \n    yy = list(y.year)\n\n    # iterate over the years in the temperature and precipitation data and remove any years that are not in the flowering data\n    for j in xTy:\n        if j not in yy:\n            xT = xT[xT['YEAR(S)'] != j]\n    \n    for k in xPy:\n        if k not in yy:\n            xP = xP[xP['YEAR(S)'] != k]\n\n    # reset the index of the temperature, precipitation, and flowering data\n    xT = xT[['ANN']].reset_index(drop=True)\n    xP = xP[['ANN']].reset_index(drop=True)\n    y = y[['DOY']].reset_index(drop=True)\n\n    # merge the temperature, precipitation, and flowering data\n    dfT = xT.join(y)\n    dfP = xP.join(y)\n    \n    # sort the data by the average temperature and precipitation\n    dfT = dfT.sort_values(by=['ANN'])\n    dfP = dfP.sort_values(by=['ANN'])\n\n    # assign the species name to the six summary dataframe\n    sixSum.loc[i, \"Species\"] = flowD[i]\n\n    # calculate the linear regression for temperature and precipitation\n    resultsT = smf.ols('DOY ~ ANN', data=dfT).fit()\n    resultsP = smf.ols('DOY ~ ANN', data=dfP).fit()\n    \n    # assign the p-values, r-squared, and adjusted r-squared to the six summary dataframe\n    sixSum.loc[i,'Temp P-Value'] = resultsT.summary2().tables[1]['P&gt;|t|'][1]\n    sixSum.loc[i,'Temp R-Squared'] = resultsT.summary2().tables[0][1][6]\n    sixSum.loc[i,'Temp Adj. R-Squared'] = resultsT.summary2().tables[0][3][0]\n\n    sixSum.loc[i,'Precip P-Value'] = resultsP.summary2().tables[1]['P&gt;|t|'][1]\n    sixSum.loc[i,'Precip R-Squared'] = resultsP.summary2().tables[0][1][6]\n    sixSum.loc[i,'Precip Adj. R-Squared'] = resultsP.summary2().tables[0][3][0]\n    \n    # assign the species name to the significant summary dataframe if the p-value is less than the significance level\n    if (resultsT.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfT['Type'] = 'T'\n        dfT['Species'] = f'{flowD[i]}'\n        dfT['Region'] = 'Six'\n        sigSum = pd.concat([sigSum, dfT], ignore_index=True)\n    if (resultsP.summary2().tables[1]['P&gt;|t|'][1]&lt;= pval):\n        dfP['Type'] = 'P'\n        dfP['Species'] = f'{flowD[i]}'\n        dfP['Region'] = 'Six'\n        sigSum = pd.concat([sigSum, dfP], ignore_index=True)\n\n\n\nsixSum\n\n\n\n\n\n\n\n\nSpecies\nTemp P-Value\nTemp R-Squared\nTemp Adj. R-Squared\nPrecip P-Value\nPrecip R-Squared\nPrecip Adj. R-Squared\n\n\n\n\n0\nAmsinckia menziesii\n0.804356\n0.001\n-0.022\n0.656283\n0.005\n-0.019\n\n\n1\nBrassica tournefortii Gouan\n0.753239\n0.003\n-0.030\n0.424593\n0.021\n-0.011\n\n\n2\nCentaurea solstitialis\n0.494795\n0.014\n-0.015\n0.483818\n0.015\n-0.014\n\n\n3\nChaenactis glabriuscula\n0.056238\n0.072\n0.053\n0.353304\n0.018\n-0.002\n\n\n4\nClarkia bottae\n0.270753\n0.029\n0.006\n0.728577\n0.003\n-0.021\n\n\n5\nClarkia purpurea\n0.040614\n0.083\n0.064\n0.049008\n0.077\n0.058\n\n\n6\nLasthenia californica\n0.458737\n0.014\n-0.011\n0.461362\n0.014\n-0.011\n\n\n7\nMedicago polymorpha\n0.121612\n0.050\n0.030\n0.987780\n0.000\n-0.021\n\n\n8\nPlantago erecta Morris\n0.362461\n0.018\n-0.003\n0.393343\n0.016\n-0.005"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#visualize-summary-statistics",
    "href": "posts/2025-01-26-bloom-shift/index.html#visualize-summary-statistics",
    "title": "Bloom Shift",
    "section": "",
    "text": "sigSum\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n0\n57.374035\n132.000000\nT\nAmsinckia menziesii\nState\n\n\n1\n57.411930\n105.500000\nT\nAmsinckia menziesii\nState\n\n\n2\n57.764483\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n3\n57.798136\n114.333333\nT\nAmsinckia menziesii\nState\n\n\n4\n57.946538\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n...\n...\n...\n...\n...\n...\n\n\n294\n22.954211\n151.000000\nP\nClarkia purpurea\nSix\n\n\n295\n24.774386\n149.000000\nP\nClarkia purpurea\nSix\n\n\n296\n25.309153\n154.000000\nP\nClarkia purpurea\nSix\n\n\n297\n26.406271\n154.000000\nP\nClarkia purpurea\nSix\n\n\n298\n30.957931\n149.000000\nP\nClarkia purpurea\nSix\n\n\n\n\n299 rows × 5 columns\n\n\n\n\n# filter the significant summary data to each region\nstateSig = sigSum[sigSum['Region'] == 'State']\nsouSig = sigSum[sigSum['Region'] == 'South']\nsixSig = sigSum[sigSum['Region'] == 'Six']\n\n\nstateSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n0\n57.374035\n132.000000\nT\nAmsinckia menziesii\nState\n\n\n1\n57.411930\n105.500000\nT\nAmsinckia menziesii\nState\n\n\n2\n57.764483\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n3\n57.798136\n114.333333\nT\nAmsinckia menziesii\nState\n\n\n4\n57.946538\n111.000000\nT\nAmsinckia menziesii\nState\n\n\n\n\n\n\n\n\nsouSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n\n\n\n\n\n\nsixSig.head()\n\n\n\n\n\n\n\n\nANN\nDOY\nType\nSpecies\nRegion\n\n\n\n\n197\n57.374035\n145.0\nT\nClarkia purpurea\nSix\n\n\n198\n57.411930\n145.0\nT\nClarkia purpurea\nSix\n\n\n199\n57.764483\n140.0\nT\nClarkia purpurea\nSix\n\n\n200\n57.798136\n129.0\nT\nClarkia purpurea\nSix\n\n\n201\n57.946538\n152.0\nT\nClarkia purpurea\nSix\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Temperature for Native Flowers in California\n# set plot size\ng = plt.figure(figsize = [10,8])\n# empty list to store legend\nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(stateSig.Species.unique())):\n    g = sb.regplot(data = stateSig[stateSig['Species'] == stateSig.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{stateSig.Species.unique()[i]}')\n    l.append(red_patch)\ng.set_title(\"Flowering DOY vs Temperature for Native Flowers in California\")\ng.set_xlabel(\"Average Yearly Temperature (F)\", fontsize = 15)\ng.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('stateSigT.png')\n\n\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Temperature for Clarkia Purpurea in CA06\n# set plot size\nh = plt.figure(figsize = [10,8])\n# empty list to store legend \nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# filter the significant summary data to temperature only\nsixSigT = sixSig[sixSig['Type'] == 'T']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(sixSigT.Species.unique())):\n    h = sb.regplot(data = sixSigT[sixSigT['Species'] == sixSigT.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{sixSigT.Species.unique()[i]}')\n    l.append(red_patch)\nh.set_title(\"Flowering DOY vs Temperature for Clarkia Purpurea in CA06\")\nh.set_xlabel(\"Average Yearly Temperature (F)\", fontsize = 15)\nh.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('sixSigT.png')\n\n\n\n\n\n\n\n\n\n\n\nFlowering DOY vs Precipitation for Clarkia Purpurea in CA06\n# set plot size\nh = plt.figure(figsize = [10,8])\n# empty list to store legend\nl = []\n# create a list of colors for each species\nc = ['blue', 'orange', 'green', 'red']\n\n# filter the significant summary data to precipitation only\nsixSigP = sixSig[sixSig['Type'] == 'P']\n\n# iterate over the unique species and plot the linear regression for each species\nfor i in range(len(sixSig.Species.unique())):\n    h = sb.regplot(data = sixSigP[sixSigP['Species'] == sixSigP.Species.unique()[i]],\n               x = 'ANN', y = 'DOY')\n    red_patch = mpatches.Patch(color=c[i], label=f'{sixSigP.Species.unique()[i]}')\n    l.append(red_patch)\nh.set_title(\"Flowering DOY vs Precipitation for Clarkia Purpurea in CA06\")\nh.set_xlabel(\"Average Yearly Precipitation (In.)\", fontsize = 15)\nh.set_ylabel(\"Average Flowering Day of Year\", fontsize = 15)\nplt.legend(handles=l)\nplt.savefig('sixSigP.png')"
  },
  {
    "objectID": "posts/2025-01-26-bloom-shift/index.html#conclusion-and-discussion",
    "href": "posts/2025-01-26-bloom-shift/index.html#conclusion-and-discussion",
    "title": "Bloom Shift",
    "section": "",
    "text": "This study addressed two key questions: (1) whether average flowering observation dates are influenced by temperature or precipitation changes, and (2) if specific climate zones, like coastal Southern California, exhibit more pronounced phenological shifts compared to statewide trends.\nKey Findings: 1. Temperature and Phenology: Across all species, significant correlations with temperature exhibited negative coefficients, indicating earlier flowering with rising temperatures. For instance, Clarkia bottae blooms ~11 days earlier for every 1°C temperature increase. Over 50 years, California’s average temperature rose by ~1°C, significantly impacting native species.\n\nPrecipitation and Phenology: Significant correlations with precipitation were positive, meaning reduced rainfall led to earlier flowering. Though annual precipitation trends were not statistically significant, extreme events likely influence phenology and destabilize communities.\nRegional Patterns: Statewide, only native species showed significant correlations with temperature. In coastal Southern California (climate division 6), significant responses were observed in Clarkia purpurea and Chaenactis glabriuscula, with Clarkia purpurea being sensitive to both temperature and precipitation.\nNative vs. Invasive Species: Native species were more affected by climate change than invasive species, potentially giving invasives a competitive advantage. Earlier flowering in natives could lead to ecosystem shifts and competitive displacement by invasives.\n\nLimitations and Recommendations: - Limited species count and uneven data distribution across regions and species. - Precipitation analysis could be refined by focusing on seasonal rather than annual totals. - More comprehensive studies are needed, especially with equal representation of native and invasive species.\nImplications: Native species like Clarkia purpurea, critical to ecosystem stability, are highly vulnerable to climate change. Differential impacts across climate divisions necessitate tailored conservation strategies. Without intervention, these shifts could lead to ecosystem reorganization, favoring invasive species and jeopardizing native biodiversity."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Master in Environmental Data Science"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "About",
    "section": "",
    "text": "Master in Environmental Data Science"
  },
  {
    "objectID": "about.html#previous-portfolios",
    "href": "about.html#previous-portfolios",
    "title": "About",
    "section": "Previous Portfolios",
    "text": "Previous Portfolios\nPython with Applications"
  }
]